{
  "series": "YC AI Startup School",
  "talks": [
    {
      "speaker": "Replit CEO Amjad Masad",
      "title": "The Future of Software Creation",
      "date": "2025-09-12",
      "source_url": "https://www.youtube.com/watch?v=lWmDiDGsLK4",
      "transcript": "I was asked to talk about the future of software. So, a lot of this talk is going to be about what we're doing at Replet, where we think the future of software is headed and some kind of trying to make some predictions or try to think out loud about really what the future holds. my mental model for for our business and really for the moment we're in today. If you think back uh uh on the future on the history of computing, mainframes were kind of the the first mainstream computing devices as mainstream as it gets back then. And to use a mainframe, you needed to be an expert. And then PCs came around and initially PCs were kind of toys. you bought a Mac and you did Mac Paint and things like that. There wasn't real business use case. I mean, people like made fun of Apple at the time uh until the Excel sheet. The Excel\n\nuh until the Excel sheet. The Excel sheet was the first software that was actually useful on computers. And now PCs run world economy. Like they actually if you go at a data center, it's also only PCs. It's x86 computers. So you go you go from something that was used by a small group of experts that had to to have a lot of training to something that started sort of as a toy and is used by by everyone. Same thing with software engineering like uh the modern software engineering career you can sort of trace it back to the u 70s with the rise of maybe uh uh Unix and the C programming language. That's when people started uh kind of being trained to become software engineers. You still needed four, five, six years of uh educ college education. You need another two or three years of uh training on the job\n\nor three years of uh training on the job to be able to actually do the job very well. I think today software is going through the same transition from something that only experts do to something that anyone can do. And this is what we're really rep uh building replet for. I've been working at Replet for like almost nine years now. And our vision has always been to solve programming to like make programming so make it so that anyone can uh write software. So we built um an IDE, we built uh language runtimes, we built like a online sandbox environment, we built deployments, we built cloud services around all of that. And then when AI came on the scene, we realized that the ultimate expression of our mission is to make it so that you don't have to code. code is the sort of bottleneck to actually getting a lot\n\nbottleneck to actually getting a lot more people making software. So around, you know, late 23, early 24, we decided to put all our resources into agents. At the time, agents sort of barely worked, but you could tell by looking at a few benchmarks that were headed there. So, SWEBench is a software engineering benchmark. Uh it is basically a collection of um issues on on GitHub from major repositories and the unit tests and pull requests sort of end state of those issues and uh and the way you test an agent is you put in an environment and have it solve some of those issues. You could tell like in in 22 sort of it barely worked. 23 started sort of working and you could tell early sort of early 24 where we're on this trend where you could tell that software engineering is getting automated or like\n\nengineering is getting automated or like big parts of software engineering is getting automated. Uh and now we're probably I think this is like a little outdated. We're like at 70 80% Sweetbench. Now if this benchmark gets saturated doesn't mean that we automated all of software engineering but we're on on our way to make really useful arguably it's already here really useful software engineering agents and by the way this is true of any agent if any any of you are building sort of agents startups uh just like really believe that it's coming really really like I I keep telling my team we need to be okay with building crappy products today because two months down the line the models will get better and your business your product will suddenly become viable. So to today's kind of the moment for for uh for agents so rapid kind of\n\nfor for uh for agents so rapid kind of went all in on agents but agents that can write code uh is actually the easy part. The hard part is the infrastructure around it. Sometimes I call it the habitat for which the agent uh lives in. So what you need is you need a a virtual machine, ideally in the cloud, ideally not on your computer because you know agents can actually also mess up your computer. They could do a lot of scary things. So it needs to be sandboxed. Uh it needs to be scalable. If you're running a product like Replet, you need to be able to, you know, scale up to like millions of users and uh you need to be able to support every language out there, every uh package out there. Um the way uh software engineering agents are trained today is they're trained on standard Linux environment. They need to be able\n\nLinux environment. They need to be able to use the shell. They need to be able to write to files, read files. Uh but they also need to able to install packages either system level packages, Linux packages, but also language packages. And many cases agents want to actually use more programming languages. And so a lot of environments today where people are trying to build agents are very constrained. But what you what you want is an environment as open as possible similar to the kind of environments that software engineers work in. So what kind of other things you need to ship real software you need deployments, you need databases. Uh really think about everything you do as a software engineer and all those tools need to be accessible uh to software engineering agents. So actually I saw earlier today if you were at uh\n\nearlier today if you were at uh Karpathy's talk he he talked about how you know the the coding part is the easy part. So sort of similar to the points I'm making but he talked about all the different things that are really unsolved but in reality we actually solved a lot of them. So replet of the gate comes with o uh agents are actually not very good authentication. It's better to use a service built-in service. So replet actually one line of code we turn on co uh off. So when ask replet agent to integrate off uh it will actually just use replet off. It will just like basically turn on setting and and then uh you have user authentication you have user management those users information are being stored in the database. You can also obviously deploy the app you can uh link a domain to it. We have secrets management secure ways\n\nWe have secrets management secure ways of kind of uh using API keys. We have background jobs. You know, a lot of applications need to be able to run continuously in the background, especially in this era of agents. Storage again, uh, you know, agents need to be able to store things. They need to be able to grab things from the web, images, documentation, whatever, and store them for the application to use them in the future. Few other things on the road map, universal model access. So, it's really a pain right now to ask the model to like to ask for an application that can generate an that can do something with an images or videos. You have to figure out which model to use. You have to go get an API key and do all of that. Pretty soon, any model that you ask for at Replet, it'll be just available in your app directly.\n\nbe just available in your app directly. We'll handle the the billing and the API integration, all of that. Payments is very important. Payments not just for your users to pay for your application. Say you're you're building a startup on Replet. You're you're an entrepreneur. you obviously need to collect uh user payments, but also I think some sometime in the future you would want your agent to have some kind of wallet to be able to go uh pay for services. So let's say you know your your agent decides that it needs a Tulio integration and replet or whatever system you're using doesn't have a tool integration, it should be able to go put in its credit card and provision that service in the in the background. A more radical idea is that your agent needs to be able to like hire people. For example, if it hits a\n\npeople. For example, if it hits a capture and it doesn't know how to solve a capture, it should go and task grab it and ask a human to go solve the capture for it. Whatever it is, there's a lot of tasks that you still need humans for and you would want your your agent to be able to uh to have money to pay for services. And similarly, agent to agent. Um, you would want your agent to be able to go on the on the market and find other agents that can it can hire. Too many YC startups are building uh agents sort of agents for accounting, agents for sales and so you need your software engineering agents to be able to integrate those agents as well. So it's so I I know a lot of people think of MCP as such an agent to agent tool but actually MCP is a more traditional RPC protocol. So it's not really going to\n\nprotocol. So it's not really going to solve this. Another model on our sort of business or technology is think about sort of the level of autonomy. So when I started working on what Replet would become like years ago, perhaps decades ago, the state-of-the-art code assist was a language server, right? That's IntelliSense if you're using VS Code. And you can think of it as level one autonomy. You know, if you think about the uh sort of drive assist in self-driving cars or like in cars, you know, would be kind of the lane assist, that would be the first level. Uh AI code completion co-pilot, that would be level two. Uh level three is what we worked on um when agent when replet agent first launched. Agent v2 I I would call it almost 3. 5. It can work up to 10 15 minutes on its own but it still needs\n\n15 minutes on its own but it still needs your input every now and then to test the app and make sure the app is working. And right now we're working on V3. I'll talk a little bit more about V3 in a second. Uh but V3 is sort of level four, right? Like you're almost there. It still needs some of your attention, but it it kind of works fully uh autonomously. Bore Plus, which I assume we're going to get to in the next couple of years, you can really spin up a thousand agents, give them a lot thousand problems and and reliably be confident that like 95% of them is going to work. Like we're going to have a really high reliability rate. any kind of engineer or product manager really anyone can spin up hundreds if not thousands of engineers to do work on their behalf. So they need very little supervision and therefore\n\nvery little supervision and therefore you can uh increase your impact exponentially as as a as a programmer. So what we're working on right now with uh Asian v3 is uh that you know it's based on uh basically three uh three pillars. One is uh end to-end testing. So today computer use is um so in models what's called computer use if you've used openi operator it's the idea that models can go into a computer you know click around and use a computer like a human does they're slow they're expensive they're not very good but this is what I talked about earlier you want to build a product at the edge of what's possible right now the edge of what's possible is like computer use in my opin is really at the frontier of what these models could do and I think over the next 3 to 6 months they're going to get\n\nnext 3 to 6 months they're going to get a lot better and it's going to enable an entire new market and also probably start to automate a lot of real jobs once we have app testing uh you know this this kind of annoying thing that replication does where keeps ask asking you to do QA for it'll start doing QA on its own and that will allow it to work you know 30 40 up to hour maybe two hours of work. Sort of the hype today is test time compute. If you think about the sort of 03 uh or like oer models or deepseek R1 the kind of main insight there is the more tokens the model is able to consume or produce uh the more intelligent uh it gets. Now today with something like 03 the model is generating a lot of tokens and trying to reason but a lot of it is sort of synopsistic. It doesn't get feedback from the environment. It's almost like\n\nfrom the environment. It's almost like it's just sitting in place and thinking. What you'd want in a real computer environment is for the model to generate hypothesis and test its hypothesis in real time. So at Replet, we built a uh fully transactional reversible uh file system. So when you're on on Replet, every edit you make to the file system is an atomic snapshot in time. And that allows us to have very cheap copy and write forks of the file system. And so our idea for this is that um anytime there's a tough problem or basically if you have a lot of budget you can have it on all the time but every time the agent is making a big change it forks itself and the environment in number of times to solve this problem in different ways and then find the best solution and then take that solution merge it into the\n\ntake that solution merge it into the main branch. So think about you know the idea of simulations like when you're thinking about the problem you're often simulating different branches of things that you could do you have different hypothesis you want to test and so we want to also uh give agents the ability to do that. So at any given problem generating a ton of different ways of doing it and then testing all of them in parallel. This will bring up reliability of agents by I think two to three folds. So that's sampling and simulations. And then finally is uh for the uh model to be able to generate tests for every feature that it creates. Today replet replet agent often creates a feature and then later on breaks that feature but also true of clot code and cursor and all the others. So we want to make it so that\n\nothers. So we want to make it so that once the agent makes a set of changes or feature, it always has tests that it runs on every change to make sure it's not breaking the software. This is actually harder than it sounds like it sounds like okay write tests and let's run them. But often actually models are pretty bad at generating unit tests. So there's still a lot of work uh to do there. It needs to be fast as well so so that it happens on every change. So I so that's what we're working on with V3. That's a lot of infrastructure work. Want to create the best habitat for agents to to live in and be able to u the most be the most reliable possible. But like let's fast forward to like what I talked about with like level five autonomy. Really the most autonomous system we can think of. YC's next batch is now taking\n\nYC's next batch is now taking applications. Got a startup in you? Apply at y combinator. com/apply. It's never too early and filling out the app will level up your idea. Okay, back to the video. My prediction is that all application software will go to zero. In other words, software will be dirt cheap, that no one will be making money on the traditional type of SAS software. I'm not saying this will happen tomorrow or even next year. I gave up on the the um trying to predict timelines. I know it's going to happen on the order of years. If anyone with one prompt can generate any kind of software of any type of complexity, then um the value of applications will go down to almost zero. So what does that actually look like? So today you know in the startup ecosystem in the tech ecosystem there's\n\necosystem in the tech ecosystem there's all these generic generic SAS you know vertical SAS software and any of you who's running a small business or even a bigger business you you probably have bought you know dozens and dozens of SAS software just to uh just to run your business even today you're able to replace large parts of those software by using something like replet agent or writing your own software uh I think in the next few years. This again this will go from uh you know maybe 15% replaceable to 100% replaceable. So this will really fundamentally change the software market. Uh just to give you a story uh one of our colleagues at Replet uh Kelsey was uh she works in HR uh she's never written a line of software in her in her life and she wanted an orchar software. She had a few bespoke\n\norchar software. She had a few bespoke needs like she wanted to connect it to ADP, our our sort of payroll software and and she had a few features that that she wanted and she went on the market and she couldn't really find an org shot software that exactly fits her needs. They were very expensive that were going to cost tens of thousands of dollars a year. So she decided to make it. She took a week, less than a week, three days, and she made orshot software that we're using today that we can go out on the market and sell it as a SAS product for tens of thousands of dollars a year. So that's like mind-blowing, right? I mean, it's HR professional can make software to run their work. That's happening today. Try to project that out a couple years later. Like the software business fundamentally changes, gets\n\nbusiness fundamentally changes, gets disrupted. Not only software but I think how we work, how businesses works, how corporations work will will fundamentally change. Today we have these roles you know uh companies like to specialize since the industrial revolution when factories you know became the main mode of creation. the sort of modern uh special, you know, specialization in the economy kind of emerged where one person is making one part of the the the product. It goes on a factory sort of um assembly line and another person is responsible for testing it, another person responsible for assembling it. And so this this um specialization has been the way the economy has been trending for a long time. And it sort of makes sense, right? You want to uh specialize people as much as possible. You want them to be as as\n\nas possible. You want them to be as as replaceable as possible. And so this is how the modern economy is built. But once your HR professional is also a software engineer is also potentially a marketer is also potentially anything because they can learn anything. There are AI agents that can do anything for them. really, you know, you go into the world where jobs will become less specialized, less um siloed. And in fact, we started, we're seeing it today and we're at Replet the way we're structuring our orchard and our business based on this idea. We're building for the first time, we're building a like a actual product team, product management team. And our product team is actually made of designers, engineers, and product managers all almost always in the same person. So we're trying to merge a lot of roles\n\nSo we're trying to merge a lot of roles together and create this generalist employee. So the the arch will start to look more like a network than a hierarchy. So it'll look more like an open source project than a than uh it will look like a traditional company hierarchy with a marketing department, sales department. Every employee will like wake up in the morning and their mandate would not be write this marketing email or you know make this uh optimize this button. Their mandate would be make the business work, generate value for the business. So everyone is sort of an entrepreneur and that will really disrupt and fundamentally change how companies work. It's a model that really we haven't you no one has really embraced or or or even started to talk about but really you know think it through if everyone has\n\nknow think it through if everyone has access to a general purpose software engineering agent and sort of agent for every possible role obviously domain expertise is still important but is not as important as it used to be. It's exponentially less important and this also affects how people build businesses. it affects the opportunities that are available for us in the future. One uh really interesting book uh that I read this book is was written in the 80s which is insane given how good the predictions were. So I'm just going to read this. Ideas will become wealth. merits wherever it arises will be rewarded as never before. In an environment where the greatest source of wealth will be the ideas you have in your head rather than the physical capital alone, anyone who thinks clearly will potentially be rich. The\n\nwill potentially be rich. The information age will be the age of upward mobility. The brightest, most successful and ambitious of these will emerge as truly sovereign individuals. Now, some of these various is a bit dated. The information age perhaps we call the intelligence age today. But this book predicted things like uh crypto, remote work, all sorts of things like that. And this idea of like a sovereign individual, someone so uh empowered by technology, so empowered by these uh uh agents uh that is able to create enormous amount of wealth uh individually is is uh is is going to be the norm. Think think about um someone like Satoshi. Satoshi created a single person created a trillion dollars worth of value. I don't know what the market cap exactly. Perhaps it's more than trillion dollars\n\nPerhaps it's more than trillion dollars of Bitcoin. But like that's a single person. They wrote the paper. They wrote the software. They put it out there and it became a big thing. Obviously there's a lot of people. It's a big market right now. But it was created by a single person and we don't know who they are. And I think that's going to be a common occurrence in the future. The really great thing about it is really um the access to opportunity will be universal. The idea of merit being rewarded wherever it arises doesn't matter if you're in Silicon Valley or anywhere else in the world. If you can think clearly and you can use some of this technology. If you can think clearly and generate good ideas, go into replet, put in those ideas, make the first version of software today, you can start to\n\nof software today, you can start to become more like the sovereign individual. Again, the way collaboration work will be will be seamless. You know, everyone's talking about the you know $1 billion single person company, but I think that really kind of misses the point a little bit. What's really interesting about it is that you'll be able to assemble groups of people really quickly. You'll also be a be able to assemble uh groups of agents really quickly. You'll be able to assemble these companies and also unwind them. You can create mission purpose, you know, companies or like projects and unwind them really quickly. And in some cases it could happen in a day or two. And sometimes you might be you might think you're working with another human on the internet, but they're actually an agent built by someone else who's out\n\nagent built by someone else who's out there doing work for them. So the way we work uh and the way people build startups will fundamentally change as the the cost of transaction goes down goes down to zero then um the the the reason to hire an employee full-time uh you'll have less of a reason to hire full-time employees. So think about um like getting an Uber today. The transaction cost the kind of effort of getting an Uber is just one button on your phone. I think the same thing will be in the future to to get a developer whether it's a software agent or another human being. Uh it'll be just like one button. I want this problem solved. You'll be able to maybe your agent will be able to go find and interview a lot of different people or agents on the internet and be able to find the best uh\n\ninternet and be able to find the best uh thing to solve that problem. And um and so you'll be able to like build businesses really at the speed of light. Now you know I I I talked about how kind of application software goes to zero. That doesn't mean that all software goes to zero. Today you know rapid agent or others the way it works is the agent makes a piece of software the user uses the software to solve problems. You can think of those things as intermediate steps. Instead, agents can just solve problems. And and for Replet, and I'm sure a lot of other businesses to survive, at some point, Replet needs to stop being focused on making applications and start being focused on solving problems with software. So, I want to leave ample time for for questions. So, I'll I'll I'll end here and open it up.\n\nI'll I'll I'll end here and open it up. My name is Chinat from Stanford. Nice to meet you. My first question is in this future do you see there potentially humans engaging with multiple agents or will there be a unilateral agent and if in the case of like multiple agents um how would we deal with the fragmentation of like data memory and context across all these different agents I think multiple agents uh and and the reason I think that's true is because let's let's say I'm someone with true unique domain expertise uh let's say I'm I'm a lawyer who is top in the world at solving certain um cases that that are very rare. And so I have this domain expertise that I'm not going to share in the open source. I'm not going to sell to scale AI so that they can sell to to OpenAI or Google all of those. I'm just going to keep this\n\nof those. I'm just going to keep this resource to myself. But the way I would monetize it instead of myself going and selling my services directly, I would like imbue this knowledge into an agent that becomes this very specialized agent in this very specialized domain and then I can scale myself. uh and so so I think I think people will be building these agents to work on their behalf and then um there's going to be agents that that uh go out there and assembles these teams of agents uh and then there's going to be obviously software development agents and maybe there's and maybe you're running all all this through chat GPT or whatever main interface you have but I think it's going to be a multi- aent world with different contacts similar that we have in the world today. When I go to a lawyer, I need to give them my context.\n\nlawyer, I need to give them my context. So, uh, and maybe there are protocols and this is why they talked about how MCP really doesn't solve the agent to Asian problem. I think there needs to be more interesting protocols in this space that and maybe this is a startup someone builds. Hi, thank you for the insightful talk. My question is as follows. in the not so far off future where we're going to have AI systems that can automate most if not all of meaningful physical and cognitive tasks and there's increasing delegation to agents that work on your behalf and talk to other agents that are working on other people's behalf then what is left for humans to do or like what will our human condition look like because our physical and cognitive aspects can all be done by intelligences depends on your\n\ndepends on your worldview and belief of the limits of AI versus the uniqueness and premacy of what humans can do. So it becomes a bit of a religious discussion but my view is there's something special about humans and my view is that there's a fundamental limitation with how we do AI today and maybe this gets solved but AI today can't truly generalize out of distribution everything AI can do h needs to be represented in the data say I go back to this example of this lawyer that is expert in the world at very rare cases uh again this is something that no one else knows how to do uh or can do or whenever there's like a truly novel problem, truly novel case, you still need human ingenuity um to solve that problem. And so I think humans will be more in the creative seat and I think agents can be creative as\n\nand I think agents can be creative as well but their type of creativity are not net new knowledge. It's more like about uh which is a lot of what creativity is bringing a lot of different things together. And so but but this idea of like ideas become wealth uh is um is what gets really exciting about it is like people can generate novel ideas and test them out really quickly which you know I don't think we're going to get to a to a point where you can go tell an agent hey go find me a you know business idea and go test all of them. I don't think we'll get there anytime soon. Thanks for your talk. I've been following Replet for many years and that's actually where I learned how to code as well was on Replet. So you mentioned the value of clear thinking and ideas being the future. Do you see this as an argument\n\nfuture. Do you see this as an argument more towards a favor of a liberal arts critical thinking model of education instead of a more STEM uh skills-based focus? I don't I don't think they're mutually exclusive, but I do think that the liberal arts will become more valuable. I I think today engineers tend to be uh a little more parochial than they can afford to be in the future because you know what I shot what I showed with the kind of the model for what the future company could look like. Everyone becoming more of a generalist. I think today engineers can afford to like not understand even the business they're in. A lot of engineers are just focused on very narrow domains. Uh so I think people need to have a more broaden worldview and set of skills. So um but I don't think they're mutually exclusive.\n\ndon't think they're mutually exclusive. I think you know being being scientifically minded I think is going to be important. Hi. Yeah. Uh so I wanted I was more curious as to uh where in the tech stack like is replet making a lot of progress because as you said uh replet can do tasks which for for one hour and so given that like replet uses probably closed source models which have no access to pre-training and post- trainining uh where in the text are you making that like amazing uh kind of innovation? that gets your models to work auton autonomously for like an hour. It's what I was calling the habitat of the model. So, you know, the um the commercial models can train really great models. They can train them to be as autonomous as they as as possible to be coherent over a long period of time. But\n\ncoherent over a long period of time. But uh us or really any um agent company needs to be able to provide the infrastructure for for that agent to to exist in. And so all these components that I talked about. So one really crucial thing about replet is this idea of uh you could call it trans uh being being transactional or atomic. every mutation to the replet computer environment happen in sync with every other uh component of the system. So right now in replet if you go to your history you can see previous checkpoints and you can actually go to any one of them and reboot the application in that state and so we think that infrastructure is going to be really crucial for how to make um the models more more reliable. I think there's a limit on how much the training can increase reliability, but I think the environment feedback and\n\nbut I think the environment feedback and the ability to try things really fast is the way to get to the upper echelon of reliability. So that's what we're focused on. Hi. So you talk about the generalist employee and how that's the sort of future of um companies. I I to I totally agree with this vision, but where I find myself stuck is finding roles today that set me up for that kind of future. what what kind of opportunities should we look out for? What kind of positions should we look out for in startups, in companies that would prepare us with the skills that are necessary in order to be a generalist good employee five five years down the line when that finally becomes a thing. I know being a founder is one option but um not all of us want to take that career plunge immediately. Uh some of us\n\ncareer plunge immediately. Uh some of us want to work with other people, build teamwork skills and learn all of those other things as well. How do we go about that? Jo join startups as early as possible. Like obviously you can think of it of it as um sort of exponentially decaying uh curve where like being the first being the founder you get the most generalist experience being the you know first employee and then by the time you get to the hund I don't know like to the maybe 100th employee you're sort of like you're not getting as much of that journalist experience but like just join as early as you can depending on your risk risk profile and and all of that. But even like number 20 at a like a series B company, I think you will get a lot more experience than at a at a fang or something like that. Even if you join\n\nor something like that. Even if you join that startup, you need to be seeking those generalist opportunities. So don't sit there waiting for people to give you tasks. Have that mindset of I'm waking up in the morning. I'm not looking at a to-do list. I'm looking at a mission. and my mission is to make this company succeed or be more valuable. Um, hi, my name is Shivam. I also wanted to ask about the one hour of autonomous like agent development. Uh, specifically like could you like elaborate a little more on how like you and your team approach how long of a time horizon is worth pursuing as opposed to improving reasoning for shorter time horizons. So, so I think the what you're talking about with shorter time horizons is more like uh let's um let's work on reliability um and then longer time horizons like\n\num and then longer time horizons like let's work on autonomy um removing the human in the loop and the burden of the human to continue to test and give feedback. Um so we're doing both. When I'm talking about reliability, this is more investing in reasoning and more investing in this parallel agent. um trial and error that I was talking about while we're calling sampling and simulations. And then for uh long horizon, it's more about testing, making sure that because as you go longer, the there's like an there's a like a gold drift. The the agent might start doing things that you don't like, but having those guard rail rails of of testing along the way uh will make it so that it stays more coherent uh over time. And then as we collect more data about what fails and what doesn't work, you can either uh like go and fine-tune\n\nyou can either uh like go and fine-tune that or you can just like continue to improve the prompts uh and add more guard guardrails to to make it better. So I think both are important. Hi, I'm Sophia. Um have been thankful for your talk and I've been following you met at AI for developers when you were talking about ghostriter and the work behind it. Um, but I'm curious to hear more about how agents are kind of over oversaturating um, uh, certain set certain sectors and um, whether or not that should kind of you should consider that when you're uh, working on them or joining a startup that's working on something. I think certainly software is like really tricky. software engineering agents. There's like there's a lot of people that want to do that. And if you're coming in late, you want to have\n\nyou're coming in late, you want to have a truly novel idea to be able to like compete there. But, you know, there's a lot of things like who's who's building the agent for HR or finance. Uh I know one company's doing accounting. Uh there's a lot of companies doing SDR for whatever reason. That's very crowded. What I would start with is what are you interested in and what where do you have domain knowledge? So the best way to start an agent company is that if you yourself you're you yourself you're like a compliance officer, you start uh a a compliance officer or you're passionate about compliance. I don't know who's passionate about compliance, but if you're passionate about compliance, uh, go start an Asian company because you're going to learn the most about it and you're going to have the most domain knowledge and\n\nhave the most domain knowledge and domain knowledge is the most important thing to build an Asian company. Hey, um, so if the cost of software and building software is going to zero, then by extension, the platforms which build software like Replet, like the value capture will be going down to zero. So, how are you planning to make money long term and how are you going to compete with like the other competitors like Bolton and lovable? Yeah. Yeah. So, notice that I I said not uh old software. I said like application software specifically. So, I think software will continue to run our lives but a lot of it will be autonomous. So for example, I build a lot of personal software using Replet and a lot of it is around managing my life and my family and like you know uh doing a lot of quantified self stuff a lot of like you\n\nquantified self stuff a lot of like you know data about my sleep and and and all of that stuff and then I spent a lot of time like plotting that data and doing all of that stuff like instead I should be able to tell replet agent here are my goals you figure out what kind of software that needs to that we built and you figure out how to how to uh operate it and you tell me what wearables I need to buy and what um and and what do I need to log in the morning, what do I need to do and she'll be able to go make the software uh acquire the things that I need in my home, what kind of sensors and then solve the problem for me. I think I think Replet needs to become a universal problem solver for our company to survive. And I think for a lot of the others, you know, I I think it's already, especially the companies that\n\nalready, especially the companies that you talk about in the prototyping space, it's already getting really crowded there. I think what replet where really Replet excels today is the fact that it's full stack. It can go from idea to a deployed and scaled software. Hi, uh my name is Emma and I'm really intrigued by your vision of this future where all code is written by agents. But I'm also kind of concerned because there is this kind of known problem where if you train a generative model on data that is generated by another model, you get an issue of like accumulating error, accumulating noise. So my question is in this future where code is written by agents, it's tested by agents, is approved by agents, how do we kind of prevent this exploding error problem while still allowing these models to\n\nwhile still allowing these models to grow and evolve? My bet is that pretty soon we're going to move into more of the alpha zero style of training where um you have a more traditional LLM that's trained on all of the internet. Um but but then the way to train the next generation of it would be to give it a reinforcement learning environment where uh it's generating a lot of problems and doing like selfplay where it's solving these problems getting feedback on them and doing it in this like massively parallel way. I think this is how we're going to get the next generation of software agents. It's not going to be trained on human code because like you said there's not going to be human code and so we have to solve this otherwise we'll plateau very hard. Hi. Um, I'm quite interested in some of the systems\n\nquite interested in some of the systems report uh support required for these agents. Um, and I find the universal package manager that you've released and your use of Nyx quite interesting. And you mentioned this um copy on write snapshotting and and uh uh forking and merging. Uh and I'm working on a similar thing. Well, you should come work out. Uh I was wondering if any of this is publicly available or something. I think you might be thinking about open sourcing. Um yeah, I mean we open sourced uh some of our package manager work. We're big contributors to Nexos. So we use Nex OS which is a transactional operating system generator is the best way I can I can describe it and and possibly the file system stuff will well at minimum talk about it but this is like active active work right now. Um but yeah come\n\nactive work right now. Um but yeah come like intern at Replet and learn all this stuff and then go build it yourself. Thank you. All right. Thank you everyone.\n"
    },
    {
      "speaker": "Michael Truell",
      "title": "Building Cursor At 23, Taking On GitHub Copilot & Advice To Engineering Students",
      "date": "2025-09-03",
      "source_url": "https://www.youtube.com/watch?v=TrXi3naD6Og",
      "transcript": "We realized we were really inherently excited about the future of coding. And I think we took a step back and realized that if we were being really consistent with our beliefs, there was going to be an opportunity for all of coding to change in the next 5 years and for all of software development to flow through models. It felt like no one working on the space at the time was really taking that seriously. It felt like they had great products and they were making them a bit better, but they weren't really aiming for a world where, you know, all of coding as we know it today gets automated and building software ends up looking very, very different. Then with that in mind, we set out to to work on that. Let's start this talk with sort of the origin story of your journey as a founder. You kind of have to go way back\n\nfounder. You kind of have to go way back to middle school when you were reading the essays from PJ, right? So early on I think uh you know had been interested in in starting a company for a long time. Had been interested in a bunch of a bunch of other things too. I think actually originally got into programming being interested in in starting something kind of commercial where uh the first time that I ever saw code. It was over some winter break and my brother and I we wanted to create a hit mobile game. We didn't really know how to do that. We looked on Google how do you create a game? We heard that you need to download this application called Xcode. Uh we did that and uh we were hit with these weird colorful esoteric symbols which were Objective C which you know uh is still around but maybe a\n\nknow uh is still around but maybe a little bit less popular than it was then for good reasons and um stared at uh this kind of impenetrable wall of Objective C and my brother promptly ejected. Didn't move on with programming. He now is on a very different career path. He's kind of trying to paint or something like that. Um but um I yeah kept going and uh bought a book on Objective C and then eventually uh started working on on mobile games. That was the genesis of me getting into programming and then along the way also yes was a big fan of uh PG's essays and uh Sam's essays too also and a bunch of the folks in YC and that was definitely a big inspiration even from the very early stages of of high school. I think the wildest thing about cursor is that right now you're just 24 and build this monster of a company in a\n\nand build this monster of a company in a really short amount of time. To a lot of people it could seem that it's a bit of a out of out of nowhere, but this was really in the making for more than a decade. You've been working and shipping a lot of different projects, right? And you were working in AI even when you were in high school, right? Tell us a bit about the projects and how you got started with that. Was lucky enough to find programming early on. was also lucky enough to be interested in AI early on uh and have some great collaborators to work on AI projects with soon after kind of the fay into mobile games which also turned into uh I wasn't very good at mobile games so one of the things that I built and actually one of the things that got most popular which was kind of the technically easiest thing to build which\n\ntechnically easiest thing to build which was maybe a lesson in startups of you know the code isn't everything uh was uh this mobile game or this mobile app where you could spoof high scores in things like piano tiles and flappy and then send them to your friends. And that was kind of the thing that went viral. It wasn't the, you know, painstakingly handcrafting the game engine yourself thing. But uh yeah, no, soon after that uh got interested with a friend in the idea of building a robotic dog where we thought it would be really great to have a robot that you could teach to do things without programming it. Um instead you could give it positive and negative feedback like you give a dog. So you could give it a treat if it does some, you know, quote treat if it does something good. Uh you could\n\nif it does something good. Uh you could say bad if it does something bad. and then maybe it would you know you could teach it to play fetch and things like that. Uh that idea really animated us. But we had no idea how to build it. And so again you know started the place where one would start which is Google and kind of went down a lot of rabbit holes and you know took us into a place of uh learning about genetic algorithms and maybe that was going to be helpful for building this robot dog that we wanted to build. And then we eventually learned about you know this neural network stuff because some people were playing with taking genetic algorithms and using them to evolve neural networks at the time you know with work like neat. And then uh eventually it took us to RL reinforcement learning um which\n\nto RL reinforcement learning um which was you know even back in 2015 uh people had been working on it for a long time. In the end my friend and I we did eventually build a couple of robots. We did we didn't do any sort of substantial work that really lasted but we did work that was interesting at the time in taking reinforcement learning algorithms and making them more data efficient. you know, making them better at learning from very, very few data points, you know, order of tens of data points and also from noisy data, you know, data that a human's giving. It wasn't exactly a dog, but we built a couple of robots where one of them was this many axis robot arm that could kind of swing a paddle and play ping pong and if you put the right sensor on it and then you gave it the right sort of positive and\n\nit the right sort of positive and negative feedback, you could teach it to swing when it sees a ball. And then uh we had this Kiwi drive robot that we would teach to follow a line. to do that. It was actually kind of this great education in ML. Um, partially because of our dumb naive where we didn't really know that there were things like Torch and TensorFlow and kind of other you know lots of building blocks we could use from maybe we weren't good enough at Googling. So you like implemented your own neural network from scratch. Yeah. So when you were like I don't know 16 17 the constraints of the problem were we were dealing with uh robots and so we were dealing with microcontrollers um and so microcontrollers have very little memory and they couldn't really fit any of the normal standard ML\n\nfit any of the normal standard ML libraries. So as part of our bike shedding trying to build a robot dog, uh we implemented our own tiny neural network library and I have memories of us not really understanding any of the internals of how these things worked or not really understanding calculus but kind of fumbling our way through re-implementing um some important ideas from neural networks. I you know I think it it taught us a lot. I think there were a lot of gaps of the fundamentals that it took many years to fill in later. Then fast forward to the founding of anyphere. It's a interesting name because cursor is not what it is. When you guys started, you had just um graduated MIT, right? That was back in 2022. What were the first idea that all four of you started working on back in 2022? Yeah. So, the the genesis of cursor was\n\nYeah. So, the the genesis of cursor was in 2021. Uh my co-founders and I, we had been interested in AI for a long time. Each of us kind of had our own little robot dog moment where one of my co-founders he worked on uh trying to build a competitor at Google actually uh using LMS in in 2021 and and training his own um and training his own contrastive models. Uh one of my co-founders uh worked on computer vision in academia and you know some of us also worked on recommendation systems at at companies like Google. But uh we were really interested in AI. In 2021 we were trying to figure out what we do with that interest. Do we go and work on AI in academia or you know do we go join you know a big existing AI effort or do we start our own thing and there were two moments that really got us excited.\n\ntwo moments that really got us excited. One was seeing the first AI product start to come out uh you know GitHub copilot was really the canonical example for us. The other was seeing work about how it looked like AI was going to predictably get better in the future as you scale up these models. At the very beginning of 2022, uh me and my co-founders, we went on a like a month-long hackathon basically and we started hacking on ideas related to kind of picking an area of knowledge work and building what it looks like as AI gets uh more and more mature. Um you guys have collected a lot of data for that first idea, right? Yeah. So the first real idea that we worked on for a long time was in me mechanical engineering. was trying to build a a co-pilot for mechanical engineers and trying to train models to\n\nengineers and trying to train models to kind of predict what you would do in a CAD system like Solid Works or Fusion 360 um which is where uh Mecky's model out parts in 3D on a computer. We picked it because we thought it would be boring and sleepy and uncompetitive and uh we were kind of doing an armchair MBA thing even though it was a horrible choice from the get-go because none of us were really mechanical engineers and also the science wasn't really ready for that area. But you guys kept working at it for a number of months, right? And you crawled and got all these CAD files and actually got something working with autocomp completion, right? That was like the first version of it working. Yes, we a bunch of the work was in data scraping. Honestly, it was trying to get all the CAD CAD models in the internet.\n\nall the CAD CAD models in the internet. There also all these different file formats and trying to convert them all into something that's canonical because CAD is this weird software market where there are all these different systems that are pretty popular. It's very fragmented. Uh there are also cloud CAD systems that don't have easily exportable files and they don't want you to scrape their stuff and so there was a bunch of work there. Also the training infrastructure for doing any kind of modeling work back then was pretty rudimentary and so there was a lot of work on the on the infra side there and just a lot of experimenting with models and a lot of experimenting with how you even jerryrig an extension into these CAD systems because they're the you know we were building an extension these\n\nwe were building an extension these applications aren't really extensible at all. There were actually also other projects that we were working on at the time. So um two of my co-founders they were working on an endtoend encrypted messaging system um because one of them has a background in security research and the idea there was apps like Signal and WhatsApp um they encrypt the body of the messages but they don't hide who's talking to who at what time which is actually really crucial information if you don't want to trust the messaging app provider. So, you know, if a journalist is talking to, you know, talking to some informant in the government, just knowing that they're communicating at all is a is actually, you know, a really big piece of information. So, that was in the middle of uh 2022.\n\nSo, that was in the middle of uh 2022. So, you guys were working for about good 6 months on this idea. Yes. And how many users were you getting at did you get at that point? So, you shipped the product. All all of these projects were elevated and it had basically no users. At what point did you realize that the idea was not working? It's like, oh no, we we're all working on this. We we're trying to do the startup. It's not working. And what was that moment like? I think it was a bit different for each of the projects. I think for the messaging system that uh two of my co-founders worked on. It was really technically impressive, but it had these bad trade-offs where it wasn't very scalable. And I think they tried to give it to people and it didn't really work. And then they tried to sell it B2B and\n\nAnd then they tried to sell it B2B and then it didn't really work. And I think it was after a couple of months of trying to get traction for the CAD ideas. It was yeah many months of trying to get the models to really be useful um for end users and then also reckoning around are we really interested in these areas or is there something else that we're inherently much more excited about. So there was a moment that you decided okay these ideas are not working we have to pivot again. Yes. you you you turned through a three ideas, three, four, five ideas before landing into into uh code completion. Yeah, I think that um so we had been inspired by um tools like copilot really early on um and we had avoided working on um AI and coding because we thought it was too competitive competitive then still is competitive now. So\n\nstill is competitive now. So 2022 GitHub copilot was making already about 100 million revenue I think or more potentially more. Yeah. And you guys are like, \"Oh, we could still do a better job than GitHub Copilot because people thought the game was done. \" It's like, \"Hey, GitHub. \" Well, I mean, we we didn't think we could at at the start. And then I think, you know, it was the desperation of having worked on ideas for a while and not really being excited about them after a while and them not really working out. And that kind of shapes, I think, what you care about and what you're aiming for. And we realized we were really inherently excited about the future of coding. I think also we got to see how some of the other people in the space were, you know, working on their products. We got to see how the tech was\n\nproducts. We got to see how the tech was developing. And I think we took a step back and realized that if we were being really consistent with our beliefs, you know, there was going to be an opportunity for all of coding to change in the next 5 years and for all of software development to flow through models. And it felt like no one working on the space at the time was really taking that seriously. like it felt like they had great products and they were making them a bit better but they weren't really aiming for a world where you know all of coding as we know it today gets automated and um building software ends up looking very very different. Then with that in mind we set out to to work on that. That was a bold move because you said okay we're going to stop working on all these other ideas that we didn't have as\n\nthese other ideas that we didn't have as much of a background and you were excited about programming even though you had this big Goliath in the room with GitHub Copilot. you decided to go and let's just solve this problem. It didn't really feel bold or like a move at the time because it's like you know bunch of people sitting around in their living room like on laptops. It's not like you know like pivoting some giant company but uh yeah no we did and uh you know initially we kind of waited into it where we were thinking well you know maybe we do this kind of very a niche tool for basically security reviews you know trying to detect future CVES in your code or maybe we build something that's just for this one niche area of software. um you know we we thought about building for quants and actually um kind of prototypes and\n\nactually um kind of prototypes and things just for quantitative researchers. But yeah, in in doing that we were just brimming with ideas for what cursor could be if it were just about trying to be the best way to code with AI uh in general. And then I think that we just we had a ton of conviction about that and we had a ton of excitement about that and so at some point we just decided to to go for it. Yeah. And that was end of uh 2022, right? when you decided to make that move and how quickly did you ship the first product and what did the first product look like and that was around you shipped it a couple weeks later and what was what was that look like? Um it did take us a little bit of time to ship something publicly. Mhm. It took us roughly I think three months from first line of code to open it up\n\nfrom first line of code to open it up and G it. Originally what we did is we built our own editor quote unquote from scratch. Oh my god. Still it was still using a bunch of open source building blocks. There are a lot of great primitives like code mirror and you know the language servers and there's a lot of open source tech that can that can help you build an editor but uh yeah no it was called together from scratch and there was our own version of remote SSH or own copilot integration at the time because we didn't have anything like autocomplete you know you have to build you know your own peen system you have to build all your own language server integrations there's just a lot that ends up going into um something as developed as you know the code editor market you know making something that can actually be\n\nmaking something that can actually be competitive there and service someone's daily driver but it was I think it was four weeks until we built something that we could use as our daily driver. It was maybe four weeks later where we gave it to the first beta testers and then there was another four weeks and then we g it and it was still very very crude at the time. It didn't feel like a big thing to just open it up to the public. What did you learn in that first version? Because you you built a code editor from scratch. You guys haven't done the whole forking yet. Yeah. And we had the fear of God in us. I mean we had people hadn't hadn't really liked some of the things we built for a while. So I think that you know we were kind of all in on it and very focused. But what did we learn from that? Um, I think that we\n\nwe learn from that? Um, I think that we learned kind of the first initial set of AI features where, you know, when we started, I think that there was just one key command and it pulled up this like universal remote in the editor and then you asked it to do something and then entirely the AI would just figure out, oh, do you what what what exactly do you want it to do? um you know, do you want something back that's like a chat response or do you want um like a code suggestion that you can then take or do you want it to go search around your codebase and answer a question or do you want it to go spin for a really long time or a short time and there wasn't a lot of control and I think that we learned you know given the tech of the time um at the end of 2022 that you actually it has to the form factor has\n\nactually it has to the form factor has to look a bit different and so we learned kind of the first early AI features that then became part of the core of cursor from iterating both for ourselves and also giving it to people. I think another thing we learned was, you know, we were very rapidly building a feature version of what we want in a normal code editor plus then some AI stuff that we thought was great. But then, you know, a feature complete code editor for the world, um, is going to be a way, way, way longer road. We thought that, you know, FS code had been developed over the course of 12 years, was one of the earliest TypeScript projects, um, had lots of people on it. Thought, oh yeah, of course, you can kind of spin something up that's just equivalent for the world in in a few months. And I think that we learned very\n\nmonths. And I think that we learned very rapidly that that wasn't the reality and our time was going to be best spent just focused on the AI stuff. And so similar to how browsers often based themselves off of Chromium's rendering engine, we then switched to being based off of VS Code. The other thing is you guys had also implemented your own models too. Like back then you got a lot of inspiration from uh codecs, right? Mhm. Yes. So when we were setting out to work on uh you know our our first idea that we really spent a bunch of time on which was trying to help mechanical engineers be more productive using AI uh one of the things when we raised our first round of funding because we we actually kind of needed money from the get-go to do a little bit of model training because you couldn't bootstrap\n\ntraining because you couldn't bootstrap it with the models that existed off the shelves. They weren't good enough at that task. One of the papers that we would tout around is actually the original Codex paper u because by our calculations codeex which was the first this was the first autocomplete model behind GitHub copilot it didn't really cost that much money to train even though even back then at kind of the beginning and middle of 2022 people were talking about how expensive AI models were to train I think it cost uh my math might be wrong but I think it was about 100k in training costs and then you know during this fay into mechanical engineering we had done our our own training and then uh when we set off on cursor. I think we were a little bit burned by that. And so we wanted to be as pragmatic as possible, not to\n\nas pragmatic as possible, not to reinvent the wheel. And so we started by doing none of that. And then over the course of 2023, you know, in dialing in the product, that ended up being a really important product lever, especially as we got to scale and we got a bunch of people using the product. And then that also gives you the ability to use product data to make the product better. And so that actually has been a really important uh muscle to build in the company. YC's next batch is now taking applications. Got a startup in you? Apply at y combinator. com/apply. It's never too early and filling out the app will level up your idea. Okay, back to the video. What happened then in 2023 was when you were still not sure about whether cursor was going to be a thing, right? You were still debating with your co-founders\n\nstill debating with your co-founders whether you should still pivot. It's like, oh, is this idea still going to work? And you were still trying to grow it, right? Because it took a long time to to get to revenue, right? Yeah. I think that over 2023 it uh it was growing the numbers were kind of small and I think that also we were working on something where there wasn't always a clear next step. Um I think that there are probably some markets where you're really well served by going immediately talking to a bunch of people listing down their problems really rigorously or you know really kind of systematically and exhaustively thinking through each problem what would kind of be the direct solution and then prioritizing them and then going from there. Um, but I think that we were and are in a space that's that's a bit bit\n\nare in a space that's that's a bit bit different than that. You know, I we're this end user application that doesn't have much of a complexity budget. We are trying to uh build the best way to code with AI. And so a lot of that is figuring out, you know, given the tools that you have today, what can you actually do? There's a lot of things that you could write down that that would be useful if you could build them, but then, you know, figuring out how to build them and all the details. It's not entirely clear how to move forward on that. And so yeah, there were a lot of times over the course of 2023 and then you know actually also to add to this of our early user base if you just kind of followed the gradient of exactly what they wanted you would get pulled in slightly different directions than we\n\nslightly different directions than we ended up in. You know we had a really loud segment of users that didn't know how to code at all and we talked about you know should we focus on those folks. We had a really loud segment of users that wanted us to do things that were very techstack specific. Um, you know, just building for one technology and making it much less of a horizontal tool and we resisted doing that too. There was a lot of early prototyping and uh kind of wandering the desert in 2023 and then you know figuring out things around you know where does it make sense to not just build the software but also build our own models to improve the API models or or to replace them in places like you know for instance with our our tab you know our next edit prediction and then how exactly to do that.\n\nhow exactly to do that. You went from zero to 1 million around 2023 right and it was uh it took it took a lot to get there right? Um, yeah, it was a a bit more than that, but sort of roughly that that And then 2024 was a crazy year. You guys went from one to 100 million in one year. Tell us about this uh loss of uh compounding power because you kept that growing 10% week over week. How did that happen? So, the numbers felt small early on, then the compounding kind of kept going. I think that there were a couple of things that really drove our growth. Um, we're in this market where if you make the product better, you kind of see it in the numbers immediately where, you know, things start to grow more. And so we felt it around, you know, when we first started to make cursor codebase aware, when we first started to, you\n\naware, when we first started to, you know, be able to predict your next action, when we made that then more accurate, then when we made that faster, then when we made that more ambitious, um, you know, it could predict sequences of changes, and then when we let the AI model start to take more action within your codebase and then do that really fast, you know, speeding that up. And so all along the way, um, you know, I we kind of just focused on making the product better. the compounding continued. Um, and I don't think that this is true of all markets, but I think we're we're in a market where end user preferences matter a lot. And if you make the best thing, people hear about it and talk about it. And that kept going for, you know, a long time. I think one of the funny things that a lot of that that's happened around that time\n\nof that that's happened around that time we did see a big shift in the YC companies as they were going through the batch because we would ask what what kind of tech stack you use to build your applications and it was night and day from one batch to the other. I remember in 2023 I think it was maybe single digit percentage of the batch would use cursor then 2024 it was like 80%. It just like spread like wild wildfires like the best builders were using you got onto their Twitter feed. Yeah. The Twitter feed. Was that where a lot of adoption? How how did all the growth came from? So the the very early stages when we were first launching the editor we uh tried to kind of evangelize it on on social networks and actually my uh one of my co-founders when kind of the the dopamine hit keeping him going in\n\nthe dopamine hit keeping him going in 2022 when we were working on some of these ill- fated ideas started posting on the internet and kind of explicitly set out to try to gain a lot of followers not by doing kind of normal social media things but by talking about AI actually it was kind of surprising you know, the degree to which someone could actually just read kind of all the papers, think kind of deeply about what was going on at the time, talk about that publicly and then get recognized by influential people in the space. And so there was like this particular um open- source model, Flynn T5 at the time that multiple uh AI efforts that ended up using that model. They found out about, you know, kind of the benefits of that model directly from my co-founder just because he was posting on Twitter and doing that\n\nhe was posting on Twitter and doing that kind of consistently. But he became like sort of niche, very niche, like sort of niche niche niche of SF micro celebrity. He would actually kind of evangelize the product early on. And so we had this kind of very movie magic demo. Um, you know, when we when we first launched and when we first did a wait list to just get our initial batch of users. I think that that was helpful getting the, you know, us kick started. But then after that, we kind of stepped away from that and we kind of lived like monks 2023 and just focused on the product. And it it really just spread from word of mouth. I remember there were a couple of times during that year where there were members of the team that would say things like, \"Guys, the product's already good enough. Like, let's put it\n\nalready good enough. Like, let's put it aside. Let's just focus on growth engineering. \" And um then there would be like a two-month sprint on, you know, doing some version of that. uh and it just never it kind of washed away compared to the to the other stuff that we worked on that year. And by that time um in 2024, how big was Kurser? How many how big was the company at that point? Uh it was pretty small in 2023 where my co-founders are are fantastic engineers and so and there were four of us and so we could go uh pretty far without hiring anyone. We also had our own, you know, set of missteps and figuring out the first set of people to hire and how exactly to do that. And um so we're both very patient early on and also, you know, focused on hiring a lot less than we probably should have early on. Um I\n\nwe probably should have early on. Um I think we ended at only single digits people. Like we were less than 10 still. Yeah. Amazing. So, so no, I guess one cu curious uh now shifting gears a little bit about what are your thoughts in terms of how the future's going to look with uh coding. We were kind of this this maybe middle road bet from the start where when we set out to work on the company and we were kind of hiring our our first people, we would get these weird looks around, you know, why are you I mean at the end of 2022 it wasn't really like this, right? because kind of catchy happened and then the whole world woke up to things, you know, beginning of 2023. But especially during 2022, uh when we were working on the CAD stuff and then the early code stuff, um people thought working on AI uh was it was kind\n\nthought working on AI uh was it was kind of weird to do. People were not entirely convinced that it was a good use of time and that there were going to be lots of great applications to fall out of AI. And then even the people who were interested in AI, there was I in our space, you know, a bunch of people that were just focused on optimizing kind of the form factor that existed already um and just making those products a little bit better. And then at the same time, you know, in our social circles and professional circles, there's a bunch of people that, you know, we're thinking, oh, why would you work on anything other than AGI? And, you know, all of the work that you're doing right now in one or two years, you know, circa 2022 is going to go away. And yeah, I think that we've always had this view that there's going to be lots\n\nthis view that there's going to be lots and lots of um incredibly valuable things to build over the next couple decades. AI is going to be this transformative technology. Uh maybe more so than you know any revolution in recent technological revolution in recent centuries, but it's going to take a couple of decades. And it's going to be this industrywide effort where there are all of these independent capabilities that each need to fall to really get to you know a place where you can entirely get to the end state of uh transforming building software on computers or kind of the other areas of knowledge work that might be transformed by AI. And yeah, I think concretely kind of in the near term um we think that for professional engineers, which is the end user we serve, uh the market that we serve, um\n\nserve, uh the market that we serve, um you know, code is still really important and uh there will be this long messy middle where um you will be working with the AI more and more it will become like a colleague more and more. It may also become like a you know a very advanced compiler that can start to hide some of the code for you. You're going to have to read the logic and um yeah, and review it and and edit it. So, and what do you think are the skills that are still going to matter? What should everyone still be studying or stop studying? I mean, I think that programming like math is kind of just a good general education. Um, and I don't think that that goes away. And I think that there's also lots of practical skills that comes from studying computer science right now. I mean, often when people are kind of\n\nmean, often when people are kind of entering dynamic industries, the like specific stuff that they they study in school uh isn't super crucial. It's more the kind of learning that they get along the way. I don't think that's changed with AI. What advice do you have for the audience? If you have like a young Michael Trello, maybe not just three years ago, they want to be like you three years ago before they start cursor. What should they be doing right now? I think just working on things that you're interested in and uh doing it with people both that you enjoy being around but that you respect a ton. Uh and taking that really seriously. Yeah, I think that for a lot of people that are in school, it there's so many things that pulls you toward um more checking boxes and less, you know, uh focusing on building something up\n\nuh focusing on building something up over time uh and really focusing on on something that you're that you're interested in. All right, let's give it a round of applause to Michael. Thank you so much. Yeah, of course. Thank you for having me.\n"
    },
    {
      "speaker": "Dylan Field",
      "title": "Scaling Figma and the Future of Design",
      "date": "2025-08-08",
      "source_url": "https://www.youtube.com/watch?v=-7Qz7tSTfUU",
      "transcript": "Designers need to be founders. We need to have folks that are designers step into the founder role and start companies. It feels intuitively like we're in the MS DOS era of AI right now. If you look back 10 years from now, everyone's going to go, can you believe that we just had this chat box? Awesome. Well, um, want to welcome Dylan. Um, I'm curious what the makeup of the audience is here. How many people um have used Figma before? Wow. All right. Awesome. How many people consider themselves to be designers? Okay. All right. Many of us. Yes. Our people. And uh how many are currently founders? Cool. Okay. That's a a good mix of people in the audience. So, we'll hear the Figma story. Then we'll talk about um advice around AI and design. Um and then we'll get some advice on uh just being a founder from Dylan too. So I'm\n\nbeing a founder from Dylan too. So I'm excited to jump in. Um maybe to start uh give us kind of a snapshot on where Figma is today and then you know we can kind of go back to the uh the beginning days. Yeah. Uh today we are uh many different places. We're hybrid uh 1, 700 people now which is wild. I have to pinch myself on that number. We have eight products now. We just doubled our product lineup at our last config. So um very excited to hear feedback if you got any on things like Figma make sites draw uh buzz. Um but it's been a very exciting time. Uh lots of work we're doing as we explore all the things that we can do to help our audience. And now take us back to uh maybe 19year-old Dylan uh getting started with the the kernel of the idea that eventually became Figma, but it wasn't a straight line getting there. Tell us\n\nstraight line getting there. Tell us about the early days and kind of how you and Evan got started. Yeah. So, in the early days of Figma, well, I guess before it was even Figma, Evan and I were at Brown together, uh, he was my TA and we were asking ourselves the question of why now? Like what's changing the world and the two answers that we came up with that we also felt deep conviction in, one was drones uh, and quadcopters. Other one was WebGL. And uh Evan after about a month or so said hey like not into drones uh for all sorts of various reasons. That was kind of the one I was pushing for more at the time also except WebGL of course. And then uh I was like great WebGL it is. And so WebGL I think everybody probably here knows but is a way to use the GPU in your computer and the browser. Uh web\n\nin your computer and the browser. Uh web GPU is its successor. And yeah, we uh started going really deep on like what are all the things that we can build and two main paths were games or tools pretty fast. We said okay not games let's go tools and then it was a deep exploration with many twists and turns as we explored all sorts of tools that we could build and uh you know it took uh we really started in earnest August 2012 uh whereas we started talking about it more December of uh 2011 so it took a while to get to the point where we started and then from there I would say it was at least June or July of 2013 before we went all in on okay let's build Figma as it is today and even then there was still a bit of a narrowing path to get to the product that exists now. And when you first started, were you\n\nAnd when you first started, were you thinking about this as a startup and a company that you wanted to build or were you thinking about it more as like a project that you wanted to do with your friend? No, it was definitely the hope was startup uh and startup that could scale at the same time. My downside case was I get to work with Evan who I considered then consider now to be a hero. He's like the smartest guy I know. Uh if you have any doubt about this statement, just look up his GitHub. Uh he he's an amazing man and an absolute genius. And I figured worst case scenario, I spent a few years working with Evan. I learn a lot. Then I go back to school, same place I'm at now, can't hurt. Uh upside case, we go build a cool company. All the problems that we were thinking about working on were very very interesting to\n\nworking on were very very interesting to me. And so I didn't really see any like risk to the scenario. And also it helped that I had the Teal Fellowship. Uh, I would have done it without it, but like having 100K over two years, I know now, you know, inflation, etc. probably sounds like less than it was then, but yeah, I mean to have actual cash and not have to dig into savings or go into debt, huge deal. Not just because of the cash element, but also because it gives you time. Uh, if we had stopped six months in and that was our point where we made a call, Figma would not be here today. And so I think if you're a founder already going or you're thinking about founding, you got to give yourself time somehow. That's really important. Yeah. You spent a couple years trying to, you know, do all the twists and\n\nto, you know, do all the twists and turns and the thing that eventually became what Figma um is today. Yeah. Um what kept you going in that time? A lot of times, you know, founders will get into this like pivot hell of jumping from idea to idea and motivation just keeps declining. And how did you keep yourselves motivated during that time and feel like you were on to something and you were on the right track? Well, I mean, first of all, just working with Evan was super fun. You know, we're kind of thinking through ideas by building them. It felt every week like we're kind of inventing the future in some way. At some point, I kind of went, \"Memes are going to go to the moon. \" And I convinced Evan, hey, let's go build a meme generator. And this is, you know, 2012 time frame. And we built a great\n\n2012 time frame. And we built a great [&nbsp; __&nbsp; ] meme generator. I think it was for sure would have been the best one in the market. Uh, and my thesis was right, by the way. Look at the exponential curve of memes since 2012. Yeah. uh we would have made some money there. At the same time, after a week of that, I think both of us were ready to quit. I was asking myself like, why'd I drop out of Brown for this? That was probably like a pretty low point at the start. But other than that, there's the constant existential nature of asking yourself like, what are we doing? What's the big goal here? when you're in that phase of really trying to discover what to work on. But I think if you've got a co-founder, you got a collaborator, you're not just alone, you know, hopefully your highs and their highs,\n\nhopefully your highs and their highs, your lows, their highs cancel out somehow and you can kind of feed off each other to keep each other going. That really helps. That's cool. Once you kind of came up with uh the idea for Figma, how did you get your first users? Yeah. Um really the first users of Figma uh a lot of it was cold emailing and uh people in network so folks that I had either interned with for example I entered at Flipboard, LinkedIn uh O'Reilly Media and from that there were people I could reach out to. They could tell me others to talk with but also I just looked online like who are the designers that I think could be really helpful to us and I respect their work. you know, if they answer my email and they let me buy them a coffee, like it'll just be like a personal moment for\n\nit'll just be like a personal moment for me because they're my hero. And a lot of them replied. Like, it's kind of wild that people reply to cold emails, but they do. And so, uh, yeah, I I went there and then it turns out designers give great feedback. So, it wasn't just like meeting them and them saying, \"Yeah, your product sucks. \" They'd be like, \"Here's exactly why it's not great, and here's what you can do better. Here's what it would take for me to use this. \" And uh the more that I engaged and we worked through that, the better the product got. I'd follow up with them and eventually they started converting. Some of them took a while before a lot of them converted. Later on we kind of went on tour. I met at this point we had venture investment the venture firms that invest in us. They invested in other companies too. I had\n\ninvested in other companies too. I had them make introductions to the companies. You know for an entire summer I basically met with I don't know five, six, seven companies a week at least. um sitting down with them, sometimes several a day, saying, \"Hey, here's a demo. Will you use it? If not, why not? \" And uh very low conversion rate. I think like in that entire summer, maybe two of them went in for it and actually started using Figma. Uh one was Notion, the other was the company that became Kota, then called Krypton. and uh kind of interesting they're both you know these cloud-based document tools with very similar philosophies to us but you know you then launch it and people start using it more there's a lot of folks out there that resonate with the message so it was a it was a slow arc over time but\n\nit was a it was a slow arc over time but the the constant was feedback getting feedback to the team making sure we understood what problems we need to solve that's interesting because you know everyone tells you to launch early and the reason to launch early is to get that feedback and from the outside it looks like you took a long time to launch but behind the scenes you were actually talking to tons of users and potential customers and getting feedback constantly like how did you think about when was the right time to actually launch the product? First of all I like definitely echo the point of launch as soon as you can. If you take anything away from this it's don't do what I did. Uh you know get your product out faster and charge money faster for the product to see if you actually can make money. Uh, unless you\n\nactually can make money. Uh, unless you have some genius galaxy brain consumer thing you're doing, in which case figure it out yourself. I I don't know what to tell you. I think that the feedback is essential and uh you should launch as quickly as you can. For me, the feedback was very clear. It's not ready and that made it so we didn't feel comfortable launching yet. But looking back, we did have the capital. I should have scaled the team faster so we could move faster and get it out quicker. That was something that I now looking back have learned. And when a team at Figma comes to me with a epic road map that they think is perfection, the first question I always ask is how do we slim slim that down? How do we make it more bite-sized and test this earlier with our users? So, it's it's absolutely the case that I\n\nSo, it's it's absolutely the case that I try to push people internally towards, you know, a one month or three month cadence uh at most. You know, if someone comes to me with a 9 month, a 12 month, two-year cadence, it's like, what the [&nbsp; __&nbsp; ] are you doing, man? Yeah, that's such an important point, especially for small teams, which is a lot of times people are like, well, I have all this stuff I have to build, so I need to go hire a bunch of people to be able to do it. But it seems like usually the right answer is like, how can you scope it down and do fewer things really well? Like it sounds like is that part of your culture as you're building things? Yeah, it's constraints can actually really help. But I also think the startup equation or not equation, but the cycle that you're always in is something along the\n\nyou're always in is something along the lines of if you're the leader of a startup, you need to be identifying what you're doing the most of. Uh figuring out how to get someone else to help you with do that or maybe in the future it's AI, who knows? But then from there, okay, how do you like go find that person? And if you don't have enough resources, how do you get the resources? Right? Right. That's a cycle that you're always in. It just turns out that actually having constraints, it breeds creativity. It breeds interesting ways to solve problems. And so, yeah, I think they're useful. What was the inflection point? I don't know. Was it shortly after you launched? Was it years later? Was it a few weeks ago when you actually believed this was going to be a huge company? Oh man. I think uh the point at which I\n\nOh man. I think uh the point at which I started to believe that actually this might be real was way later than our users did. People were telling me, \"This is amazing. I'm really excited. Here's my 12-page doc on all the things that I want you to do for Figma. \" Uh, I should have known then, even though our product was really bad, that there was something there. But in reality, it took until Microsoft told us, \"Hey, this is spreading like wildfire, and we're asking ourselves, should we shut it down or uh, you know, should we keep going? \" And the reason we're asking ourselves that is because you're not charging us. Maybe you should actually charge for the product. That was the moment that I was like, \"Oh, I think something might be working. We should probably charge people. \" And that was like five years in. So, yeah,\n\nthat was like five years in. So, yeah, don't do that. Um, and also listen for when people are uh pulling the product out of you. Like, I think everyone talks about product market fit, but product market pull is really important. And you'll see signs of it when people are highly engaged, when they are obsessive about what you're doing, when they see the future of the vision that you're planting, uh that is a sign that you should really double down and in whatever way you can. And so many people interpreted instead as, oh man, if only we had all these things that they're asking for, then we might have product market fit. Guess we got to grind for a long time and who knows if it'll work. the right mindset is, oh my god, they actually care enough to give us this feedback. This is huge. Uh, and I think\n\nfeedback. This is huge. Uh, and I think that people misinterpret that too much. It seems even your feedback seeking early on in the early days, I think a lot of people are nervous to do that because they don't want to hear that it's not good enough and, you know, they don't want to hear the thing that they poured so much time and energy into um, is not good yet and I would not use it and I would not pay you for it and so you want to just hide from that. How did you shift your perspective to actually want to seek that? I I think maybe it's just like childhood for me. When I was growing up, I was a child actor. Uh not like a a child actor that got into like anything really cool that you know about like commercials and some TV and stuff. But as part of that, you audition constantly. Uh and basically you constantly get rejected.\n\nbasically you constantly get rejected. Uh for me that was not a big deal. Like I was used to rejection and I had fun with the process of it. So yeah, I think for me it's just maybe a different mental equation than others. But yeah, if you're not there yet, like seek rejection, it's got interesting data in it. Don't you want to know the data? Switch gears. Talk about design for a little bit. It's been a really great month for design. It feels like been pretty wild. Yeah. I mean, we've had some popular redesigns from Airbnb and Netflix. Yep. We've had um Apple's new liquid glass UI, which seems to be somewhat controversial. I'm sure there are opinions out here. at least there was opinions on X or Twitter or whatever. You guys had some incredible launches um at um at config recently and you know at\n\nat um at config recently and you know at YC we have kind of a call for more design founders and then maybe the most um surprising and impressive thing was uh OpenAI acquiring Johnny Ivan his company for more than $6 billion which is pretty crazy. So I I'm curious like why now? Like what is happening in this moment where it seems like design is is really a part of uh the conversation in a lot of the tech world. Yeah. I mean I first of all I think that in some ways it's new, in some ways it's not new. Design has I think been growing in importance exponentially over the past decade. At Figma we see it up close every day. Uh more designers being hired. design going from, you know, lipstick on a pig, make it pretty at the end of the process to let's deeply think about how it works every step along the\n\nabout how it works every step along the way. That's been a mindset shift that's been ongoing. But now, I think in this age of AI, if you really believe that development gets easier and it's more simple to create software, it's faster to create software. Then like what is your differentiator? It's design, it's craft, it's attention to detail, it's point of view. What we're seeing is recognition of that. I mean, Airbnb, they literally said our differentiator is design. Yeah, I think Brian said that. I believe that, you know, there's lots of takes on Open AI and uh this more than $6 billion transaction. Uh some people are like this is the stupidest thing in the world. Other people are hailing it as like absolute genius. I guess my mental model is there are some people out there who when they do something you don't\n\nwho when they do something you don't understand uh it's easy to go into an attack mode and just dismiss it. But over enough time, sometimes you see patterns and you're like, \"Okay, I've consistently not understood what this person's saying over the course of like years. \" And uh you know, years later, I go back to it and I'm like, \"Oh, what I said in response to what they did was just wrong. \" And then you kind of do this mental flip of, okay, assume that there's something to learn from whatever they're doing. assume you're missing something. And I think that I look at something like OpenAI and some part of I understand. Design is differentiator. Some parts I don't understand. Like that's a really big transaction. Uh but Sam is one of those people that, you know, he's he's right about a lot of\n\nknow, he's he's right about a lot of stuff. So I I would encourage you if you just dismissed it outright to ask yourself what you might be missing. And you guys launched some uh really cool AI focused products at uh your conference config about a month ago which has been really cool to see the reception there. Um really positive from a lot of your users and the design community. Um I'm curious if you can share more about those and and your motivation for building some of those. If you look historically at the products we've launched for Figma, the pattern is we notice behavior happening in Figma Design. We take it out of Figma Design and make it its own product. And therefore, Figma design is able to be what Figma design wants to be, a product design tool. And you know, whether it's Fig Jam or whiteboarding brainstorming\n\nFig Jam or whiteboarding brainstorming tool, the first new product we launched that we can make a dedicated space for and make it be everything it needs to be or it's slides where we saw, okay, 5% of files created uh in Figma Design or slides. So great, pull that out, make a slide tool because there's all the stuff you need for slides that if you put it in Figma design now you've got a complicated UI and oneplus 1 is not equal to three is more equal to like 1. 5. A lot of the things you saw launch at configure in that category. So uh draw for example which is a way to do more uh vector tasks we made a separate mode for uh so that users can go deeper because again if you believe the craft is differentiator more people want to be more expressive. How do we enable our customers and designers everywhere to do\n\ncustomers and designers everywhere to do that on the Figma platform buzz same thing you have all these people that want to create uh mass exports and figure out ways to create production graphics. So, if you got a brand team and they've created templates, uh, how do you make it so that you're able to then empower a marketing team to go use those templates and do mass creation of assets? That's like a core workflow we see all the time. But we didn't want to uh make Figma design more complicated or dumb it down. And so, instead, you make a new surface. Uh, sites, we see people designing websites all the time in Figma Design, but they have to go somewhere else to actually build the site and get it out there. So, how do we get that so that they can actually ship it? And then make, uh, we're so excited about make.\n\nmake, uh, we're so excited about make. This is a tool that lets you go from prompt to app. And it's already changed a lot of how we do work at Figma in terms of quickly prototyping and being able to get to the point where you throw ideas away faster. And with Figma make, there's so much more that we want to explore and are really excited to explore there. So, yeah, stay tuned on that one. Cool. Yeah, I mean you just touched on it there, but it feels like a lot of the line between design and development is getting blurred and they used to be very distinct phases in a product development process or parts of an iterative cycle and now it feels like you know they're almost being combined into one. How do you think about that with the tools that you're making and and I'm also curious um maybe how that process has changed like how\n\nhow that process has changed like how your own development process has changed within Figma? I'll start with Figma. Uh, I think that for us it's all about speed of iteration, speed of testing ideas and tools like make really help with that. It helps to have ways to rapidly prototype and to figure out what's going to work and what's not going to work and make that as low cost cost as possible. And then there's tools I can't talk about and things we're developing that uh have been pretty instrumental to how our development process is changing. Um, so yeah, can't wait to talk about you with them, but not today sadly. Yeah, when you go back to just the way that design and development are blurring more, um I think it there's a lot of stuff going on there. I think product is also blurring with design and\n\nalso blurring with design and development and potentially even parts of research. All this is becoming less distinct and uh it's all kind of coming together more. I think this is happening before AI, but it's happening even more with AI. There's something about AI that empowers generalist behavior. I will say that I think that the models today are better at the earlier phases of development than they are at like late stage code bases. Um, so if you have an established codebase, I think you're going to get less out of uh AI development tools as they currently exist than if you're at the very start. So I think that everything's better suited for prototyping and sort of like zero to one than it is from one to 100 uh at this current moment. But you know, in a week this could change. Yeah, it changes so\n\nthis could change. Yeah, it changes so fast. Yes. Um I mean related to that, how do you expect user interfaces to change uh over the next couple years? And feels like chat has kind of become a lot of the dominant uh interface paradigm, but I don't know, it feels like there's got to be something better that comes along, right? Yeah. I think that it feels intuitively like we're in the MS DOS era. Yeah. Uh of AI right now. and that you know if you look back 10 years from now everyone's going to go can you believe that we just had this chat box and yet I think the problem of how do you show users all the things that are possible to do with these models is a very hard challenge and um there's something about the experiments that have worked there that's very interesting so for example look at midjourney you know they started\n\nlook at midjourney you know they started off in discord where you can rapidly see all the other things that people are doing and that was in many ways is a way to show people what's possible or even Meta's new AI app. Uh there's been a lot of press cycle and whatnot about the public aspect of people sharing accidentally things that are quite private. But the flip side of that is you actually learn what you can do and so I think that's been underexplored uh in the media. So I I I think that there's this problem that people have not solved of like how do you expose capabilities of of these models and there's so much that needs to be developed and worked through there. Yeah, I think it there's a lot to come. On top of that, everything will be more contextual uh AI as you blend it in to different applications. That's a really\n\ndifferent applications. That's a really interesting layer to think about and on top that we're going to have so many new surfaces as well. the surfaces that will exist are not going to be just like your phone and your laptop and your tablet and the thing you know it's going to be glasses uh we're going to see much more um in terms of uh different types displays that exist throughout your life so the surfaces are going to multiply AI will have context all of it will be a layer you have to intersperse and that is a a really interesting challenge for design of how do you reconcile all that keep it consistent and actually be able to navigate that whole broad spectrum that people expect you to show up on. YC's Next Batch is now taking applications. Got a startup in you? Apply at y combinator. com/apply.\n\nApply at y combinator. com/apply. It's never too early. And filling out the app will level up your idea. Okay, back to the video. How many of you um consider yourselves to be researchers or have done research work? Yeah, it's a it's a lot of people in this audience here. And I know you've done this internally, you know, at Figma and and building your own models. Um, what is the role of design um in in research and the research work that you've done? Um, and you know, what are some of the design decisions that go into actually like making them better and and making them work really well? I mean I think that a lot of researchers uh are sort of trained in an academic environment and come at problems as abstractions and they try to think very generally and I I think if in some research like if you're doing pure math\n\nresearch like if you're doing pure math like keep going that is definitely the way to approach it if you're doing more research that's applied uh for example in AI I I really do think that thinking like a designer can be helpful and working with designers can be helpful We found for example that embedding designers into our research teams because obviously we're doing a lot of work on how do we make better AI tools for designers uh is been critical because researchers need that intuition of how designers think and without actually having that close collaboration it really doesn't work. Now you might say in response well yeah that's nice but you're building for designers. My maybe response back would be well uh it's it's the case that designers have this mindset of you're building for an audience. Maybe it's a general audience.\n\naudience. Maybe it's a general audience. Maybe it's a specific audience. That audience has a problem or a set of problems they're trying to solve. And that sort of thinking I think is very useful to bring into the research context. And also qualitative research needs to pair with uh more deep AI research as well. the more that you can actually surface through qualitative methods what people are actually trying to do and how they perceive and think, the more uh you can advance. So yeah, I guess my push for anyone who's coming from more of a research background would be go get in the field, go talk to people because you'll learn from it and it'll actually make you go faster and some of the ways that designers have learned and some of the tools that designers have are likely useful for you. Yeah, it's it's like that Steve\n\nyou. Yeah, it's it's like that Steve Jobs quote that, you know, design isn't just how it looks, it's how it works. Yep. Um it feels like, you know, when you're building models and doing research, you're trying to make a thing like that is the how it works. You know, you're trying to define that and that is the core function of a designer that may not be obvious to how people view them from the outside. I'm curious what you think the role of designer looks like over the next decade. It seems like it's shifting a lot and you know design and development seems to be you know drawing closer together and there's all this research where design can be involved. How do you think that role changes? I'm really excited about how this will evolve. I think that designers uh will have far more leverage in the future and\n\nhave far more leverage in the future and the value of design will only continue to go up. I mean your RFP uh request for proposal for designer founders I think embodied this. You said uh designers need to be founders. We need to have folks that are designers step into the founder role and start companies. I know that it's been uh looking back you know you got Brian Chesy, you got Ki at linear. We have so many designer founders that you can point to now and say wow uh these folks are really successful and are are killing it. But I think that the number of designer founders will multiply. I think the number of designers that are leading large areas and sort of GMs will grow as well. And in general, uh designers will be looked to as experts inside of companies that in sort of the same way that you might have a writer today who\n\nthat you might have a writer today who is the expert and like the best writer in the company or the best editor uh but everyone has a word processor and can write. You'll have a designer who might be the best at problem solving and thinking through how do I actually craft a solution and explore this idea maze and figure out which direction to go create a system around it. But I think most everyone in the company will be contributing to that process of design and so there will be a lot of curation involved and a lot of leadership will be needed from designers. So they have to step up. I'm curious what are some of the most interesting ways you guys are using uh AI internally at Figma? Yeah, I mean can't talk about it all like I said uh since some of it is like products that we'll be releasing. But maybe one thing\n\nwe'll be releasing. But maybe one thing I'll say is on the designer embedded in the research side point uh it's been fascinating to see just how important it is for designers to uh contribute on evals. So if you think about it uh as you're you know doing a developing a model or you're developing research ideas you have to have good evals and usually the researchers are the ones building those and I think that's kind of just the wrong model for us at least designers my point of view is that they should be contributing to eval product people they should be contributing to evals it's not something that you need your engineers and your researchers to do because they probably have less understanding of the end user less contact with end user than your designers do your product people do. So, uh, as you design these models, I think\n\nuh, as you design these models, I think eval has become more important, too. And I guess if you were in your 20s today, um, what are some of the skills or tools that you would focus on becoming great at in this, you know, to be successful in this new AI world? The setup of the question is that it's like you should kind of do different things than you did in the past. And that's probably true. But I guess I'd start by saying that I think that the stuff that you know folks have done historically in order to get really good at thinking and work through problems with critical thought uh and learn broadly so they can make mental connections, those are still important. So, I think learning about as many different areas as you're curious about deeply, uh, and trying to experience the world, uh, making sure you're still\n\nworld, uh, making sure you're still relating to people, like those are pretty core things that you should still do. One thing that I'm worried about is, you know, I I think, uh, a lot of people in their 20s these days, uh, apparently, according to the stats, are dating less. Maybe that's true, maybe it's not true. Y'all can tell me later. Uh, but if you think about the future, it'd be so easy to just go talk to your AI model all day. Maybe that gives you a sense of social connection. Like, I would highly advise you don't do that. Uh, I would highly advise that y'all date uh if you're in that cohort. Um, and I even go so far as to say this is less a comment about the products that are in this category of the past, but more about what the future could hold. Um I I think AI boyfriends and girlfriends if\n\nAI boyfriends and girlfriends if developed and allowed to exist uh is a societal self-own. I I think it's like actively poisonous to society if um this becomes the primary a a primary mode of relationship. There's a lot of things that we need to talk about there and have a pretty broad society level discussion about. Well, I don't want to leave it on that before we open up to questions. But maybe um you know before uh we can open up some questions here as people kind of line up. I'm curious um what was the most fun period in the history of building Figma for you? Uh you know maybe is like the answer everyone's expecting but it's true. It's right now. Uh we have like so many things we can do the most brilliant people around to do them with. I love my team. I love the problem set that we have. Uh some companies they go uh\n\nhave. Uh some companies they go uh forward and they kind of tap out and they don't have any more ideas. Like the number of ideas that we have right now has grown so much. There's so much we can do and there's so much people are asking of us and it's more about okay how do we make sure we do the right things and that's a fascinating and really fun place to be. Cool. Let's open up some questions. I'm a founder, product engineer, solo engineer, everything solo entrepreneur at the same times and recently I have started using cursi to handle both coding and design even like down to pixel level details. So what do you think about cursi? Is this cursi can become your one of your competitors and at the same times uh I just recently discover a tools called penpod or giving like developers more control through\n\nlike developers more control through open source uh self-hosted options. What do you think Figma should uh move towards being more open and developer friendly to catch up with the trend of many so engineer become product engineer in the future and more and more solo entrepreneur using cursi to create product in the future. Yeah, I think it's a great question. Um and actually just was uh able to run into Michael backstage that was good to see him. Uh I think that when it comes to AI generation, you know, if you take a step forward from okay, I generated something, the next question is okay, how to make it good? And you know, there's different ways to do that. Uh you can be writing code and going into your browser and kind of having that loop. That's a very structural way to think. Um other people prefer to think\n\nthink. Um other people prefer to think in a more free form way. uh with make we're trying to enable that uh in a way that's visual first rather than code first. You can still get to the code. Um but I really don't think of cursor as a competitor. Uh I think of them as someone that we we just launched our MCP server to explicitly make it so that you can get your designs into cursor and windsurf and all these other NVS code you know all these great tools faster. So I think there's just going to be new workflows that are established and like I said if the differentiator is design then your first generation your oneshot is probably not the thing that's going to win. So I'd encourage you to think a little bit further than that. In terms of open source we actually just announced today uh the acquisition of\n\nannounced today uh the acquisition of payload uh CMS which is an open source uh project and uh I'm really excited about what we can do there and how we can support open source more. Thank you. Hi Dylan. Um my name is Charlie Fearborn. Uh, I'm a game designer here at a startup in San Francisco. Um, and I graduated last year from USC in computer science and game design. Best major ever. So, it's cool to hear about the games roots of Figma. Yeah, we cut it off early. But Evan is also like really was really deep in game design and it's a hard hard industry, but it's a hard industry. Yeah. It's awesome that you're doing it. Um, I have kind of a more personal question for you. Um, uh, what is the meaning of life? um mean of life I think uh you know seek out how to explore consciousness, learn as much as you can uh uh share love with\n\nas much as you can uh uh share love with others and make sure that um you feel fulfilled and the other people around you uh are fulfilled and happy um at the end of the day. And I think that uh that can be something you do on a micro level in your local community, a macro level at scale, doesn't matter. Uh as long as you're living true to your internal values, I think that uh you're leading a fulfilling life. Hey Dylan, thank you so much. Um I was wondering as a designer, are there any specific design principles that you love and use which you think a lot of like builders or companies get wrong or like sometimes even completely ignore? I think the biggest one that I repeat all the time at Figma, uh, which is not my own. It's, you know, has existed for decades is keep the simple things simple\n\ndecades is keep the simple things simple and make the complex things possible. Uh, there's always a wide range of things that you want to be able to enable. But if you try to do all of them and that's the expense of your product not being approachable uh, and not being obvious or intuitive how to use, you're you're kind of messing up. So, I think you have to figure out how to do both, but you start with making the simple things simple. Thank you. I'm Michael. I study HCI and computer science at Colombia. Um, say there's a founder you really respect and you finally landed an enterprise contract and have a decent amount of traction on the project that you've been building with a bunch of friends. What would be the most polite way to show them the product and ask them to be an angel investor? I would send them a a Loom\n\ninvestor? I would send them a a Loom over email. Um, so that way, you know, it's got an async component since time is sometimes hard to find. Uh, they can watch it. Um, and if you want to really peique their interest, mutual connections help. Uh, but like I said earlier, cold emails work, too. Expect a cold email. Thank you. Okay, I'm looking forward to it. And honored, too. Hey, Dylan. Um, I love your shoes, first of all, but um, thank you. Of course. Um, but you said you noticed behaviors when deciding what to productize. And I can very clearly see that. I was using slides for classes. I using Figma for slides for classes before you guys dropped slides made it easier. Using lock layers for social media graphics for my Fred and then Buzz made that so much easier. So I guess my question is how do you watch how people\n\nquestion is how do you watch how people repurpose the tools and what kind of structure do you use for these emerging use cases? It's always a mix of signals, right? You have to do everything from like watching support requests to qualitative interviews, sitting with people and watching how they work, looking at the data and you know actually doing data science analysis on it, you know, looking at what people are saying on social media and more. But it's kind of you digest all those signals and you build some intuition around it and hypotheses you can test. So yeah, it's kind of art plus science but you have to combine a lot of methods I think. Awesome. Thank you. Thank you. Hi. Uh thanks very much for the talk. Um so right now you're helping designers in a huge breath of industries. When you\n\na huge breath of industries. When you just started with the cold emailing etc. How did you go about with defining rise? Was it very broad as today or did you start focused on one industry? No, we really started focused on product design and uh for digital products uh where and I think even more narrowly where people cared about design uh if I'm going to be totally honest rather than like you know the broad world. uh it seemed like it'd be an easier cell. But yeah, I think it required um a lot of sort of slimming down of our ambition to be able to state that clearly. You know, I started off saying we're going to do everything and thankfully the team pushed back and so it got us to here with the ambition of later on doing everything, but I'm glad we started more narrowly. Hi. Um, so my background besides being\n\nHi. Um, so my background besides being like a CS major and whatnot is also in traditional art. Cool. Um, where perhaps AI is not necessarily as popular as the moment. Um, so I guess my question is just how is Figma navigating like ethical challenges of AI and design and like incorporating AI into the products that you are you have available. Yeah, there's so many different ethical challenges you could consider, you know, everything from, uh, okay, you're doing some inference, is it heating up the planet, uh, to the questions of, um, okay, are these models regurgitating something they've seen elsewhere, uh, and beyond. And so I think you have to be very clear about like what you're trying to solve for. But yeah, it's a maybe a sort of escape answer. right now a lot of the work we're doing uh is actually\n\nof the work we're doing uh is actually with thirdparty models and so that's something that we have less control over um as we do more things in house I think these questions are very relevant and things that we'll have to wrestle with like the art world has Dylan uh I'm an HCI researcher and a design founder and as we've been kind of like thinking about interfaces and how we talk to AI it seems that we tend to anthropomorphize things it tends to be that these are probabilistic and we can't design explicitly how we did with like previous hardware. Do you think of AI human interaction as necessarily a tool or how do you kind of like build a mental model around this? I think that there's uh sort of where things are at now, where they're going and you have to kind of consider both. I think that uh there's an interesting\n\nthink that uh there's an interesting split maybe between people that come from a materialist worldview and by that I don't mean like they're going and buying stuff all the I mean the worldview of materialism is one of uh consciousness arises from matter and then on the opposite side of the spectrum is like religious mindsets where people go of course that's wrong like there's god god is great everyone has a soul doesn't have a soul obviously it's like a computer um and so those are like fundamentally at odds and uh my prediction is that we'll probably see an increase in people projecting consciousness onto AI whether or not that's the right uh thing that you know you agree with or don't agree with. I think that the number of people that'll do that will increase. Um and I think it leads to some uh very hard to wrestle\n\nleads to some uh very hard to wrestle with territories. And so yeah, I've been thinking a lot about that. And then in terms of what that means for HCI or uh whatever you want to call it, I I think that that's a very underexplored question and I'm excited to see what you do with it. I think we're at time sadly. Um, but I just want to thank everybody for coming and uh wish you all the best of luck with whatever path you pursue. Thank you, Dylan.\n"
    },
    {
      "speaker": "Anthropic Co-founder Jared Kaplan",
      "title": "Scaling and the Road to Human-Level AI",
      "date": "2025-07-29",
      "source_url": "https://www.youtube.com/watch?v=p8Jx4qvDoSo",
      "transcript": "Hey everyone. Um, I'm Jared Kaplan. I'm going to talk briefly about scaling and the road to human level AI, but my guess is for this audience, a lot of these ideas are pretty familiar, so I'll keep it short and then we're going to do a sort of fireside chat Q&amp; A with uh with Diana. I actually have only been working on AI for about six years. I uh before that had a long career, the vast majority of my career as a theoretical physicist. um working in academia. And so uh how did I get to AI? Well, I I I want to be brief. Why did I start in physics? It was basically because my mom was a science fiction writer and I wanted to figure out if we could build a faster than light drive and physics was the way to do that. Um I also was very excited about just understanding the universe. How do things work? How do the\n\nuniverse. How do things work? How do the biggest trends that underly sort of everything that we see around us, where does that all come from? For example, is the universe deterministic? Do we have free will? I was very, very interested in all of those questions. But fortunately, along the way, uh during my career as a physicist, I met a lot of very, very interesting, very deep people, including many of the uh founders of Anthropic that I now work with all of the time. And uh I was really interested in what they were doing and I kept track of it. And as I moved from different uh among different subject areas in physics from large hadron collider physics, particle physics, cosmology, string theory, um and on I got a little bit frustrated, a little bit bored. I didn't feel like we were making progress quickly enough. And\n\nwere making progress quickly enough. And a lot of my friends were telling me that AI was becoming a really big deal. Um and I didn't believe them. I was really skeptical. I thought, well, AI, people have been working on it for 50 years. SVMs aren't that exciting. Um, that was all we knew about back in 2005, 2009 when I was in school. But I got convinced that that maybe AI would be an exciting field to work on. Um, and I I got very lucky to know the right people and the rest is history. So uh I'm going to talk a little bit about how our contemporary AI models work and how scaling is leading them to get better and better. So there are really two fundamental phases to the training of contemporary AI models like claude chatgpt etc. The first phase is pre-training and that's where we train AI models to\n\nthat's where we train AI models to imitate human written data, human written text and understand the correlations underlying that data. And these these figures are very very retro. This is actually from the playground of the original GPD3 model. And you can see that as a speaker at a journal club, you're probably elephant me to say certain things. is the word elephant in that sentence is really really unlikely. What pre-training does is teach models what words are likely to follow other words in large corporate of text and now with contemporary models multimodal data. The second phase of training for contemporary AI models is reinforcement learning. This is another very retro slide. Um it shows the original interface we used for sort of claude zero or claude negative one uh back in the ancient days of 2022\n\nthe ancient days of 2022 when we were collecting feedback data. And what you see here is basically the interface for having a conversation with very very early versions of Claude and picking which response from Claude was better according to you, according to crowdworkers, etc. And using that signal, we optimize, we reinforce the behaviors that are chosen to be good, that are chosen to be helpful, honest, and harmless. And we discourage the behaviors that are bad. So really all there is to training these models is learning to predict the next word and then doing reinforcement learning to learn to do useful tasks. And it turns out that there are scaling laws for both of these phases of training. So this is a a figure that that we made five or six years ago now and it shows how as you scale up the pre-training phase of AI,\n\nscale up the pre-training phase of AI, you predictably get better and better performance for our models. And this was something that came about because I was just sort of asking the dumbest possible question. As a physicist, that's what you're trained to do. You sort of look at the big picture and you ask really dumb things. I'd heard it was very popular in the 2010s to say that big data was important and so I just wanted to know how big should the data be? How important is it? How much does it help? Similarly, a lot of people were noticing that larger AI models performed better. And so we just asked the question, how much better do these models perform? And we got really lucky. We found that there's actually something very very very precise and surprising underlying AI training. This really blew us away\n\nAI training. This really blew us away that there are these nice trends that are as precise as anything that you see in physics or or astronomy. And these gave us a lot of conviction to believe that AI was just going to keep getting smarter and smarter in a very predictable way. Because as you can see in these figures already back in 2019, we were looking across many many many orders of magnitude in compute, in data set size, in neural network size. And so we expected once you see something is true over many many many orders of magnitude you expect it's probably going to continue to be true for a long time further. So this has sort of been one of the fundamental things that I think underlies uh uh improvements in in AI. The other is actually also something that started to appear quite a long time\n\nthat started to appear quite a long time ago although it's become really really impactful uh in the last couple of years is that you can see scaling laws in the reinforcement learning phase of AI training. So uh a researcher about four years ago decided to study scaling laws for Alph Go. Basically putting together two very very high-profile AI successes, GPD3 and scaling for pre-training and AlphaGo. This was just a researcher uh Andy Jones working on his own uh with like his own I think maybe single GPU back in these sort of ancient days. And so he couldn't study AlphaGo, that was expensive, but he could study a simpler game called Hex. So he made this plot that you see here. Now, ELO scores, I think, weren't as as as well known um back then, but all EOS ELO scores are, of course, is chess ratings. They\n\nof course, is chess ratings. They basically describe how likely it is for one player to beat another in a game of chess. They're used now to benchmark AI models to see sort of how often does a human prefer one AI model to another. But but back then this is just sort of the classic application of ELO scores as as chess ratings. And he looked at as you train different models to play this game of hex, which is a very simple board game, a bit simpler than than Go, how do they do? And he saw these remarkable straight lines. So it's sort of a skill in science to notice very very simple trends and and this was one I think it went unnoticed. I think people didn't focus on this this sort of kind of scaling behavior in RL soon enough but but eventually it came to pass. So we see that basically you can\n\npass. So we see that basically you can scale up the compute in both pre-training and RL and get better and better performance. And I think that's sort of the fundamental thing that is driving AI progress. It's not that AI researchers are really smart or they suddenly got smart. It's that we found a very very simple way of making AI better systematically and and we're we're turning that crank. So what kinds of capabilities is this unlocking? I tend to think of AI capabilities on two axes. I think the less interesting axis, but it's still very important is basically the the flexibility of AI, the ability of AI to meet us where we are. So if you put say Alph Go on this figure, it would be very very far below the X-axis because although Alph Go was super intelligent, it was better than any Go player at playing Go, it was uh only\n\nplayer at playing Go, it was uh only able to operate in the universe of a Go board. But we've made steady progress since the advent of large language models making uh AI that can deal with many many many all of the modalities that that people can deal with. We don't have AI models I think that uh that have a sense of smell. Um but that's that's probably coming. And so as you go up the y- axis here you get to AI systems that can do more and more relevant things in in the world. I think the more interesting axis though is sort of the the x-axis here which is how long it would take a person to do to do the kinds of tasks that AI models can do and that's something that has been increasing steadily as we increase the capability of AI. This is sort of the time horizon for for tasks and um an organization meter studied this very\n\norganization meter studied this very systematically and found yet another scaling trend. They found that if you look at uh the length of tasks that AI models can do, it's doubling roughly every 7 months. And so what this means is that the increasing intelligence that is being baked into AI by scaling compute for pre-training and RL is leading to predictable useful tasks that the AI models uh can can do, including longer and longer horizon tasks. And so you can sort of speculate about where this is heading. And in AI 2027 folks did. And this kind of picture suggests that over the next few years we may reach a point where AI models um can do tasks that don't just take us minutes or hours but days, weeks, months, years etc. Eventually, we imagine AI models or or millions of AI models perhaps working\n\nor millions of AI models perhaps working together will be able to do the work that whole human organizations can do. They'll be able to do the kind of work that the entire scientific community currently does. Um, one of the nice things about math or theoretical physics is that you can make progress just by by thinking. Um and so you can imagine AI systems working together to make the kind of progress that the theoretical physics community makes in in say 50 years in a matter of days, weeks etc. So what is left if if this sort of picture of scaling can take us very far? What is left? I think that what may be left in order to unlock um kind of human level AI broadly construed is relatively simple. One of the most important ingredients I think is relevant organizational knowledge. So we need to\n\norganizational knowledge. So we need to train AI models that don't just greet you with a blank slate but can learn to work within companies, organizations, governments as though they have the kind of context that someone who's been working there for years has. So I think AI models need to be able to work with knowledge. They also need memory. What is memory if not knowledge? I distinguish it in the sense that as you do a task that takes you a very very long time, you need to keep track of your progress on that specific task, you need to build relevant memories and you you need to be able to use them. And that's something that we've uh we've begun to build into into Claude 4 and I think will become increasingly important. A third ingredient that I think that we need to get better at and and we're making progress on is\n\nand we're making progress on is oversight. the ability of AI models to understand sort of fine grained nuances to solve hard fuzzy tasks. So it's easy right now and you see an explosion of progress for us to train AI models that can say write code that passes tests or that answer math questions correctly because it's very crisp what's correct and what's incorrect. So it's very easy to apply reinforcement learning to make AI models uh do better and better at those kinds of tasks. But what we need and are developing are AI models that help us to generate much more nuanced reward signals so that we can leverage reinforcement learning to do to do things like tell good jokes, write good poems, um and have good taste in in research. The other ingredients that we need, I think, are are are simpler. We\n\nneed, I think, are are are simpler. We obviously need to be able to train AI models to do more and more complex tasks. We need to work our way up the y-axis from text models to multimodal models to robotics. Um, and I expect that over the next few years, we'll see increasing uh continued gains from scale when applied applied to these these different domains. And so how should we sort of prepare for this this future these possibilities? I think there are a few a few things that I always recommend. One is I think it's really a good idea to build things that don't quite work yet. This is probably always a good idea. We always want to have ambition, but I think specifically AI models right now are getting better very very quickly. And I think that's going to continue. That means that if you build uh a product that doesn't\n\nyou build uh a product that doesn't quite work because Claude 4 is still a little bit too dumb, um you could expect that there'll be a Claude 5 coming that will make that make that product work and deliver a lot of value. So I think that's that's something that I always recommend is sort of experiment on the boundaries of what AI can do because those boundaries are moving rapidly. The next point I think is that AI is going to be helpful for integrating AI. I think that one of the main bottlenecks for AI is really just that it's developing so quickly that we haven't had time to integrate it into products, companies, other thing everything else that we we we do into into science. Um, and so I think that in order to sort of speed that process up, I think leveraging AI for AI integration is going to be is going to be very\n\nis going to be is going to be very valuable. And then finally, I mean, I think this is sort of obvious for for this crowd, but I think figuring out where adoption of AI could happen very very quickly is is key. Um, we're seeing uh an explosion of AI integration for coding. And there are a lot of reasons why software engineering is a great place for AI, but I think the big question is sort of what's next? Um, what beyond software engineering can grow that that quickly? I don't know the answer, of course. Um, but hopefully you guys will figure it out. So that's it for for for the talk. Um, I want to invite Diana on stage for uh for a chat. YC's next batch is now taking applications. Got a startup in you? Apply at y combinator. com/apply. It's never too early and filling out the app will level up your idea. Okay, back\n\napp will level up your idea. Okay, back to the video. That was a awesome talk about all the scaling laws and recently Anthropic just launched clot 4 which is just available. Curious uh how does it change what is possible as all these model releases keep compounding for the next 12 months? I think that uh we'll be in trouble if it's 12 months before before an even better model comes out. But uh I guess uh a few things with with Cloud 4. I think that with Cloud 3. 7 Sonnet uh it was already really exciting to use 3. 7 for coding. But I think something that everyone noticed was that 3. 7 was a little bit too eager. Um sometimes it just really wanted to make your tests pass. Um and it would do things that that you you don't really want. Uh there are a lot of like try excepts things like that. Um, so with Cloud 4, I think\n\nlike that. Um, so with Cloud 4, I think that we've been able to improve the model's ability to act as an agent specifically for coding, but but in a lot of other ways for search, for all kinds of other applications. Um, but also improve its supervision, the sort of oversight that I I I mentioned in my talk, so that it uh it follows your directions and hopefully improves in in code quality. I think the other thing that we've worked on is improving its ability to uh save and store memories and we hope to see people leveraging that because Claude 4 can blow through its context window with a very complex task but can also uh store memories as files or records, retrieve them in order to sort of keep doing work across many many many context windows. But I guess finally I think the picture that scaling\n\nfinally I think the picture that scaling laws paint is one of incremental progress. And so I think that what you'll see with Claude is that steadily it gets better in lots of different ways with each release. Um but I think that scaling really suggests a kind of smooth curve towards what I expect is kind of human level AI or AGI. Is there some special feature that a lot of the audience here are going to get excited? some some beta that you can some alpha leak you can give everyone on what you think people are going to fall in love with the new APIs. I think the thing that I I'm most excited about is sort of uh memory unlocking longer and longer horizon tasks. I think that like as as time goes on we're going to see Claude as a collaborator that can sort of take on larger and larger chunks of work. This\n\nlarger and larger chunks of work. This is to your point of all these future models being able to take bigger and bigger tasks right now. At this point, they're able to do tasks in the hours. Yeah, I think so. I think it's a very imprecise measure, but I think that right now if you look at sort of software engineering tasks, I think meter literally benchmarked how long it would take people to do various tasks and uh and yeah, I think it's a time scale of of hours. I think just gen like broadly as people work with AI, I think that the people who are skeptics of AI will say correctly that AI makes lots of stupid mistakes. Um, it can do things that are absolutely brilliant and and surprise you, but it can also make uh make basic errors. I think one of the sort of basic features of of AI that's different about the shape of AI\n\ndifferent about the shape of AI intelligence compared to human intelligence is that there are a lot of things that I can't do but I can at least judge whether they were done correctly. I think for AI the judgment versus the generative capability is much closer which means that I think that uh a major role people can play in interacting with AI is kind of as managers to sort of sanity check uh sanity check the the work which is fascinating because one of the things we observe through the batches in YC last year a lot of companies when they were out and selling products they were selling it more still as a co-pilot where you would have a co-pilot let's say for customer support where you still need the last human approval before they would send the reply for a customer but one thing that has changed just in the\n\none thing that has changed just in the spring batch I think a lot of the AI models are very capable to do task end to end to your point that which is uh remarkable founders are selling now directly replacements of full workflows how have you seen this translate to what you hope the audience will build. I think there are a lot of possibilities. Basically, it's a question of what level of success or performance is is acceptable. There are some tasks where getting it sort of 70% right is is good enough and others where you need 99. 9% to to deploy. I think that honestly I think it's probably a lot more fun to build for use cases where uh 70 80% is good enough because then you can really get to the frontier of what AI is capable of. But I think that we're sort of pushing up the the reliability as well. So I think that uh we will see\n\nas well. So I think that uh we will see more and more of these tasks. I think that uh right now human AI collaboration is is going to be the sort of most interesting place because I think that for the most advanced tasks you're really going to need humans in the loop. But I do think in the longer term there will be more and more tasks that can be fully automated. Can you say more about what you think the world is going to look like with this human to AI loop collaboration? because there's the essay from Dario with machines of love and grace that he paints this picture that's very optimistic and what are the details of how we get there with with this book? I think that we already see some of some of that happening. So at least when I talk to folks who work in say biomedical research um with the right sort of\n\nresearch um with the right sort of orchestration I think it's possible to take frontier AI models now and produce interesting valuable insights for say drug discovery. Um so I think that's already starting to happen. I guess an aspect of it that that I think about is that like there there's sort of intelligence that requires a lot of depth um and and intelligence that requires a lot of breadth. So for example in math you can sort of work on trying to prove one theorem for a decade like the threemon hypothesis or firmat's last theorem. Um I think that's that's sort of solving one very specific very hard problem. I think there's a lot of areas of science, probably more so in biology, maybe interestingly in psychology or or history, where putting together a very very large number of pieces of information um across many\n\npieces of information um across many many different areas is kind of where it's at. And I think that AI models during the pre-training phase kind of embibe all of human civilization's knowledge. And so I suspect that there's a lot of uh fruit to be picked in using that sort of feature of AI that it knows much much more than any one human expert and therefore you can kind of elicit um insights putting together many different uh many different areas of expertise say across biology for for for research. So I think that um we're making a lot of progress on making AI better at deeper tasks like hard coding problems, hard math problems, but I suspect that there's a particular overhang in areas where putting together knowledge that maybe no one human expert would have where that kind of intelligence is is is\n\nwhere that kind of intelligence is is is very useful. So I think that's something that I' I'd expect to see more of. Um is sort of leveraging AI's sort of breadth of knowledge. In terms of how exactly it will roll out, I really don't know. It's really really hard to predict the future. Scaling laws give you one way of predicting the future which says this trend is going to continue. I think a lot of trends that we see over the long haul I expect will continue. I mean the economy, the GDP, uh the these kinds of trends are really reliable indicators of the future. But I think in terms of in detail how will things be implemented, I think it's really really hard to say. Are there specific areas that you think a lot more builders could go into and build with these new models? I mean there's a lot that has been done let's\n\nthere's a lot that has been done let's say for coding tasks but what are some tasks that have a lot more green field that are just getting unlocked right now with the current models I come from a research background rather than uh rather than business so I don't I don't know that I have anything very uh very deep to say but I think that like in general any place where um it requires a lot of skill um and it's a task that mostly involves sort sitting in front of a computer interacting with data. I think finance uh people who use Excel spreadsheets a lot. Um I think I I expect law although maybe maybe maybe law uh is is is more regulated requires more uh more more expertise um as a stamp of approval. But I think all of these areas are probably green field. I think another that that I sort of mentioned is how do we integrate\n\nsort of mentioned is how do we integrate AI into existing businesses? I think that like when electricity came along, there was some long adoption cycle and the very first simplest ways of say using electricity weren't necessarily uh the best. You wanted to not just replace a steam engine with an electric motor. You wanted to sort of remake the way that factories work. And I think that probably leveraging AI to integrate AI into parts of the economy um as quickly as possible. I expect there's just a lot of a lot of leverage there. Now other question is you have a extensive training as a physicist and you were one of the first to really observe this trend with scaling laws and it probably comes from being a physicist and seeing all these exponentials that happen naturally in nature. How has that\n\nhappen naturally in nature. How has that training come about with uh being able to perform like the best research in the world with with with with AI? I think the thing that was useful from a physics point of view is looking for the biggest picture, most macro trends and then trying to make them as precise as possible. So I remember meeting like kind of brilliant AI researchers who would say things like learning is converging exponentially and I would just ask really dumb questions like are you sure it's an exponential? Could it just be a power law? Is it quadratic? Like like exactly how is this thing converging? And it's a really dumb kind of simple question to ask, but basically I think there was a lot of fruit to be picked and and probably still is in trying to make the big trends that you see as precise as\n\nbig trends that you see as precise as possible because that I don't know it gives you a lot of tools. It allows you to ask like what does it really mean to move the needle? I think with scaling laws, the the holy grail is finding a better slope to the scaling law because that means that as you put in more compute, you're going to get a bigger and bigger advantage over other AI developers. Um, but until you've sort of made precise what the trend is that you see, you sort of don't know exactly what it means to beat it and and how much you can beat it by and how to know systematically whether you're you're you're achieving that end. So, I think those were kind of the tools that that I think I used. It wasn't necessarily like literally applying say quantum field theory to AI. I think that's uh that's a\n\ntheory to AI. I think that's uh that's a little bit too specific. Well, are there specific uh physics heruristics like reormalization, symmetry that came in very handy to really keep observing this trend or or measuring it? Something that you'll observe if you look at AI models is that they're big. Neural networks are big. They have billions now trillions of parameters. That means that they're made out of big matrices. and basically studying uh approximations where you take the limit that neural networks are very big and specifically that the uh matrices that compose neural networks are big. That's actually been kind of useful and that's something that actually was a well-known approximation in in physics um and and in math. Um that's something that's been applied. But I think generally it's really asking\n\nBut I think generally it's really asking very naive dumb questions that gets you very far. I think AI is really in a certain sense only like maybe 101 15 years old in terms of the current incarnation of how we're training AI models. That means that it's an incredibly new field. A lot of the most basic questions haven't been answered like questions of interpretability, how AI models really work. And so I think there's there's really a lot to uh to learn at that level rather than applying very very fancy techniques. Are there specific tools in physics that you apply for interpretability? I would say that interpretability is a lot more like biology. It's a lot more like neuroscience. So I think those are kind of the tools. Um there there is there is some more more more mathematics there. But I I think it's more like\n\nthere. But I I think it's more like trying to understand the features of the brain. Um the benefit that you get with AI over neuroscience is that um you can really measure everything in AI. You can't measure the the activity of every neuron, every syninnapse in a brain, but you can do that in AI. So there's much much much more data for reverse engineering how AI models work. Now when aspect about scaling laws, they've held for over five orders of magnitude, which is wild. This is a bit of a contrarian question, but what empirical sign would convince you that the curve are changing that maybe we're getting off the curve? I think it's a really I think it's a really hard question, right? Because I mostly use scaling laws to diagnose whether AI training is broken or not. Mh. So I think that uh once you see\n\nSo I think that uh once you see something and you find it very it's a very compelling trend, it becomes very very interesting to examine where it's failing. But I think that my first inclination is to think if scaling laws are failing, it's because we've screwed up AI training in some way. Maybe we got uh we got the architecture of the neural network wrong or there's some bottleneck in training that we don't see or there's some problem with precision in the algorithms that we're using. So I think it would take a lot to convince me at least that scaling was really no longer working at the level of the sort of these empirical laws because so many times in my experience over the last 5 years when it seemed like scaling was broken it was because we were doing it wrong. Interesting. So I guess going into\n\nInteresting. So I guess going into something very specific that goes hand in hand is a lot of the compute power required to go keep going on this curve. What happens uh as compute becomes more more scarce how far down do you go into the precision ladder like do you explore things like FP4 do you explore things like turnary representations what what are your thoughts around that? Yeah, I mean I think that um right now AI is really inefficient because there's a lot of value in AI. So um there's a lot of value in unlocking the most capable frontier model. Um and so companies like Anthropic and others are moving as quickly as we can to both make AI training more efficient and AI inference more efficient as well as unlocking frontier capabilities. But a lot of the focus really is on uh unlocking the\n\nfocus really is on uh unlocking the frontier. I think that over time as AI becomes more and more widespread, I think that we're going to really drive down the cost of inference and training dramatically from where we are right now. I mean right now we're seeing sort of 3x to 10x gains algorithmically and in sort of scaling up compute um and in uh inference efficiency per year. I guess like the joke is that we're going to get computers back into binary. So I think that we will see much much lower precision as one of the many avenues to make inference more efficient over time. But sort of we h we're very very very out of equilibrium with AI development right now. AI is improving very rapidly. Things are changing very rapidly. We haven't fully realized the potential of current models, but we're unlocking more\n\ncurrent models, but we're unlocking more and more capabilities. So I think that what the equilibrium situation looks like where AI isn't changing that quickly, I think is one where AI is extremely inexpensive, but it's sort of hard to know if we're even going to get there. like AI may just keep getting better so quickly that uh sort of improvements in int intelligence unlock so much more and so we may continue to focus on that rather than say getting precision down to FP2 which is very much uh the Jebans paradox as intelligence becomes better and better people are going to want it more not that is driving the cost down which is this irony right yeah absolutely I mean I think that uh yeah that's that's certainly certainly something that we've seen that there are certain uh certain points where AI\n\ncertain uh certain points where AI becomes accessible enough. That said, um I think as AI systems become more and more capable um and can do more and more of the work that that we do, it's going to be worth it to pay for uh frontier capabilities. I think it's a question that I've always had and can have is kind of like is all of the value at the frontier or is there a lot of value with kind of cheaper systems that aren't quite as capable? And I think the sort of time horizon picture is maybe one way of thinking about this. I think that you can do a lot of very simple bite-sized tasks, but I think it's just much more convenient to be able to use an AI model that can do a very complex task end to end rather than requiring us as humans to sort of orchestrate a much dumber model to break the task down into very\n\nmodel to break the task down into very very small slices and put them together. So, I do kind of expect that a lot of the value is going to come from the most capable models, but I might be wrong. It it might depend and it might really depend on the capabilities of AI integrators to sort of leverage AI really efficiently. What advice would you give this audience which there everyone is early in the career with lots of potential in terms of how do you stay relevant in the future where all these models are going to become so awesome. What should everyone be really good at and study and to still do really good work? I think as I mentioned there's a lot of value in understanding how these models work and being able to really efficiently leverage them and and integrate them and I think there's a lot of value in kind\n\nI think there's a lot of value in kind of like building building at the frontier. Um I don't know we could turn it over to the audience for for questions. Let's turn it out to the audience for some questions. I had a quick question on the scaling loss. You show that a lot of the scaling laws are like linear that like the more we have exponential compute going up but then like we have linear progress in uh in the scaling loss but then on your last slide you show that you expect then suddenly like an exponential growth in like how much time we save. I want to ask you like why do you think that suddenly on this chart we're exponential and not linear anymore? Thank you. Yeah, this is a really good question and I don't know. Um I mean the meter finding was kind of an empirical finding. Um the way that I tend to think\n\nfinding. Um the way that I tend to think about this is that um in order to do more and more complex logger horizon tasks um what you really need is some ability to self-correct. You need to be able to sort of identify that you've you've you make a plan and then you start executing in the plan. But everyone knows that our plans are kind of worthless and uh and we encounter reality. we get things wrong. And so I think that a lot of what determines the horizon length of what models can accomplish is their ability to notice that they're doing something wrong and and correct it. Um, and I think that's not sort of like a lot of bits of information. It doesn't necessarily require a huge change in intelligence to sort of notice one or two more times that you've made a mistake and how to correct that mistake. But if you sort of\n\ncorrect that mistake. But if you sort of fix your mistake, maybe you sort of on the order sort of double the horizon length of the task because like instead of getting stuck here, you get stuck twice as far twice as far out. So I think that's sort of the picture that I have that like you can kind of unlock longer and longer horizons with relatively modest improvements in your kind of ability to understand the task and self-correct. But that just kind of like those are just words. I think the empirical trend is maybe the most interesting thing. And uh maybe we can build more detailed models for why that trend is true, but it's sort of your guess is as good as mine. Yeah. So I also have a question over here. Um so it's an honor. Um so basically um in terms of um increasing the time horizon, I feel like so my\n\nthe time horizon, I feel like so my mental model of neuronet networks is very simple. If you want them to do something, you train on such data. Um so if you want them to um if you want to increase the um time horizon you have to slowly get for example verification signals. Now um I think one way to do this is via product. So like for example um cloud agent and then you use the verification signal to incrementally improve the model. Now my question is basically this works really nicely for for example coding where you have a product that is sufficiently good such that you can deploy it and then get the verification signal but what about other domains like in other domains are we just um scaling data labelers to AGI or is there a better approach? Yeah, it's a good question. I mean, um, so when when\n\ngood question. I mean, um, so when when sort of skeptics ask me sort of why do I think we will be able to sort of scale and get something like broadly human level AI, it's basically because of of what you said. there is some sort of very kind of operationally intensive path where you just sort of build more and more different tasks for AI models to do that are more and more complex, more and more long horizon and you just sort of turn the crank and train with RL on those those more more complicated tasks. So I sort of feel like that's the worst case for AI progress. And I mean given the level of investment in AI and I think the the sort of level of value that I think is being created with AI, I think people will do that if necessary. That said, I think there are a lot of ways of sort of making it simpler. The\n\nways of sort of making it simpler. The best is to have an AI model that is trained to oversee and supervise what uh claw like you have claude say which you're training to be clawed when you have another AI model that's sort of providing supervision and is not just saying did you do this incredibly complicated task correctly like did you become a faculty member and get tenure will that take six or seven years is that like an endto-end task where at the end you sort of either get tenure or not over seven that's that's ridiculous. That's very inefficient. But instead can provide more detailed supervision that says you're doing this well, you're doing this poorly. Um I think that sort of as we're able to use AI more and more in that kind of way, we'll probably be able to make training for very long\n\nable to make training for very long horizon tasks more efficient and I think we're already doing this to some extent. We'll do one last question. Yeah, I wanted to build on top of that. when you're basically developing like these tasks and then training them with RL, would are you like like would you like try creating these tasks like using large language models like the tasks you use for RL or are you still using humans? Great question. So I would say a mix. Um I mean obviously we're building the tasks as much as possible using AI to sort of like say generate tasks with code. we do like also uh ask humans to create tasks. So it's it's basically some mixture of those things. Um I think that as AI gets better and better, hopefully we're able to leverage AI more and more, but of course the frontier of\n\nand more, but of course the frontier of the difficulty of these tasks also increases. So I think humans are are are still going to be involved. Okay. Thank you. All right. Let's give it a round of applause to Jared.\n"
    },
    {
      "speaker": "Chelsea Finn",
      "title": "Building Robots That Can Do Anything",
      "date": "2025-07-22",
      "source_url": "https://www.youtube.com/watch?v=a8-QsBHoH94",
      "transcript": "Hi everyone. Um, I'm really excited to talk about developing general purpose robots and how we might uh actually like truly develop and bring intelligence into the physical world. So, um, to start off, I'd like to talk about this problem, which is that if you want to truly solve a robotics application, you essentially need to build an entire company around that application. uh you need to build a different company for logistics, for wet lab automation, for robots and kitchens, for surgical robots and so on. And this is really really hard to do because that company needs to make new hardware, develop custom software, design unique movement primitives for that application, handle edge cases and so on. And you have to do all of that from scratch uh if you want to solve a robotics problem. And as a\n\nto solve a robotics problem. And as a result, uh, a lot of robotics companies haven't been very successful in actually bringing robots into the physical world successfully, uh, in our daily lives. I co-founded a company called physical intelligence, uh, that's trying to solve this problem. And in particular, we're trying to develop a general purpose model that can enable any robot to do any task in any environment. uh and we think that this sort of generalist model may work better and be easier to use than purpose-built models just like we've seen in the development of found foundation models for language and other applications. Uh for example, if you want to build uh a coding assistant, you don't nowadays develop something specifically for coding, but you develop and you build on models that were\n\nand you build on models that were trained on large amounts of data, not just on code. And essentially this is the problem of trying to develop these sorts of foundation models and bring this sort of intelligence into the physical world rather than the digital world where they largely are today. So how do we do this? Uh in this talk I'd like to talk about how we go about doing this. And if we were to take a lesson from language models we know that language models have taught us the importance of scale. And so one possible conclusion would be that perhaps scale is the most important ingredient for developing these models. And if you were to say this conclusion is true, then you might look to certain data sources for largecale uh data. So for example, we might look at data from industrial automation and you get tons and tons of\n\nautomation and you get tons and tons of data of robots uh doing tasks over and over again like this. But this sort of data isn't going to allow robots to go into disaster zones or to make a sandwich uh or to bag groceries. And so this massive scale doesn't have the diversity of behaviors that we need in order to solve this general problem. Alternatively, maybe we look at data from YouTube which has a also a massive data source and many videos of humans doing tasks uh that could be useful for training robots. uh but at the same time we don't learn how to write by watching other people write and we don't become expert tennis players by watching Wimbledon. Uh and so even though there's a massive scale of data here, it's very challenging to use and there's also a a gap between the embodiment of robots and\n\ngap between the embodiment of robots and humans. Um and lastly, we might look at data from simulation and you can also get a massive scale of data here, but uh this data lacks realism and also has a gap from reality. And so I think the lesson here is that scale is necessary for developing these models that can generalize in open world conditions, but they're subordinate to actually solving the problem. So you need scale, but it's not sufficient uh for the entire problem. And so at physical intelligence, we've been um this is an example of a data episode uh that we've collected. Uh this is uh in honor of our first anniversary, which was a few months ago. uh where we um here you can see a teley operator uh in person who's operating um some leader arms to control the robot uh to light a match and light\n\nthe robot uh to light a match and light a candle with the match and with this sort of data we can train robots to do a variety of different tasks and so um what I'd like to talk about is some of our recent results at trying to develop sort of physical intelligence with largecale real robot data I should mention this is large scale by today's robot standards and arguably a minuscule amount of data compared to the sorts of robot data that we should have in the years to come. And so in particular, we'll be looking at whether robots can do a variety of dextrous long horizon tasks, whether robots can succeed in places they've never been, whether robots can respond to open-ended prompts and interjections. Uh, and even if you're not excited about robotics, I think that the lessons uh that we've learned from trying to address these\n\nlearned from trying to address these problems are applicable outside of the physical world. So um can we develop robots that can have uh complete dextrous long horizon tasks? And in particular uh in this first part I'd like to talk about how we trained uh a pi zero foundation model to do this task which is to unload a dryer and fold laundry. Uh and to date I think this is the most impressive thing that I've seen uh a robot do in the physical world. It's really hard. This is an incredibly difficult problem. You can see that it's not perfect. Uh here is making some miscrops, making some mistakes, but it's really really hard because you have to deal with the variability in the clothes and the way in which they might be positioned and crumpled uh and be able to handle all those sorts of things. And as you're\n\nthose sorts of things. And as you're doing this task, which takes about 10 minutes for the robot, there's many opportunities to fail uh to fail catastrophically. For example, dropping um things on the ground, which is hard to recover from. uh and you have to be able to recover from even small mistakes. I was personally actually working quite a bit um on this laundry folding robot along with Michael and Siraj uh and of course supported uh and with contributions from the whole physical intelligence team. Uh so how do you even approach this sort of problem? It's this is a really really hard thing for a robot to do and what we did is we started simple. Uh we started with can a robot fold a single size single brand shirt uh and can a robot dynamically flatten one shirt again single brand single sized and if you start simple\n\nsingle sized and if you start simple this makes the problem quite a bit easier uh we collected some data with teley operation and trained a policy with imitation learning and our model had around 100 million parameters mapping from images from the robot's cameras to joint target joint positions on the robot arms and we do this source of control at 50 hertz on the robot Uh, and uh, we founded the company in kind of mid-March of of 2024. Uh, and a couple months later after we had set everything up, we were able to get a policy that could fairly reliably fold a single size single brand shirt. Uh, you can see that I'm testing the policy right here. Uh, and we also wanted to test some dynamic motions because you need to be able to match the control frequency accurately in order to do these sorts of dynamic motions. Um and\n\nthese sorts of dynamic motions. Um and so these were some of our very initial tests at uh addressing this sort of laundry folding problem. Then from there we wanted to make the problem incrementally harder. Uh and so we instead of starting from the shirt flat on the table, we started in a crumpled position like these. And it turns out that this actually makes it a lot harder. Uh and so here are some videos of some of our initial attempts at trying to train the robot to fold these shirts. And the robot struggles. uh the the robot does some things that kind of look somewhat sensible but generally isn't able to make progress on the task. Uh with many tests we frequently were getting 0% success rate in our tests of this uh system and really struggling to make progress. So really here is the it introduces this challenge of handling\n\nintroduces this challenge of handling the sorts of variability in the ways in which shirts might be crumpled on the table. We had some initial signs of life in late June uh of of last year. Uh and so in this case, the robot was able to kind of make progress on flattening the shirt. Uh it's also then able to fold the shirt uh decently well uh from that initial state. Still not perfect. Uh and as you can see, it takes quite a while to do this. So this is a video that was sped up AEX. Uh so not something that you might have the patience uh for a robot to do. Um, so with some initial signs of life, the also very low success rate, we started to transition to a slightly harder version of the task where the laundry starts in a laundry basket. We also introduced variable size shirts and shorts into the mix. Uh, and again, the\n\nshorts into the mix. Uh, and again, the robot really struggled. So in many of our tests, we were getting 0% success rate across the board, and we're really struggling to actually get the robots to learn how to do these tasks. At this point, we were trying to consider a lot of different things. uh we thought that maybe the robot needs memory, needs history in some way. Uh maybe we need to just train our models for longer. Maybe we should be doing control and endeector space rather than in joint space of the robot. Uh maybe our encoders, we knew that there were calibration issues and maybe we need that calibration to be more consistent. Uh maybe we need to condition the model on more information about the data. Uh maybe we need hierarchy because this is a pretty long horizon task and it needs to break it\n\nhorizon task and it needs to break it down into different subtasks. Maybe we need higher resolution images. uh maybe we need to introduce kind of interventions in data collection. A lot of these things we also tried. We had around two to three months of failure where nothing was really working at addressing this task. But then at some point we actually had a bit of a breakthrough uh which was that um we found one thing that really seemed to make a difference in the robot's ability to do the task. And this was actually to take some inspiration from the world of language modeling to actually instead of just training a policy on all of our data, we pre-train on all the data and then fine-tune on a highly on a curated consistent highquality set of demonstration data. When we did this, uh, we found that the robot was actually\n\nuh, we found that the robot was actually able to make progress and a lot more reliably fold articles of clothing. Uh, and so I think that this video was the first video where the robot was able to fold five items in a row and stack them. Uh, I went home very excited this day. Uh, this was in September of 2024, so multiple months after our initial tests. Uh, now this is far from perfect. Uh, it takes 20 minutes to fold five items of clothes. Uh and um at the same time though it kind of suggested that this sort of recipe was able to unlock uh the capability in the robot to actually fold these articles of clothing. So you can see these sorts of failures here. In this case, it attempted to fold the the blue shirt around seven times uh before eventually actually figuring out how to do that. Um there's also other failure\n\ndo that. Um there's also other failure modes as well. So, here's an example where the robot pushes the stack to the corner of the table uh and decides to kind of fiddle with it a bit uh and then eventually uh slides it off the table and then it proceeds as if nothing had happened and it's going to continue to fold. We continue to iterate on this recipe. We uh selected and worked on our curation strategy for curating a higher quality set of demonstration data. Uh we got it from 20 minutes down to 12 minutes uh for these five items. This is kind of how we were evaluating uh how good our robot system was. uh it still makes mistakes. It's still the full quality still varies, but um it's still significantly better than our previous curation recipe. Now, at this point, we were still training models largely um\n\nwere still training models largely um kind of we were pre-training uh and fine-tuning only on laundry data, and we weren't leveraging uh kind of pre-trained models in the community. And there were some folks working at physical intelligence that were working on developing a pre-trained model trained on all of the robot data. And um we then started to try to introduce these models into our um into our recipe. And so we took an open- source vision language model, a three billion parameter model uh called Polygeemma. Previously we're using the previous videos were all with like a 100 to 300 million parameters that we're iterating on. Um this model takes as input images from the robot also a language command uh and then has a head a diffusion head that's going to attend to all the internal values of the vision language\n\ninternal values of the vision language model. and uh with the joint angles uh predict a chunk of 50 actions into the future. So about 1 second uh of of action steps and we're using a flow matching a variant of diffusion uh to actually output these actions and output continuous actions. Um so we took this pre-trained uh this model and instead of pre-training only on laundry, we pre-trained on all of the robot data that we had collected. Uh and then we just fine-tuned it with the same exact post- training recipe that we had developed uh without using the vision language models. Uh and when we did this, we actually saw the robot uh continue to actually get better when we just plugged in that new pre-trained model. Uh and so in the left video, it's able to do five items in 9 minutes, which was faster than the 12 minutes we\n\nwhich was faster than the 12 minutes we had before. In the right videos, we were testing with um some novel clothing items and found that it was also quite efficient at folding multiple items in a row. Uh, and we also saw as a result there was also more consistent bold quality by using this model that was about 10 times larger um, and had seen more robot data as input. To look at a few highlights of this, here's a pair of shorts that the robot hasn't seen before. And this is kind of a tricky scenario where to flatten it, it actually kind of needs to reach under the kind of the bottom of the shorts. And it's able to do that. is able to kind of figure out that it should reach under um the the left part of the shorts in order to uh eventually flatten it. Uh and then um once it actually successfully flattens it, uh it's able\n\nsuccessfully flattens it, uh it's able to fold it successfully. It also has to do something similar at times to fold shirts. So in this case, it needs to actually kind of fold the shirt over on itself with actually puts it in a more crumpled state arguably, but allows it to find the corners of the shirt and then uh go ahead and fold it. Uh, and then like I mentioned, it also is able to handle unseen clothing items. So, uh, here's an example of a shirt with a V-neck, uh, that is able to fold even though, um, like the the post training data set didn't have, well, didn't this shirt was completely held out and the post training data set didn't have any V-necks uh, as input in the data set, it's also able to fold shirts with buttons. So, it has some degree of generalization to different clothing items.\n\nclothing items. Um, and then lastly, because this policy is a neural network and it's kind of uh taking his input, the current image, it's able to handle interruptions. So here, Michael is uh continuing to mess with the robot and the robot uh figures out that it should put the the shirt away uh while it's trying to fold the other shirt. In this case, Michael's going to continue messing with the robot. So, Michael unfolds one side and the robot reacts. and the robot makes some mistakes here but able to recover. Michael messes it up again. So those are some results of of what the robot's able to do. Now I talked about this pre-training and post-training recipe being really important. We can actually quantitatively measure that and actually make sure that this is actually what's leading to improvement. So, we compared\n\nleading to improvement. So, we compared this pre-training and post-training recipe to not using any pre-training and only training on the curated data set versus no post-training where you're training on all of the data rather than fine-tuning on the curated data set. Uh, and we evaluated these models in terms of their progress on the task where you u make partial progress for getting it out of the bin, which is the easiest part, and then further progress for flattening, folding, and stacking the items. And we see that the pre-training and post-training recipe is able to get far higher performance than omitting pre-training and omitting post-training. Uh and notably omitting pre-training and post- training is basically able to get it out of the bin and make very little progress after that. Whereas when we\n\nprogress after that. Whereas when we combine pre-training and curated post-raining, we get far higher performance whereas able to reliably uh flatten and fold objects. Um and then the last thing that I'll mention on this note is that uh nothing in this recipe is specific to laundry. And so we took the same recipe um and fine-tuned on other tasks. So here uh the task is to um kind of clean up a table. And the robot's also able to successfully uh do this task uh despite the fact that we primarily were iterating a lot on laundry, but it's able to also apply this recipe to this task. It also um is able to scoop uh coffee beans into a coffee grinder. Uh this task is pretty hard. it has to construct the bottom part of a cardboard box uh which requires uh quite a bit of dexterity and then um lastly autonomously lighting a\n\nthen um lastly autonomously lighting a candle with a match again with this kind of same pre-training and post-training recipe. And so this is pointing at this kind of the benefit of foundation models that I alluded to before which is that to do these different tasks you don't have to start completely from scratch. you can actually leverage pre-training across multiple robots and across multiple tasks. And then we're also able to apply that same recipe to robots at other companies. Uh this is a robot that I've actually never seen in person before. Uh they collected data. They sent the data to us. We fine-tuned our model on their data. We actually didn't even know exactly how the model is being controlled. Uh exactly the representation of their actions. uh but by fine-tuning the model on this new\n\nby fine-tuning the model on this new robot, the model is able to control the robot in order to uh make a cup of coffee in this case. So um some takeaways for this part uh we were able to independently develop post- training and pre-training and decouple the problem um and then eventually get the best of both. Uh we found that training on all the data doesn't work for complex tasks and this sort of pre post post pre-training and post-training on curated data leads to far better performance. And then we broke up this really hard problem of folding laundry by gradually starting with folding single shirts and going to more and more complex versions of the task. Now there's a number of limitations here and one limitation I'd like to point out is that these robots inevitably um in this case were trained in the environments\n\ncase were trained in the environments that they were tested. Uh and so this means that in principle you could use these methods to collect a lot of data in one environment and then deploy them in one environment. But ultimately, there's going to be things that change about an environment and scenarios where we would want to actually apply these robots to environments that they've never seen in before. And so, how can robots actually succeed in places that they've never been? The lesson we've learned from machine learning in other places is that we should collect diverse data. Uh, and so we started by collecting data of tidying bedrooms and kitchens in many different environments. Uh, and here's an example, kind of a sample of that data. uh and we collected robot data in homes across San Francisco\n\nrobot data in homes across San Francisco here uh and also collected data in diverse mock kitchens and mock bedrooms and in total we had more than 100 unique rooms represented in the data set that ended up being uh a part of a bigger pre-training mixture. So we trained on this diverse mobile manipulation data uh including the low-level action prediction as well as predicting highle subtask commands for how to complete the task. But we also trained on previously collected static manipulation data that was also fairly diverse. Um static manipulation data that we had collected in our office and in labs as well as web data um and highle instructional data. And I should point out here that the mobile manipulation data of tidying bedrooms and kitchens only accounted for 2. 4% of the overall pre-training mix.\n\n2. 4% of the overall pre-training mix. And so the lesson here is that you were basically able to spin up a new task and actually an entirely new robot. the rest of the mixture didn't have any mobile manipulation data with this particular mobile manipulator in it um without redoing all of the data collection. We're able to build upon everything that had been done before. And it's kind of this kind of same story of foundation models being able to make it easier to spin up um a new problem, a new application without starting from scratch. Um now this wasn't completely easy. Um we had a couple challenges. One of the challenges that we ran into is that naively uh this model can ignore language instructions. So we had actually in this case asked it to pick up the cutting board and it chose to pick up the plate instead. Now we're\n\npick up the plate instead. Now we're again asking it to pick up the cutting board. Uh and instead the robot had a mind of its own decided to pick up the plate. Uh and then we tell it to put the plate in the sink. And eventually it decides that well after kind of moving away from the cutting board it eventually decided that it would actually pick up the cutting board. And so in the early development of our model, we found that it often ignored language. And to solve this, we thought about how vision language models actually follow language well. And so maybe there's a way to preserve the inherent abilities of the pre-trained models when addressing this task. Uh and so what we did is with this PI zero architecture, this action head that's using diffusion is randomly initialized. And this ends\n\nis randomly initialized. And this ends up actually deteriorating the pre-trained knowledge that's present in the vision language model. Uh and we found that if we can prevent this deterioration, we might be able to get better language following. Uh and so the recipe that we came up with was actually in some ways fairly similar, but instead we're going to be predicting tokenized actions. And then when we have the diffusion head, we'll be stopping the gradient from the randomly initialized diffusion head to prevent it from deteriorating the language following abilities of the VLM backbone. Uh and we found that this first led to faster training because the tokenized actions are a more direct supervision signal. And second, it also followed language far better. Uh an 80% follow rate rather than a 20% follower rate. Uh which\n\nthan a 20% follower rate. Uh which suggests that we're able to preserve the the kind of pre-training in the vision language model backbone. So, we put those pieces together. We took that recipe and trained it um pre-trained it on all of our data, including the mobile manipulation data. We fine-tuned it on mobile manipulation data in a variety of environments. And then we tested the model in places it's never been in before. So, we rented uh three Airbnbs that uh we had never been to before. Uh we put the robot in those homes, in this case, in the kitchen, and I asked it to close the cabinet. I asked it to put away the dishes. has also never seen these dishes um or the these forks, these objects. And the robot's able to succeed even though it's never been the here before. There's different uh\n\nhere before. There's different uh countertops, different furniture, different objects, and so forth. Uh lastly, I asked it to clean up the spill, and the robot is able to oblige and wipe down the spill and eventually Uh it's also able to do this for bedrooms. So Laura asked it in this case just clean the bedroom and it puts uh articles of clothing in. Uh it throws away the trash and uh then is able to tidy the bed by putting the uh putting the pillow at the top of the bed and uh tidying the the blanket or the comforter YC's next batch is now taking applications. Got a startup in you? Apply at y combinator. com/apply. It's never too early and filling out the app will level up your idea. Okay, back to the video. So, quantitatively, I talked about how the kind of there's only 2. 7% or something of the the\n\nonly 2. 7% or something of the the mixture and so how much does that other data actually help? Uh could we actually just train on that kind of 2. 7%. And we find that these kind of bars on the right which are excluding data from static robots in labs and environments and so forth um reduces performance significantly. So the performance goes down to less than 60% when you exclude that data when evaluated in novel homes compared to if you use the full pre-training mixture it has uh more than 20% higher performance. Lastly we also looked at is the diversity of data helpful? Is it important? And so we increase the amount of data from these environments to test this. It's always good to like you can kind of do vibe eval but it's really helpful to actually measure how well uh these things work and so this is what this is measuring\n\nand so this is what this is measuring and we find that if we actually increase the amount of homes the amount of uh locations that are represented in the data the performance increases which is great uh and it actually gets to the same level of performance as if we train on data from that target environment and so it means we're actually mostly closing the generalization gap and suggest that the bottlenecks at this point for this sort of task lie not in collecting more diverse data but in actually getting higher reliability and higher performance. Um now I should also mention that there's failure modes like this the success rate was around 80%. There's lots of room for improvement. Uh here are a couple examples of those failure modes. So um here it's told to put the items in the drawer. Uh it is\n\nput the items in the drawer. Uh it is able to put it in the drawer but the item isn't fully in the drawer at the end and it decides that it's done and kind of moves on to the next thing. Uh here the robot uh needs to put the clothes in the laundry basket. It drives over the shirt um and then it gets stuck and it's not able to lift it up. Uh here we asked it to put the dishes in the sink and it successfully is able to put a number of the dishes in the sink but it struggles to pick up the cutting board uh in this particular case because it's a very thin and it's flush against the surface of uh the countertop. Uh and in the last case, my probably my favorite case, um it's told to put the spatula into a drawer and it decides that the oven looks a lot like a drawer and so it opens the oven um and uh yeah,\n\nand so it opens the oven um and uh yeah, tries to to put it in there. Um and beyond this, there's also challenges with regard to speed, partial observability, uh long-term planning um and so uh yeah, lots of work to do still. So the takeaway here is that with diverse data, uh, robots can follow a variety of instructions in environments that the robot has never been in before. Uh, which is a big step up from a lot of robotic scenarios where they're trained in the scenarios that they are being tested. Now the last kind of bit I'd like to talk about is this model has a fairly limited instruction set. It can only follow kind of a certain set of commands. And if we think about how other forms of AI technology have been deployed, people really like to customize and actually tell the robot what they want or tell the system what\n\nwhat they want or tell the system what they want from these kinds of models. And so just like we prompt language models, can we allow robots to respond to open-ended prompts and open-ended interjections? Uh so to do this and actually to do the past work, we're actually leveraging hierarchical uh vision language action models. So we're going to have a high level policy break down uh the prompt into uh intermediate uh verbal responses and intermediate atomic language commands. So the highle prompt might be kind of can you make me a sandwich uh and this highle policy will break it down into the subtask of pick up one slice of bread. This will be passed to a low-level model that actually executes and predicts target joint angles um to fulfill the low-level command of picking up one slice of bread. Now, on its own,\n\nup one slice of bread. Now, on its own, this isn't going to be able to follow all sorts of prompts, and it's actually fairly tricky to handle open-ended language because it's going to be challenging to collect a large number of human robot interactions with the real robot in the loop. And this is also going to be fairly hard to scale. Uh and so what we did is we kind of took all of our existing robot data and we can actually generate synthetic data for the existing robot data. In particular, we can use language models to reabel and generate hypothetical human prompts for the scenarios that the robots are in. And so what this looks like is we'll take data that says um here's a kind of a video and then the next skill is to pick up a Kit Kat because that's what the robot does next in terms of just\n\nthe robot does next in terms of just like basic low-level annotation. And then for this scenario where the robot is about to pick up the KitKat, we can ask a vision language model, what is a hypothetical prompt that a human might have asked that led to this um this particular scenario and the robot to actually choose to pick up a Kit Kat. And then we can train our high level policy on these synthetic prompts to basically augment the robot data with various human interactions that might have led to those different situations. And as a result of this, we're able to actually allow robots to follow a variety of different prompts. So on the left, we ask, \"Hi, robot. Can you make me a ham and cheese sandwich? \" The robot says, \"Sure, I'll start with the bread and add ham and cheese next. \" And it's able to break down this task\n\nAnd it's able to break down this task into the various subtasks of picking up a slice of bread, putting on the cutting board, picking up a slice of cheese, putting it on the bread, um picking up some ham, um and so on and so forth. I can also follow more complicated prompts like, \"Hi robot, can you make me a vegan sandwich? I don't like pickles, though. \" uh and in this case is able to break it down and decide that it's going to add lettuce and tomatoes to the sandwich uh and not add pickles, not add cheese, not add um meat as well. In addition to prompts, we're also able to train the robot to handle different interjections. Um actually here's an a case where of a different kind of prompt. So on the left we train the robot to clean tables. So put trash away and put dishes into the bin. And on the\n\nand put dishes into the bin. And on the right we ask the robot clean up only the trash but not the dishes. And the robot's able to understand what that means and connect that to its low-level actions and only put away the trash and complete when it um when the trash is all put away. And then lastly, it's able to handle interjections and situated corrections. So in this case, um the robot is uh kind of getting items for a user. The user interjects and said, \"Get me something sweet that's not in the basket. \" Right after it had put a Kit Kat into the basket and the robot um says, \"Uh, sure. Let me get you some Skittles. \" uh and reasons through kind of basic reasoning of how to uh what how to fulfill the user's request and is able to um respond to those kinds of corrections situated in the world that\n\ncorrections situated in the world that the robot is in. Now you might also wonder like maybe some existing foundation models could serve as a highle planner for robots and do this sort of high level reasoning without actually training a separate model. And so we also evaluated that um and we found that in blue the performance at following instructions and making progress on the task was substantially lower than the performance of our system which is shown in green. Uh and in general we found that these frontier models generally struggle with visual understanding as it pertains to robotics which makes sense because in general these models aren't kind of really targeting uh many physical applications and have very little data in the physical world. Okay. Um, so to start to wrap up, um, and then we'll all have\n\nwrap up, um, and then we'll all have some time for questions. Uh, I talked a bit about how robots can do a variety of dextrous long horizon tasks with pre-training and post- training. How robots can succeed in places that they've never been, and how they can respond to open-ended prompts and interjections by leveraging synthetic data from language models on top of the robot data that we had collected. Um now with some closing notes the we've seen a few different scenarios in this talk where general purpose robots might be more successful than specialist robots but because we can essentially rather than start from scratch for every single application actually build upon a much broader foundation for physical intelligence in the real world. Um we also saw that like large scale data in the real world is really helpful for\n\nthe real world is really helpful for developing these things and we found that uh and I think that it's necessary but not sufficient for physical intelligence and there's a lot of uh challenges and we need more research uh to be done uh ourselves and through open source contributions before robots I think will be truly ready to tackle the open world. I'd also like to mention that at physical intelligence we're hiring a number of roles. Uh if you're excited about some of the things that we talked about, you can see a list of the open roles on the pi pi. As well, awesome. Happy to take some questions. Let's start on the left. Uh hi Chelsea. So, uh first I want to say thank you for all your work on robot learning. They're all really impressive. Yeah. And uh so mainly I have two questions on uh especially uh regarding\n\nquestions on uh especially uh regarding the post- training part you mentioned. So um the first thing is uh you mentioned that the in post training the most important part is to have high quality action data. So I'm wondering what the components of that would be and then the second question is what do you think uh RL will play into the part of post training? Yeah absolutely. So I think that the the different components of it a lot of it comes down to consistency of the data and the strategy being followed uh and whether the robots whether the um the data completes the task efficiently and with a reliable strategy. Uh and then on the second question I think that reinforcement learning can play a very large role in um it actually in post training. I think that online data from the robots uh which reinforcement\n\nthe robots uh which reinforcement learning allows you to use can allow robots to have a much higher success rate and also uh be faster than if they're just trained with imitation learning. Yeah, thank you. Hi, thank you so much for your talk. Uh so your work is really fascinating and there is no doubt that it will have a lot of impact in the future. But um can I ask you at this stage uh how can you find the fundings because honestly I can't imagine how hard it can be to convince people to invest in a robot that folds close and deal with the dishes. Yeah. So um it's a good question. I think that well I guess first I'll mention that we aren't just focused on applications in the home. uh we really want to solve this broader problem of physical intelligence and we've been starting with those applications because they're ones that\n\napplications because they're ones that are kind of easy to make progress on. Um but we've also been doing tasks like inserting an Ethernet cable which I put put in the talk as well as constructing a cardboard box. Uh and generally I think that this sort of problem has a ton of potential for for like making impact in all sorts of realms not just in domestic tasks but all sorts of realms as well. And even in domestic task, I think there's a huge market for um for this kind of technology. Uh we ourselves haven't had um a lot of challenge with fundraising and I think that a lot of robotics companies recently have also done a great job um and found that there's actually a lot of excitement around this sort of technology because I think things are actually starting to work. Uh I started working on this technology uh more than\n\nworking on this technology uh more than 10 years ago at this point and things really weren't working then and so uh yeah I think that there's a lot of excitement that is starting to mature and and um like actually be ready for the real world. I think that there's a lot more work to do uh but generally it seems like there's a lot of people excited about this technology and and eager to actually put funds behind it. Okay, thank you so much. Yeah. Hi. Uh thank you so much. Um I have two questions like one uh uh more broad and one more technical. So the technical one like is uh VAS uh in my opinion like at least to my understanding are a framework that a bit that is a bit separate like from world modeling and I wonder like how the two of them like will interplay among each other and whether like you have actually planned\n\nwhether like you have actually planned like to somehow like use them together. uh as I see right now like VAS as more of a policies uh that could actually benefit a lot from world modeling and uh from a B perspective I wonder like which kind of infrastructure layers could be the most useful uh to work on such as like explanability, traceability or uh uh safety in general to deploy such models like in the real world. Yeah, great question. So um on the first point we there's actually fairly natural ways to incorporate world model objectives into vision language action models and um we've done some work where um instead of only predicting the next action you predict some intermediate subgoal image uh like what should happen in the future in order to accomplish the task uh and then predict an action from\n\ntask uh and then predict an action from there uh and we've seen some kind of signs of life that that seems to be quite promising. So I think there's ways to merge the merge the two paradigms. Uh at the same time I think there's a lot of challenges that come up with world modeling with regard to the ways in which basically the data that you put into it not necessarily being kind of reflective of the ways in which you're going to use it. You might train it on demonstration data of successful data of completing the task and then evaluate it on to try to actually use it to evaluate actions that are not optimally completing the task. And then the world model will hallucinate um a video of completing the task successfully even if the actions that you provide as input didn't uh weren't actually going to\n\ndidn't uh weren't actually going to successfully lead to a good outcome. Um so there's challenges there to overcome and and so it's not like uh yeah there's various challenges uh but there's also ways to integrate it into the VA uh paradigm and then could you remind me your second question? Um what are like the infrastructure layers like you want the chess to work on uh in the shortest term to bring like the most um improvements let's say to actually run these models on robots. you need uh we have like a real-time system um that needs to actually be hitting a certain frequency to actually like execute actions successfully. Uh and if you have lag in that system and so forth, it introduces all sorts of challenges. And so thinking about fast inference um and infrastructure for like that's actually going to be on the robot\n\nthat's actually going to be on the robot is a big part of uh what our software team does. And then also thinking about like large scale machine learning infrastructure, training large models, ingesting large amounts of data. Um the data that we have is different from a lot of kind of typical data sets because it's very multimodal in nature. Um it's kind of videos, actions, language segments um and and various other uh components as well. So um yeah, some interesting infrastructure problems I think both on the robot side uh and on the kind of model training side. Thank you so much. Yep. Hi, I'm Frederick and I have got a question about model sizes in general. So I think what we're seeing right now is that in general larger model sizes lead to better accuracy. For example, also in your experiments or um it's also\n\nalso in your experiments or um it's also what OpenAI and Enthropic and others are doing right now with their LLMs. However, there's also the approach of using a quite small model and then outsourcing the world knowledge into a database of some sort with which the model can interact. Um what is your take on that? Do you think that's like a valid approach or do you think encapsulating all the world knowledge inside of the model is better or works better? Yeah, it's an interesting question. So in my experience working on like retrievalbased systems um is that it actually is a little bit tricky to well first figure out what should be offloaded versus actually done by the model and second uh sometimes the model will ignore the retrieved content and try to generate something itself and it it actually seems to be very quite\n\nit actually seems to be very quite tricky to get that technically to work uh exactly the way you want it. Um, I think it's probably going to depend on the application and the use case, uh, in terms of how best to like like whether that might make sense, but in my experience, it ends up being quite tricky to figure out what the division of labor is. And even the like the model part of it will need to have some degree of intelligence in order to um like actually make use of the retrieved information and so forth. Uh, so I think it's an really fascinating research problem. Uh, but it also needs like a lot of research to make that uh to that make that work successfully. Thank you. Yeah. Hi, Chelsea. My name is Charu Thomas. Um, first off, really appreciate the talk. It was really fascinating and have\n\ntalk. It was really fascinating and have been a big fan of your work since metalarning. Um, when you think about how software and hardware have are going to continue to evolve, what are the biggest opportunities for builders today for your vision of physical intelligence? I mean, I think that yeah, there's lots of different like opportunities to make things work a lot better and a lot of like open questions. I think kind of like what I was mentioning before, uh, thinking about better ways of having infrastructure on like kind of the robot side. I think that there isn't a lot of like there's some open source code for that sort of thing, but there's a lot of um opportunities to make robot infrastructure better. Uh, and not a lot of people I think are are working on that aspect of the problem. also lots of\n\nthat aspect of the problem. also lots of opportunities like I guess one of the things I love about um about AI and computer science as a whole is there's a really big open source community and I think that there's a ton of opportunity to actually like do open source work and contribute to like a broader community that's trying to like collect data open source models fix bugs on those models uh fine-tune those models figure out new recipes for fine-tuning those models um so yeah all sorts of questions also like on the research side especially in the open source realm yeah thank you hi Hi, Chelsea. Uh, I also, just like everyone else, am a big fan of all your work. So, thank you for putting that all out. Uh, I've been reading through a lot of your group's work recently and particularly enjoyed reading Siraj uh,\n\nparticularly enjoyed reading Siraj uh, Siraj's PhD thesis. It taught me a lot about scaling real world robotics with data. And a question I have is how do you think synthetic data will sort of scale for robotics in the future? As we've seen with LMS, we've moved a we've moved away from sort of not moved away from pre-training, but moved away from human collected data into more creating synthetic data and a lot of filtering and a lot of self-grading. So, how do you think using generative synthetic data for creating environments or reward models will impact robotics? Yeah, I have many thoughts on this topic. Uh I think that at the end of the day there's going to be no replacement for real data and so we're like large amounts of real robot data is going to be a necessary component of any like system that's going to work in a\n\nsystem that's going to work in a generalizable way. Uh so we're going to need that. Um, at the same time I do think that there's tools for like simulation and synthetic data especially to potentially play on the evaluation side because it's very tricky to actually as you for example are generalizing too many environments. It's very tricky to actually evaluate how well that model generalizes not just in one new environment but in 10 new environments because then you actually need to bring the robot to those 10 environments or construct 10 environments. Uh whereas in simulation that gets a lot easier. Uh and so I think I'm really excited about kind of simulation and synthetic data for that use case. I should also mention that I think that the analog of synthetic data in language models is actually not\n\nin language models is actually not necessarily simulation in robotics but closer to something like reinforcement learning. Uh I think that a lot of synthetic data is generated by the model that's actually trying to do the task and then trying to kind of reason through different ways of doing the task. And I think that the analogy there is a robot that's trying to attempt the task and learn from its own attempts and get better from its own attempts. And that sort of online data from the model I think will also play a really critical role in post training and something that uh we're working on quite a bit. Uh and so yeah that that I think is like really important and really helpful. Thank you. Cool. I think we have time for one more question. Sorry we won't be able to get to everyone. Yeah. Hi. It's super cool to see you as an MIT\n\nHi. It's super cool to see you as an MIT EES alumni now working in a really cool robotics and talking to us about robotics and entrepreneurship. Um, but I've been wondering how robotics research that involves hardware components plays out differently in academia versus industry and are there typically more resources, fewer constraints or broader applications in one setting over the other? And what kind of people or goals do you think might be better suited for each path? Yeah, it's an interesting question. Uh, I still love both kind of startup um and academic environments and industry environments. I think they all have various pros and cons. Uh certainly I think that uh any um I think that generally academic environments aren't quite as well resourced in terms of data collection throughput, eval throughput\n\ncollection throughput, eval throughput and compute as um like startups and industry labs. Uh but at the same time I think that there's a lot of uh problems that you can solve without large amounts of resources uh that uh we need to figure out like on the algorithm side. Uh so I think that there's a lot of really interesting work to be done there. Um and then on the like in industry and in startups, I think the um actually like trying to do some of the research on these big models, scaling up data, seeing what hap things happen at large scales um is is really great to do there. Yeah, I think that there's yeah, there's there's a place for both. I also think that the gap isn't as large as often people make it seem. Uh and oftentimes people in industry environments kind of wish they had more compute. Like you kind of always wish\n\ncompute. Like you kind of always wish that you had more resources. uh and sometimes when you have a lot of resources, you don't actually think as carefully and as critically about what runs you're going to be doing and so forth and you uh end up being sometimes more wasteful of compute uh than if you were kind of more compute constrained. So there's also actually downsides to having more resources in my experience. I'm really sorry. Can I just ask a one quick question on architecture? I know that um the scaling laws have worked well for transformer based architectures and I was thinking do you see currently limits um in VLM based architecture which are kind of made for like text tokens because they don't have like modules for physical awareness. Yeah. And how do you deal with that? Yeah. So, we we tokenized the actions\n\nYeah. So, we we tokenized the actions and so I'd encourage you to take a look at the the fast tokenizer paper that we put out um as as kind of a way to accomplish that. And yeah, we should uh wrap up there. Uh thanks everyone and um\n"
    },
    {
      "speaker": "Nobel Laureate John Jumper",
      "title": "AI is Revolutionizing Scientific Discovery",
      "date": "2025-07-15",
      "source_url": "https://www.youtube.com/watch?v=2Yguz5U-Nic",
      "transcript": "This is something of a nice change. I've given a lot of scientific talks and no one claps and cheers when I come on. Not It's really exciting. It's really wonderful to be here. I guess I should start off assuming that not everyone in this cavernous hall knows who I am. Who am I? I'm I'm someone who has done some work in AI for science who really believes that we can use the AI systems, these technologies, these ideas to change the world in a very specific way to make science go faster to enable new discoveries. I think it's really really wonderful. We have the opportunity to take these tools, these ideas and aim them toward the question of how can we build the right AI systems so that sick people can become healthy and go home from the hospital. And it's been kind of a a really wonderful and winding\n\nkind of a a really wonderful and winding journey for me to end up here. I was originally trained as a physicist. I thought I was going to be a laws of the universe physicist. If I was very very lucky, I could do something that would end up one sentence in a textbook. And I did physics and I went to actually do a PhD in physics. And then kind of what I was working on didn't really grab me. I just it didn't feel like what I wanted to do. So I dropped out. I didn't start a startup. That would have been very on point for this event, but I uh dropped out and I ended up working at a company that was doing computational biology. How do we get computers to say something smart about biology? And I loved it. I loved it not just because it was fun, but it was something that would let me do what I thought I was good at.\n\nlet me do what I thought I was good at. Write code, manipulate equations, think hard thoughts about the nature of the world and use it toward this very applied purpose that at the end we want to ena we want to make medicines or we want to enable others to make medicines. Then I really kind of became a biologist and a machine learner. Actually a machine learner because I left that job and I went back to grad school in biohysics and chemistry and uh I no longer had access to this incredible computer hardware that I had when I was working at my previous job and in fact they had custom asics for simulating how proteins this part of your body that I'll talk about move. And since I didn't have that anymore but I still wanted to work on the same problems. Well, I didn't want to just do the same thing\n\ndidn't want to just do the same thing with less compute. And so I started to learn and I was getting very interested in statistics, in machine learning. We didn't call it AI back then. In fact, we didn't even call it machine learning. That was a bit disreputable. I said, I'm working in statistical physics. But you know, how are we going to develop algorithms? How are we going to learn from data and do that instead of very large compute? And I guess it turns out in terms of AI in addition to very large compute to answer new problems. And after this I joined uh Google DeepMind and really joining a company that wanted to say how are we going to take these powerful technologies and all kind of these ideas and we they were becoming very very readily apparent how powerful these technologies were with\n\nthese technologies were with applications uh to especially games but also to things like data centers and others. How are we going to take these technologies and use them to advance science and really push forward scientific frontier? And how can we do this in an industrial setting with an incredibly fast pace working with some really smart people working with great computer resources and with all that you darn well better make some progress and it's been really really fun and the fact that I'm on this stage indicates that we made some progress and I think it really the guiding principle for me has that when we do this work that ultimately we are building tools that will enable scientists to make discoveries. And what I think is really heartening about the work we've done and the part that really I think still just resonates\n\nthat really I think still just resonates with me at my core is there about I think 35, 000 citations of Alphafold. But within that is there are tens of thousands of examples of people using our tools to do science that I couldn't do on my own but are using it to make discoveries. be it vaccines, be it drug development, be it how the body works. And I think that's really really exciting. And the part I want to talk to you about today and the story I want to tell you is a bit about the problem, a bit about how we did it. And I think especially the role of research and machine learning research and the fact that it isn't just off-the-shelf machine learning and then I want to tell you a little bit about what happens when you make something great and how people use it and what it does for the world. So,\n\nit and what it does for the world. So, I'll start with the world's shortest biology lesson. The cell is complex. Um, for people who have only studied biology in high school or in college, you might have this idea that the cell is a couple parts that have labels attached to them. And it's kind of simple, but really it looks much more like what you see on the screen. It's dense. It's complex. Uh, in terms of crowding, it's like the swimming pool on the 4th of July and it's in full of enormous complexity. Humans have about 20, 000 different types of proteins. Those are some of the blobs you see on the screen. They come together to do practically every function in your cell. You can see that uh kind of green tail is the psyllium of uh an ecoli. That's how it moves around. And you can see in fact how it moves around. And you can\n\nfact how it moves around. And you can see that thing that looks like it turns and in fact it turns and drives this motor. All of this is made of proteins. When people say that DNA is the instruction manual for life, well, this is what it's telling you how to do. It's telling you how to build these tiny machines. And biology has evolved an incredible mechanism to build the machines it needs, literal nano machines, and build them out of atoms. And so your DNA gives you instructions that say build a protein. Now you might say your DNA is a line and so are proteins in a certain sense. It's instructions on how to attach one bead after another where each bead is a specific kind of molecular arrangement of atoms. And you should wonder if I my DNA is aligned and I am very much not one-dimensional, what happens in between? And the answer\n\nwhat happens in between? And the answer is after you make this protein and assemble it one piece at a time, it will fold up spontaneously into a shape like you've opened your IKEA bookshelf and instead of having to do the hard work, it simply builds itself and you get this quite complex structure. You can see quite typical protein, a kynise for those of you who are biologists in the audience over there. And you can see this very complex arrangement of atoms and that arrangement is functional and and the majority not everyone of the proteins uh in your body undergo this transformation and that is what functions and that is incredibly small. So light itself is a few hundred nanometers in size and that's a few nanometers in size. So it's smaller than you can see in a microscope. And for a long time scientists have wanted to\n\nlong time scientists have wanted to understand this structure because they use it to predict how changes in that protein might affect disease. How does that work? How does biology work? Often if you make a drug it is to interrupt the function of a certain protein like this one. Now scientists have through an incredible amount of cleverness figured out the structure of lots of proteins and it remains to this day exceptionally difficult. Right? You shouldn't imagine this as I want to determine the structure of a protein. So I shall open the lab protocol for protein structure determination. I shall follow the steps. It consists of cleverness of ideas of finding many ways. In this case, I'm describing one type of protein structure prediction in or protein structure, sorry, determination, experimental\n\nsorry, determination, experimental measurement, where you convince that big ugly molecule I just showed you to form a regular crystal kind of like table salt. No one has an easy recipe for this. So, they try many things. They have ideas and it's exceptionally difficult and filled with failure like many things in science. And you're really looking at kind of one way to get an idea of how difficult this is. Just one kind of ordinary paper that we were using. I flipped to the back and it said, you know, in their protocol, after more than a year, crystals began to form. Right? So, not only did they do all these hard experiments, but they had to wait about a year to find out if it worked. And probably that year wasn't spent waiting. It was trying a thousand other things that didn't work as well.\n\nthat didn't work as well. Once you do that, you can take this to a uh synretron, a modest thing. You can see the cars rigging the outside of this instrument so that you can shine incredibly bright X-rays on it and get what is called a defraction pattern and you can solve that and you can deposit it in what's called the PDB or the protein datab bank. And one of the things that enabled the work we did is that scientists 50 years ago had the foresight to say these are important, these are hard. We should collect them all in one place. So there's a data set that represents ex essentially all the academic output of protein structures in the community and available to everyone. So our work was on very public data. About 200, 000 protein structures are known. They pretty regularly increase at about 12, 000 a year.\n\nabout 12, 000 a year. But this is much much smaller than the need. Getting the kind of input information, the DNA that tells you about a protein is much much much much easier. So billions of protein sequences are being discovered. About 3, 000 times faster are we learning about protein sequence than protein structure. Okay, that's all scientific content, but I should talk to you about the little thing we did which has this kind of schematic diagram. We wanted to build an AI system. In fact, we didn't even care if it was an AI system. That's one of the nice things about uh working in AI for science is you don't care how you solve it. If it ended up being a computer program, if it ended up being anything else, we want to find some way to get from the left where each of those letters represents a\n\neach of those letters represents a specific building block of the protein considered an order. We want to put something in the middle in the alpha fold and we want to end up with something on the right. And you'll see uh two structures there if you look closely where the blue is our prediction and the green is the experimental structure that took someone a year or two of effort. If you want to put an economic value on it on the order of $100, 000 and you can see we were able to do this and I want to tell you how and there were really three components to doing this or to do any machine learning problem and you can say you have data and you have compute and you have research and I feel like we tell too many stories about the first two and not enough about the third. In data, we had 200, 000 protein structures. Everyone has the\n\nprotein structures. Everyone has the same data. In terms of compute, this isn't LLM scale. It's the final model itself was 128 TPU v3 cores, roughly equivalent to a GPU per core for two weeks. This is again within the scope of say academic resources but it's worth saying really most of your compute when you think about how much compute you need don't get distracted by the number for the final model the real cost of compute is the cost of ideas that didn't work all the things you had to do to get there and then finally research and I would say this is all but about two people that worked on this it's a small group of people that end up doing this So really when you look at these machine learning breakthroughs they're probably fewer people than you imagine and really this is where our work was\n\nthis is where our work was differentiated. We came up with a new set of ideas on how do we bring machine learning to this problem and I can say earlier systems largely based on convolutional neural networks did okay. They certainly made progress. If you replace that with a transformer you're honestly about the same. If you take the ideas of a transformer and much experimentation and many more ideas, then that's when you start to get real change. And in almost all the AI systems you can see today, a tremendous amount of research and ideas and what I would call midscale ideas are involved. It isn't just about the headlines where people will say transformers, you know, scaling, test time inference. These are all important but they're one of many ingredients in a really powerful system and in fact we can measure how\n\nsystem and in fact we can measure how much our research was worth. So someone Alphafold 2 is the system that is quite famous the one that uh was quite a large improvement. Alpha fold one was the best in the world but someone did uh the Alcesi lab did a very uh careful experiment where they took Alphold 2 the architecture and they trained it on 1% of the available data and they could show that alpha fold 2 trained on 1% of the data was as accurate or more accurate as alphafold one which was the state-of-the-art system previously. So there's a very clean thing that says that the third uh the third of these ingredients research was worth a hundfold of the first of these ingredients data. And I think this is generally really really important that one of the big as you're all thinking as you're all in startups or thinking about\n\nyou're all in startups or thinking about startups think about the amount to which ideas research discoveries amplify data amplify compute they work together with it we wouldn't want to use less data than we have we wouldn't want to use less compute than we have available but ideas are a core component when you're doing machine learning research and they really helped to transform the world. YC's Next Batch is now taking applications. Got a startup in you? Apply at y combinator. com/apply. It's never too early. And filling out the app will level up your idea. Okay, back to the video. We can even go back and we can do ablations and we can say what parts matter. And don't focus too much on the details. We pulled this from our paper. You can see here this is the difference compared to the baseline. And\n\ndifference compared to the baseline. And you take either of those and you can see that each of the ideas that you might remove from our final system kind of discreet identifiable ideas some of which were incredibly popular research areas within the field like this work came out and a part of it was equivariant and people said equivariance that is the answer alphafold is an equivariant system and it's great we must do more research on equivarians to get even more great systems well I was very confused by this because the sixth uh row there no IPA invariant point attention that removes all the equavariance in alpha fold and it hurts a bit but only a bit. Alpha fold itself on this GDT scale that you can see on the left graph. Alphafold 2 was about 30 GDT better than alphafold one and equivariance explains two or three of\n\nequivariance explains two or three of this. It isn't about one idea. It's about many midscale ideas that add up to a transformative system. And it's very very important when you're building these systems to think about what we would call in this context biological relevance. We would have ideas that were better. We kind of got our system grinding 1% at a time. But what really mattered was when we crossed the accuracy that it mattered to an experimental biologist who didn't care about machine learning. And you have to get there through a lot of work and a lot of effort. And when you do, it is incredibly transformative. And we can measure against uh this axis where the dark blue axis the other systems available at the time. And this was assessed. Protein structure prediction is in some ways far ahead of uh LLMs or\n\nis in some ways far ahead of uh LLMs or the general machine learning space and having blind assessment. Since 1994, every two years, everyone interested in predicting the structure of proteins gets together and predicts the structure of a hundred proteins whose answer isn't known to anyone except the research group that just solved it, right? Unpublished. And so, you really do know what works. And we had about a third of the error of any other group on this assessment. But it matters because once you are working on problems in which you don't know the answer, you get to really measure how good things are. And you can really find that a lot of systems don't live up to what people believe over the course of their research. And because even if you have a benchmark, we all overfit to our ideas to the benchmark,\n\noverfit to our ideas to the benchmark, right? Unless you have held out. And in fact, the problems you have in the real world are almost always harder than the problems you train on, right? Because you have to learn from much data and you apply it to very important singular problems. So it is very very important that you measure well both as you're developing and when people are trying to decide whether they should use your system. External benchmarks are absolutely critical to figuring out what works and that's what really helps drive the world forward. So just some wonderful examples of this is typical performance for us. These are blind predictions. You can see they're pretty darn good. also important we made it available and we thought it was and we did a lot of assessment but we decided\n\ndid a lot of assessment but we decided that it was very important to make it available in two ways. One is that we open source the code and we actually open sourced the code about a week before we released a database of predictions starting originally at 300, 000 predictions and later going to 200 million essentially every protein um from an organism whose genome has been sequenced. And this made an enormous difference. And one of the most interesting kind of sociological things is this huge difference between when we released a piece of code that specialists could use and we got some information and then when we made it available to the world in this database form. It was really interesting kind of you know you release something and every day you check Twitter to find out or check X to find out what's going on. And\n\ncheck X to find out what's going on. And what we would really see is even after that CASP assessment, I would say that the structure predictors were convinced this obviously was this enormous advance solved the problem. But general biologists, the people we wanted to use, the people who didn't care about structure prediction, they cared about proteins to do their experiments, they weren't as sure. They said, \"Well, maybe CASP was easy. I don't know. \" And then this database came out and people got curious and they clicked in and the amount to which the proof was social was extraordinary that people would look and say how did deep mind get access to my unpublished structure. you know, this moment at which they really believed it that everyone had a a protein either had a protein that they hadn't solved or had\n\na protein that they hadn't solved or had a friend who had a protein that was unpublished and they could compare and that's what really made the difference. And having this database, this accessibility, this ease led everyone to try it and figure out how it worked. Word of mouth is really how this trust is built. And you can kind of see some of these testimonials, right? I wrestled for three to four months trying to do this uh scientific task. You know, this morning I got an alpha fold prediction and now it's much better. I want my time back, right? You know, you really appreciate alphafold when you run it on a protein that for a year refused to get expressed and purified. Meaning they for a year they couldn't even get the material to start experiments. These are really important. When you build the\n\nreally important. When you build the right tool, when you solve the right problem, it matters and it changes the lives of people who are doing things not that you would do but building on top of your work. And I think it's just extraordinary to see these and the number of people I talked to. The time that I really knew this tool mattered. In fact, there was a special issue of science on the nuclear pore complex a few months after the tool came out. And the special issue was all about this particular very large kind of several hundred protein system. And three out of the four uh papers in science about this made extensive use of alpha fold. I think I counted over a hundred mentions of the word alphafold in science and we had nothing to do with it. We didn't know it was happening. We weren't collaborating. It was just people doing\n\ncollaborating. It was just people doing new science on top of the tools we had built and that is the greatest feeling in the world. And in fact, users do the darnest things. They will use tools in ways you didn't know were possible. The tweet on the left from Yoshaka Morowaki came out two days after our code was available. We had predicted the structure of individual proteins, but we consider we were working on building a system that would predict how proteins came together. But uh this researcher said, \"Well, I have alphapold. Why don't I just put two proteins together and I'll put something in between? \" You could think of this as prompt engineering but for proteins. And suddenly they find out this is the best protein interaction prediction in the world, right? That when you train on these a really really powerful system,\n\nthese a really really powerful system, it will have additional in some sense emergent skills as long as they're aligned. People started to find all sorts of problems that Alphafold would work on that we hadn't anticipated. It was so interesting to see the field of science in real time reacting to the existence of these tools, finding their limitations, finding their possibilities and this continues and people do all sorts of exciting work be it in protein design be it in others on top of either the ideas and often the systems we have built. One application that really uh I thought was really important is that people have started to learn how to use it to engineer big proteins or to use it in part of and I want to tell this story for two reasons. One is I think it's a really cool application but the second\n\nreally cool application but the second is how it really changes the work of science and often people will say science is all about experiments and validation. So it's great that you have all these alpha fold predictions. Now all we have to do is solve all the proteins the classic way so that we can tell whether your predictions are right or wrong. And they're right about one thing. Science is about experiments. Science is about doing these experiments. But they're wrong about another thing. Um science is about making hypotheses and testing them not about the structure of a particular protein. In this case, the question was they took this protein on the left called the contractile inject injection system, but that's a mouthful. They like to call it the molecular syringe. And what it does is it attaches to a cell and injects a\n\nit attaches to a cell and injects a protein into it. And the scientists at the Jang Lab at uh MIT were saying, well, can we use this protein to do targeted drug delivery? Can we use it to get gene editors like cast 9 into the cell? They tried over a hundred methods to figure out how to take this protein, which they didn't have a structure of. This is just kind of a rendition after the fact, and say, how can we change what it recognizes? I think it's originally involved in plant defense or something like that, and they didn't know how to do it. And they ran an alpha fold prediction. You can see the one on the left. I wouldn't even say it's a great alpha fold prediction, but almost immediately they looked at that and said, \"Wait a minute. those legs at the bottom are how it must recognize and\n\nthe bottom are how it must recognize and attach to cells. Why don't we just replace those with a designed protein? And so almost immediately as soon as they got the alpha fold prediction, they re-engineered to add this design protein that you see in red uh to target a new type of cell. And they take this system and then they show in fact that they can choose cells within a mouse and they can inject proteins in this case fluorescent proteins. So there you'll see the color and they can target the cells they want within a mouse brain. And so they are using this to develop a new type of system of targeted drug discovery. And we see many more examples. We see some in which scientists are using this tool to try thousands and thousands of interactions to figure out which ones are likely to be the case. In fact, discovered a new\n\nbe the case. In fact, discovered a new component of how eggs and sperm come together in fertilization. Many many of these discoveries that are built on top of this. And I like to think that our work made the whole field of what's called structural biology, biology that deals with structures, you know, five or 10% faster. But the amount to which that matters for the world is enormous and we will have more of these discoveries. And I think ultimately structure prediction and larger AI for science should be thought of as an incredible capability to be an amplifier for the work of experimentalists that we start from these scattered observations, these natural data. This is our equivalent of all the words on the internet. And then we train a general model that understands the rules underneath it and\n\nunderstands the rules underneath it and can fill in the rest of the picture. And I think that we will continue to see this pattern and it will get more general that we will find the right foundational data sources in order to do this. And I think the other thing that has really been a property is that you start where you have data but then you find what problems it can be applied to. And so we find enormous advance, enormous capability to understand interactions in the cell or others that are downstream of extracting the scientific content of these predictions and then the rules they use can be adapted to new purposes. And I think this is really where we see the foundational model aspect of alpha fold or other narrow systems. And in fact, I think we will start to see this on more general systems, be them LLMs or others,\n\ngeneral systems, be them LLMs or others, that we will find more and more scientific knowledge within them and we'll use them for important important purposes. And I think this is really where this is going. And I think the most exciting question in AI for science is how general will it be. Will we find a couple of narrow places where we have transformative impact or will we have very very broad systems? And I expect it will ultimately be the latter as we\n"
    },
    {
      "speaker": "Aravind Srinivas",
      "title": "Perplexity's Race to Build Agentic Search",
      "date": "2025-07-11",
      "source_url": "https://www.youtube.com/watch?v=2jOnoTEk-xA",
      "transcript": "YC's next batch is now taking applications. Got a startup in you? Apply at y combinator. com/apply. It's never too early and filling out the app will level up your idea. Now, on to the video. You have to innovate. You have to move faster than everybody else. And it's like running a marathon but at an extremely high velocity. Right. The only uh mode you have is speed. I read all the Twitter comments every time. Google IO last year was AI overview and perplexity is dead. This year was AI mode and perplexity is dead and I read all of that too and it's it's always Aravant, I see you every I don't know 2 or 3 months and you give me an update on the latest on Perplexity. Why don't you just tell these folks where you're at? How are things going? Do people use Perplexity? Do you guys use Perplexity?\n\nDo you guys use Perplexity? Well, whether you believe it or not, like I have infra issues every day. So there are a lot of people using it and um this usage is actually growing to the extent that we don't actually know how to deal with it. We have to rebuild the infra to scale the next 10x. So definitely a lot of people in the world using it. Thanks to all of you as well. What is next for us? The browser. That's the big bet we're making as as far as the future of the company goes. Everyone's here is like why should I use perplexity when there's search and other AI apps of course chat GPT has a bigger distribution than us every other AI app is trying to put search as a layer in it all of them support citations a lot of them support some of the verticals we put work into yes like we're always\n\nput work into yes like we're always going to continue to remain better than others in that category but I think the browser and agents are truly the next bet that we want to make we think about it as an assistant rather than a complete autonomous agent but one omni box where you can navigate you can askformational queries and you can give agentic tasks and your AI with you on your new tab page on your site car as an assistant on any web page you are makes the browser feel like more like a cognitive operating system rather than just yet another browser and we hope to make it like a cloud where you launch several tasks in parallel that are running asynchronously Okay. And pulling all your personal contacts, your email, your calendar, your Amazon, your, you know, all all sorts of social media accounts that you have and you go and do\n\naccounts that you have and you go and do research on real estate, the markets, and these are all like just processes running on your browser. That's never been possible before. And Chrome was exciting when each tab was its own process. You think about each query or each prompt could be that and that will be our new browser comet. So, we're putting all our energy into that. This was going to be the hard question I saved for the end, but since you queued it up, I'll do it right now. Um, I think if Sam Alman were still on the stage today, he would say, \"Oh, yeah, that's what we're doing. \" Um, and I think Sundar at Google probably would say that's the direction we're headed as well. So, it feels like there are a bunch of players now, many of them very wellunded, going in generally the same direction. How do you see the world?\n\ndirection. How do you see the world? Like do you think that there's going to it's going to play out where there's actually like a bunch of different use cases and you can own a very important one that others won't want to own or are we in for like a major competitive battle? Look, if something is really worth doing, it's it's only natural that people with a lot of funding will go and do it. Um people said perplexity is a great product. Now everyone is trying to do something that can answer any question with sources. Cursor was a great product. Now, OpenAI is trying to buy cursor's competitor anthropic launch codeex uh like clot code. Google has its own like rival tool. So, it's only natural that when there's a lot of money to be made in a certain sector, people are going to try to copy it. And there's only a\n\ntry to copy it. And there's only a limited amount of things you can be world class at, whether it's being building great models or building one or two really good products. So, you're obviously not going to win on everything. For us, this is the only thing we care about. accuracy at the level of answers, accuracy at the level of tasks, orchestrating all these different tools. The browser is much harder to copy than like uh yet another chat tool. That said, I'm I'm fully working with the assumption that uh OpenAI will also build its own browser. Anthropic will also try to build its own browser. Google already has one called Chrome. So, it's completely reasonable to expect them to do it. And the only uh mode you have is speed. You have to innovate. You have to move faster than everybody else. And it's like running a\n\neverybody else. And it's like running a marathon but at an extremely high velocity, right? Yes. Yeah. I I really agree with your statement that like you can only focus on one thing and be world class at one thing. And just to give you guys like a little glimpse into it, we were backstage before this talk and he was showing me some of the new stuff that they're working on and there was like a bug, right? And he stopped everything he was doing to like figure out what was wrong with this bug. Why was it not doing the right thing? And if you think about like what would the CEO of a large company do in that situation? Probably they would like hand it off to somebody else on their team. So that's like a good piece of evidence that you actually mean what you say. Yeah. I I I love I love triaging and\n\nYeah. I I I love I love triaging and fixing bugs. I know it sounds trivial. Like is that the best use of the time of a CEO? There are a lot of people who would think otherwise. Recently people are like uh oh like like there I hope this behavior is rubbing off on others. Like I've noticed even Sundar is doing bug support on X right now. So I'm happy that like you know that that's setting a good example. Great. Okay, let's go back to the beginning. Like most of the folks in the audience here are either students or recent grads or grad students. Um and I think hearing your story of like how you started Perplexity uh would be really interesting to them because it's probably exactly the world that they're in now. Yeah. Tell us how you got started. We started the company without actually having clear idea of what to build which is the\n\nclear idea of what to build which is the opposite of what YC advises which is start from a project and turn it into a company. I really think at this point in time when AI is improving so fast you don't have to rigidly stick to any one idea when you're getting started but the most important thing is you don't change the idea every week like that you shouldn't do either. So start with something like brainstorm, think about it and then try to immediately build it and get it in the hands of people. Uh one tool that we were building was natural language SQL which we actually thought about it as a search tool searching over relational databases. I allowed Twitter search but it never like like the original version of Facebook graph search. I allowed that when I was much younger. So I wanted to like\n\nmuch younger. So I wanted to like rebuild that but using language models. Um, and I love Twitter as a platform. So, it was there's no good way to search over Twitter. There still is no good way to search over Twitter. But at least at the time, we organized the entire Twitter's data in the form of like relational tables and just converted every user's query into a SQL query and ran it as against the database and it was really really good and um that's what got us started. But at some point we figured it's better to like scale this across the web and we cannot make every website in the form of tables and neither is it actually easy to answer all sorts of questions. So we bet on the fact that language models can do all the reasoning and parsing and like structuring later but the more important\n\nstructuring later but the more important thing is to start with something more unstructured and that ended up becoming perplexity. Got it. Um, and maybe one step before you actually left to go start the company, like how did you find your co-founders? How did you decide that machine learning and AI was like the area you wanted to focus on? Cuz that was the only thing I was good at. I was not good at anything else. Okay. So, what's the point in starting a company? I cannot start a delivery company or a social media company. Like, I'm not I'm not the right fit, right? Uh, the only thing I knew was AI and machine learning. In fact, it's funny. I we started an AI company. uh but we're not made fun of like not even training our own models like mo but only the foundation models are stuff we don't\n\nfoundation models are stuff we don't train we train so many different models but uh that's the extent to which you need to have the intellectual humility to know like what you're good at what is actually doable for you within with the resources that you have access to and the co-founders are like people I like like I knew from grad school so we had been talking and discussing ideas for a long time and um I think grad school is a great way to like uh you know like like identify your co-founders. You don't talk to them with the you know with the long-term calculation of like oh this could be my co-founder of my future company. You talk to them because they're interesting people. And I think that's essentially the value of the Y cominator network. So even if your first startup year fails, you get access to a\n\nstartup year fails, you get access to a lot of amazing people and maybe they could be your future co-founders. So that that's essentially what grad school was for me. Yeah, that's awesome. Um, okay. So, you launched this first version of Perplexity, which is largely to like do Twitter search effectively. Um, at what point did it like start to work and you maybe internally felt like, oh, we should keep working on this. This is going to be something to explore. Yeah. So, whoever we gave early access to, they were all very excited about it. They kept using it repeatedly. I think there's a phenomenon in products where there's an initial wow factor. Yep. And then mostly either drops completely that that means you never had real retention or it it definitely drops but there sustained usage. So when we saw\n\nthere sustained usage. So when we saw that for the relational database searches like Twitter, LinkedIn, GitHub, we knew that we have like there was something magical about combining large language models in search. But then what we did is like we dreamt bigger and said what if we just give answers and site the relevant sources. We launched that as a discord bot and that was also continually being used. It was not like a one-day usage and people started ignoring it. So that's when we decided we had the courage to launch it. We launched it 7 days after the chat GPT launch especially at a time when chat GPT did not have web right web search. So that was a good moment. And I think like many of the successful AI products that people speak about today cursor included all were like 2022 launches or\n\nincluded all were like 2022 launches or like like early 2023 or late 2022 launches. So they're all like old people, you know, in the in the in the in this AI time scale. Yes. For me, the aha moment was like the New Year Eve, there was like close to 700, 000 queries. And I was like, okay, this has the crappiest name for a consumer product. It's called Perplexity. Very hard. Nobody even knows how to share it. And then it was so slow. Took seven seconds to answer for a query at the time. And um it was making a lot of mistakes, hallucinations and like a no-name company, no-name founder, very one or two million dollars in seed funding. Despite that, people were caring enough to sharing screenshots and like and and a new year eve and you could be, you know, watching Netflix, right? So, uh that's when I\n\nNetflix, right? So, uh that's when I knew there was something real here and I started like optimizing for like, you know, committing to this this vision. Okay. And at that point, like on that New Year's Eve, did you in your head think I'm building a thing that could really compete with Google and like take over a market as big as what Google offers or was it just a toy for you? The first time the thought occurred to me was when um Google wrote a blog post. Sundar wrote a blog post about Bard. Like that was around the time when we were raising series A funding and everybody said, \"Okay, Bard is going to do whatever you're doing. \" And it's like why do I have to build bar like why not just do it on Google right where you you have all the distribution in the world so why do you have to build a separate\n\nso why do you have to build a separate product like just just update your core main the best possible asset to do this exactly and I kept thinking it was pretty obvious you cannot like if if if people can get answers to best hotels to stay in San Francisco with a view of the Golden Gate Bridge or like Bay Bridge or like where can I stay in New York like next to the Central park with good amenities or like which flight is the best thing for me to take to fly from SF to London. If you get direct answers to these questions with booking links right there, how are you going to mint money from booking and Expedia and Kayak and like like you know or like same same thing for shopping. How are you going to take money from um Amazon and like Walmart for the same ad where they're all bidding against each other? It's not\n\nall bidding against each other? It's not in their incentive to give you good answers at all. So that's when I realized that they have to build a separate product but they can never capitalize on their core distribution and 2024 2023 especially and a large part of 2024 too Google had like maybe the fourth or fifth best models at any moment. So as a startup outside Google, you had access to AI that was better than what Google internally had, which was unprecedented, right? Until then, if you had to compete with Google and you had to build something that needed a lot of AI in it, good luck, right? Like cuz you never have an AI outside Google that's even equal, leave alone being better. But now it's a completely reversal of the situation thanks to open AI or anthropic or open source models. So that plus innovator dilemma plus the\n\nSo that plus innovator dilemma plus the fact that we could make a lot of mistakes and it's fine. Whereas for Google, one mistake tanks their stock. Like you remember the live demo of Bard where it failed and the stock went down 6%. Yep. So we knew that there was a lot of advantages for us. Yeah. And I heard you talk about this recently but you know Google specifically has been trying to build perplexity like experiences and you know you AI mode. Yeah. They just like change the name of it each Google IO and then not really true. I'm not I'm not I'm not like saying something wrong. Yes. Right. So it's like I I look it might sound a little um cocky to say that but it's true. Um the same feature is being launched year after year after year with a different name with a different VP with a different group of people but\n\nVP with a different group of people but it's the same thing except maybe it's getting better but it's never getting launched to everybody. One of the things I I've come to admire about you is you really have a focus on the user experience and and you told me how you kind of learned that from Larry Page. Yeah. By reading the book about uh Google. Um why do you think Google has lost that ability? Well, it's a much bigger business, right? And it's not founder anymore. Uh it's hard to take risks. Um I think they have great people. Nobody like no one in this audience would think Google has incompetent people. I think they're like really great engineers. It's largely the incentive structure. It's hard to like you know take a hit on your own stock and do the thing that's long-term correct. So you know honestly I'm happy\n\ncorrect. So you know honestly I'm happy that that sort of dilemma exists because otherwise where is the opening for startups right and and then if startups can succeed then it's going to be monopolies getting bigger and bigger and that's not great for the world. I actually am very happy that we are able to win and they're also like able to like ship new products and people are like first time comparing right earlier for access to information you would never even bother to compare an alternative to Google. It's true. Like that was like considered a waste of time a joke. Now at least you're like oh I first go ask this app like I I'll ask Google or I'll ask Chad GPT or I'll ask Perplexity or ask Gemini and then maybe you don't even ask Google anymore. You just ask the AI apps and there are a bunch of AI assistants and the phone\n\nbunch of AI assistants and the phone makers will start offering all of them as alternatives. It's not going to be like a locked in default search option. So, I'm really happy that they're competing in a world where a monopoly hopefully doesn't exist and that creates a more fair ground for everybody. Yeah. Yeah. You were also telling me backstage about um you know you are facing this increased competition from a variety of folks but if you look at your numbers you haven't really seen effect you know I read all the Twitter comments every time the Google IO exactly the same set of comments repeated this year u Google IO last year was AI overview and perplexity is dead this year was AI mode and perplexity is dead and I read all of that too and it's it's always fun I love it actually um because like like\n\nI love it actually um because like like they know that they're all thinking like I don't I don't even expect these things or the people in the company are like thinking Google wouldn't build this or something like that but it's the reality is like nobody actually gets exposed to those features but competition is real okay let's assume let's let's accept that open AI is extremely wellunded doesn't have all these innovative DMA problems wants to actually ship search on chat GPT chat GPT is the most successful consumer AI product out there And so competing against it is very difficult which is why I I really want to like um push the company more on the browser side and I think comet the browser will be an abstraction layer above chat bots. I you could even imagine like I you know if you permit comet all your chat GPT chats\n\nyou permit comet all your chat GPT chats can you know be fed into that AI and like you don't even have to worry about memory or personalization or like you know any of these things and it'll do a thing a lot of new things that a chatbot cannot do like accessing other tabs accessing your browsing history going and completing forms for you like paying your credit cards buying stuff for you um and being your scout you know going and doing all the research for to that sort of thing like periodic recurring tasks. I think that's the magic that the browser enables for you. And putting it into like mobile like like building mobile versions of this browser is going to be very hard like just engineering wise it's going to take many months. So I'm not really worried about like someone else trying to copy this. It's\n\nsomeone else trying to copy this. It's going to take time for anybody. Switching to a different browser is like a pretty big decision for a user. What what do you think will be the very shortterm things that your browser will do? so much better than what I can get today in Chrome that will make me want to switch. The perfect blend of AI, navigation, and agents is is is what we're going to offer. And um might sound like a boring answer, but no one's done that. And there are like hundreds of millions, probably close to a billion people using AI these days. So, the market's already pretty big. What's like a specific example of how I would do that, you know, if I had access to it tomorrow? You can schedule your meetings. uh you can reply to some of your emails that you don't even want to read. You can\n\nyou don't even want to read. You can like for example let's say you're hosting a Y cominator event and you say I only want to accept Stanford dropouts and it can go through the entire list of people who applied and just filter based on who's you know took scrape their LinkedIn URLs filter based on whether they were Stanford and whether they dropped out or not and then accepted like that level of multi-step reasoning is something you can uniquely do. By the way, I'm not saying that's a good filter. Uh I wouldn't get in otherwise. And so hopefully you don't you're more open. Yeah. We look for deep mind researchers also. Yeah. Yeah. Don't worry. Um Okay, cool. Let's talk a little bit about how you run the company now, right? I don't know if you wanted to say how many employees you have. Yeah, we have about 200.\n\nYeah, we have about 200. Okay, so the company's getting bigger. Um you now have access to code writing AI tools. Um, are you guys just like full in on that stuff? Are you vibe coding everything? How what what's it look like? I mean, you you don't want to wipe code everything, right? Like like like we frequently run into infra issues and you don't want a wipe coder right there fixing it on live things on production like I do want like people well trained in regular software engineering, infrastructure, distributed systems like you don't want to like replace these skills. But yeah front-end design that's where we are seeing tremendous adoption like cursor is being used by everybody. uh we made it mandatory to use at least one AI coding tool and internally at perplexity it happens to be cursor and\n\nperplexity it happens to be cursor and like a mix mix of cursor and github copilot but yeah we definitely made it compulsory and so the way machine learning people are do using it AI people are like sometimes they read a paper and they can just upload a screenshot of the pseudo code and uh ask cursor to like just edit the files to implement this new algorithm and then it's able to like uh write it on unit tests and then uh run an experiment pretty quickly that uh is reducing the experimentation time from like 3 4 days to like literally 1 hour or like there are people who don't know design and so sometimes I'm I just give them feedback where I take a screenshot of my iOS app and I say this button needs to move here with an arrow and they upload my screenshot to cursor and then ask it to like write write a change to the swift\n\nlike write write a change to the swift UI file. So that level of change is incredible. Like like the speed at which you can fix bugs and ship to production is is crazy. The more bugs there are as long as you can fix them fast. Yeah, bugs are always ahead of like how fast people can write code though. But just just to be clear, I'm a big fan of all these tools, but it is also introducing new bugs and many people don't know how to fix them and they don't even know how the bug got introduced and they have to go find it again. So it's not perfect and I actually like the more newer tools like clawed code seems to be far smarter than like what cursor is able to do. So I'm actually like like really positive that this is the right future but there are there are issues right now. Yeah. um in talking to a lot of the folks here, one of the major questions\n\nfolks here, one of the major questions that I've heard is um as these coding tools get better and better and better, what is the like actual enduring value of a company like yours if if increasingly it's easy to replicate what you have done using these tools? What's your take on that general type of question? I mean brand definitely has a big value, right? Like there are cursor competitors, perplexity competitors like OpenAI will have like their own cursor. OpenAI has perplexity within chat GPT that did not kill any of these companies. So there is a certain brand value that once you acquire at the scale of like several millions of users, paying users, you don't actually die that fast. You earn the right to survive and keep building. Uh so brand is important. uh narrative is very important to the brand like you have to\n\nimportant to the brand like you have to communicate to people why do you even need to exist for us it's the focus on accuracy okay let there exist 100 chat bots but we are the most focused on getting as many answers right as possible we focus on speed time to first token on app or web like we're still the fastest despite doing search uh we focus a lot on like how we present the answer so there are some things you are obsessed about because you care about it and that becomes your narrative and your brand identity. And if you manage to get reasonable amount of distribution, not saying 100 million users, but tens of millions, then you earn the right to keep playing the game no matter what other people ship. Until then, it's definitely a challenge. You have to worry about it. Even now, we worry about\n\nworry about it. Even now, we worry about it and the only solution is to move fast and keep shipping. be beyond brand like do you think about any network effect types of things emerging with perplexity I mean brand has network effects right like people people tell each other about the brand but no AI product has within app network effect like like it's not like WhatsApp where if you build a WhatsApp rival meta has a definitely like a questionable brand right like people don't necessarily trust Meta's products they think like these are ad products Despite that, nobody's able to switch off WhatsApp that easily because all your contacts, your groups, everything is there. AI doesn't quite have that yet. Uh mainly because you can easily export your chat GPT history, upload it somewhere else or uh things like that. I\n\nsomewhere else or uh things like that. I think the browser will definitely be one play to like you know figure this out because as your browsing history and like which again you can still export but not the same as just getting a dump a CSV dump uh and your passwords your wallet your agent remembers you there's a lot of tasks that are running on the browser that you rely on your day-to-day life and work that's one way to like keep get the product a lot more sticky and like create more network effects especially if multiple people rely on the same set of tasks you're sharing it with them. That's one way to get all this into like the next level. It also sounds like a lot of the stuff that you aspire to solve for users requires integrations or partnerships or something with a bunch of other companies in the world. Yeah. And if you\n\ncompanies in the world. Yeah. And if you can get those to be good, then there is somewhat of a network effect in the sense that your product will be good and some competitor would have to build the same integration or same deal with with these providers. What does that look like do you think in the future? like does perplexity do deals with all the airlines in the world and all the hotels and all the e-commerce providers? So we we already work with self book uh they power all the hotel bookings natively done on perplexity. We work with trip advisor to surface all the reviews of hotels and different you know places. We have like collaborations for the maps. We work with Yelp. uh we also like you know for shopping we have a lot of merchants who are directly selling on us uh and then we work with firmly to like\n\nuh and then we work with firmly to like support the bookings like like native purchases so there's already a lot of partnerships Shopify is one of our partners on finance we work with FMP sports we work with like uh stats perform so there's a lot of data providers already working with us to on these verticals and we just think it's going to expand further as agents start to do things. Different people are okay with like becoming MCP servers. Some people are not. Some people just want to like like preserve their websites. The browser agent will be generic enough that it'll respect whatever the third party wants because at the end of the day, the agent is the one that's being permitted by the user to act on their behalf. And um if there is no MCP server, it's still fine. You can just use these tabs as if the user would have\n\nuse these tabs as if the user would have done it. And uh that's the key advantage of the browser that you do not have if you commit entirely to just the MCP vision. If you commit entirely to MCP vision, you require these third party MCP servers to work reliably. Uh the data that they send you uh on with the MCP protocol has to be perfect. Your chatbot has to like like you know deal with all these issues that exist. On the other hand, if you just ground up design it as the way a human would use that website, you have full control over like how to how to do it, you don't have to rely on someone else doing the engineering well on their end. Um, let's talk next about business model. Your main competitor Google, their business model, as you've talked about, is selling ads. Um, and you think that prevents them from being really\n\nthat prevents them from being really good at what you're doing. So what what will your business model be and how will you get it to be on the order of magnitude of of Google's? I don't know if you'll ever get order of magnitude profits as Google. Uh just to be clear and I don't think that's needed. No one in the history even Google themselves never has had another business that had the margins that Google has. So it's completely reasonable to get something far far better than any public company out there right now and and way be still way below Google. Number two, I think the subscription revenue is like really encouraging. We never expected to get this far and then we think like we can grow at least, you know, a few billions a year in just subs, which is a great business. usage based pricing where\n\nbusiness. usage based pricing where people are paying an agent for completing a task or people have recurring tasks and they pay based on you know every single use of the task and they normalize this system based on like how much it would take to hire a person to do that for them uh is going to be a thing I don't exactly know how it's going to play out what are the margins going to be on that potentially it's going to be way better than um subscriptions in terms of volume of people who would pay for it but it might be lower margins because it's usage based. So you're still going to be spending on all those queries. Someone might be paying a subscription to like one of these AI apps and might not have used it for an entire month. And so that's good margins on that user, right? So I don't actually have a clear sense\n\nSo I don't actually have a clear sense of how this is all going to like evolve. But all I know is subscriptions and usage based pricing are going to be a thing. transactions, you know, uh if people start buying more through AIS, uh taking a cut out of the transactions is good. It's going to be CPAs have historically been way lower margins than CPCs, which is why Google never became a transaction platform, which is why I said like you're going to make a lot of money here. You may never make as much money as Google. Yeah. I Google Google's business model is potentially the best business model ever. Ever. So, yeah, it's fair to not. Maybe it was so good that you needed AI to kill it basically. All right, let's we're going to do some audience Q&amp; A in a little bit, but um before we get there, I kind of wanted to\n\nbefore we get there, I kind of wanted to understand your advice for the folks in this room, right? Like if you were in their position back whatever it was four years ago, what would you advise they do? I would say uh work incredibly hard. There is no substitute for it. Don't think like you're very smart like like strategizing the right way to build a company despite all like what big model labs are doing. You should assume that if you have a big hit, if your company is something that can make revenue on the scale of hundreds of millions of dollars or potentially billions of dollars, you should always assume that a model company will copy it. Mainly because they are really looking for revenue. They raise like tens of billions or close to 50 billion and they need to justify all that capex spend and\n\nneed to justify all that capex spend and they need to keep searching for new ways to make money. So they will copy anything that's good. I think you got to live with that fear. You have to embrace it and realize that like your mode comes from moving fast and building your own identity around what you're doing because users at the end care. Like when you're trying to get like a specific person for your house help, you are searching for that specific person. and you're not like going for a general agency that handles all of it. So, um I think there's like like real benefit from embracing that fear and like sleeping with that fear and waking up every day and like feeling excited about what you're going to build because that's the only thing that'll keep you going. Well, you guys are the perfect example\n\nWell, you guys are the perfect example of how it's possible to go up against somebody as big as Google. That's great. All right, let's do some Q&amp; A. We'll start on the left side here. Go for it. Uh, hi, my name is Sammy and I just want to personally thank you for helping me get a 100 in my theory of knowledge course. Uh, would not have been able to do it without you. No shame. Um, quick question for you. Uh, you know, with your recent partnership with Nvidia to ship AI models across Europe, um, there's been talks about perplexity being installed on um, all Samsung phones or pre-installed. Um, and that could lift your valuation towards 14 billion uh, according to sources like Bloomberg. Um it's a heavy responsibility being the default search engine for you know the mainstream population. What do you think are the\n\npopulation. What do you think are the most important factors at Perplexity to prevent hallucinations or incorrect uh data from you know being given to the masses? Thank you so much. Thank you. Uh hallucinations is something we we really care about. We we're building benchmarks internally uh to keep up to date with that. The only way there is to keep building a better search index. uh keep capturing better snippets of all the web pages and then like these models like like you know are getting fast enough that you can have them reason multistep for every query without incurring too much cost and so that's another way to reduce hallucinations. I I want to ask you about like the innovator's dilemma. So, if you were in Sund's shoes or in um in like the Google co-founder's shoes, like what would you\n\nco-founder's shoes, like what would you do and how would you kind of come up with maybe changing their business model even if it's a worse model? So, if you were running Google competing against yourself, what would you do? I I think I don't envy that job at all. Um I I nobody in the world wants that job. It's it's it's a very difficult job. Would you sacrifice the business model in order to get like a new get the next product or would you ship it as a separate product? Like if you're Google, would you just build a separate thing that is the perplexity competitor and and sacrifice the distribution advantage Yeah, I I don't like genuinely I don't know. I think uh I can say all what I want but they have more data on like what their users are doing and um there are a lot of people in the world who\n\nare a lot of people in the world who hate AI by the way so I think just throwing AI down people's throats on such a you know massive distribution area is not easy what I would do I would I definitely don't know and I I don't want to be in that position also by the way if if if ads are part of every AI answer you're going to hate it too um and and so um it's good that There there's alternatives like us. All right. Hey Arvin, my name is Akshad. Uh so in a recent interview with Nikl Kamat, he asked you for an internship at Perplexity. So I was just wondering how that um arrangement is going. He he came he came to the office. He spent a couple of days. I mean he hasn't posted about it. So I'll let him post about it. But I we did spend time with him. Uh it was not a proper internship but we did speak to him for a while.\n\nbut we did speak to him for a while. I want to start by saying thank you very much for your very candid answers. I really appreciated that. So um a lot of startups they find some like cool application of foundation models and then they'll like build something off of that but then if it does gain traction then the foundation models will consolidate that into their own infrastructure. And Perplexity sort of has that issue too with like a lot of LMS adding search like TAGBT, Gemini, companies like Coher. So I was just wondering like how would you approach something like that? Would you try to pivot just get better at what you do or I think I would say uh pick something you want to like be known for? Uh yes there are other people integrating search but we still want to be the fastest and most accurate and\n\nbe the fastest and most accurate and obviously I cannot just say that and and then stop like we need to figure out a new strategy too and and build new products that don't exist yet. Uh so our browser will be that bet for us and browser and search are not two distinctive products. They're actually like the browser is a natural graduation step from search just like how Google graduated from Google search to Chrome and Chrome is the main reason they got billions of daily queries from hundreds of millions. So when Google IPOed they had no browser and they had like maybe a 100 million queries now you know like it's like 10 billion or something. So the browser is an important part of that and then so that's why we we are making a massive bet on that and agents can only be built with a browser. I'm very\n\nonly be built with a browser. I'm very like convinced about that vision that if you want to have a mobile agent that you can actually build and implement without being restricted by whatever OS rules that Apple or Google sets in terms of not being able to call third party apps. Expecting every mobile app to have MCP servers and then like connecting all their data to your thing is not going to be that straightforward. Like nobody wants to be disintermediated by an AI that quickly. So the browser will be a great way to build all these things. Thank you. So as a lot of us here have done um we've tried we've failed at our startups um you know some of us have been more successful than others some like me have failed when you're in that moment failing over and over again. What do you tell yourself as CEO or as an\n\ntell yourself as CEO or as an entrepreneur to to win to teach yourself to win? What what do I tell myself when I feel like I might fail? Yeah. or when you're in that very specific moment of failing where you feel like everything's crashing down on you or this feature isn't working or this bug has popped up, how do you get through that and what do you think your biggest motivational factor is in that realm? Or maybe like at the beginning before it started to take off, what gave you the hope to keep working on it versus just go back to OpenAI and get your job? I just watched uh the Elon Musk videos on YouTube. No, I'm serious. I I can tell you which video. There's a video where there's like a third failure in a row and like what do you think? And he's like I don't ever give up. I would have to be dead or incapacitated.\n\nhave to be dead or incapacitated. So you'd say you're also never going to give up? Yeah, I I hope to I hope to like stay that way. It's not easy. Uh I think he's done it for way longer and that's why you all like respect him. But that's you know there are examples of great entrepreneurs who have done this despite all the odds stacked against them. So what do you have to lose? Just keep going. Thank you. Yeah. Uh yeah my question is about uh kind of the sustainability of perpetuity not in terms of the business model but just in terms of the web in general. Um, you know, a lot of studies have come out recently showing that AI search engines like Perplexity drive a lot less traffic to websites. So, I'm curious, what do you think like the web will look like in 5 to 10 years when a lot of these websites, you know, they're not getting\n\nwebsites, you know, they're not getting as much traffic and so they have to kind of cease their operations and like the web will just be a lot quieter of a place for content creation. How do you think perplexity fits into that? And what do you think the web will look like in that era? I think that there are going to be uh, you know, the web is already pretty long tail uh, and there's a massive power loss. So I I feel like the parallel is going to get even more skewed. That is very obvious. There are going to be certain brands that are wellnown and they're going to preserve direct organic visits, but those who are trying to game the SEO system and trying to get traffic, I think they're definitely going to have a harder time. Okay. Yeah. Hi Rean, good afternoon. Uh firstly, where do you place the line between\n\nwhere do you place the line between summarization and plagiarism in report generation? And how do you avoid IP violations in your product? And secondly, how do you deal with political bias? Bias and political sorry, political bias and personal interest in news articles and other human written sources. Yeah, I think there are cases where you actually have objective truth, right? Like what was the score in the NBA game? what is the live weather right now in San Francisco where you don't want to you don't want to be wrong ever on those queries and and people know what is true but you even there you're trusting right like you're trusting some data provider who's tracking the live game the TV that's showing you the number or Apple or Google's like acute weather all these things so at some point it all relies on\n\nthings so at some point it all relies on trust and trust is built over time based on being being accurate reliably and so trying to surface the right data from the right people who have earned the right to like like be surface in AI is is how we think about it for accuracy. Now there are things that don't have one clear accurate answer. I think there the best thing we can do is offer all the perspectives and not really take a clear opinion on like what is right and wrong when there's no clear uh answer to that question. Do you measure how accurate you are at that job by user feedback in some way? We don't actually measure it today. We we should an eval set uh should be built for that like like questions where there is no one objective answer. The problem with building an automated eval for for\n\nwith building an automated eval for for that type of thing is what what what is the right answer? It's subjective, right? like like if if there are questions about the origins of CO and there's so many different opinions of that relying a lot on Wikipedia as a source and and you know can say maybe for a human raider you're like okay saying all the things Wikipedia said it's a good answer but maybe what you want is to say stuff that is not there in Wikipedia and that relies on like having a much better human evaluators like pool much smarter people who who are supposed to rate these things and they're not like available for like you scale AI style evaluations. Right. Right. Okay. I think we have time for one final question. You get it? Awesome. Hi, my name is Angela. Thank you so much for talking to us. I have a\n\nyou so much for talking to us. I have a question about your go to market strategy. You had a great campaign for students. That's how I and assume many college students learn about you guys. But then also you had a collaboration with Koshi which is a little bit different audience. So I'm just trying to understand how do you decide which audience you're trying to get? I think like what one one perspective here is trying to get into distributions of users that you don't typically have access to on your traditional marketing channels. You know, there are a lot of people who don't use Twitter or LinkedIn and and and and they're all like they all exist in the world. We just are living in a bubble here. U and and there are some other businesses that have good access to them. uh like you know traditional businesses like like you\n\ntraditional businesses like like you could imagine the the kind of people who use Costco regularly may not even be using AI on a regular basis and so if that's the kind of people you're going for then it makes sense to change your strategy to reach them but also remember that uh it's good to grow with adjacencies like you do want to have some overlapping sets of people who would be the word of mouth carriers as they help you expand to more you know non-over overlappinging circles. So I think that that's how I think about it. Like there should be some overlap, but your distribution should keep evolving over time. Thank you. All right, Arvin, thanks for joining us.\n"
    },
    {
      "speaker": "AI",
      "title": "Andrew Ng: Building Faster",
      "date": "2025-07-10",
      "source_url": "https://www.youtube.com/watch?v=RNJCfif1dPY",
      "transcript": "It's really great to see all of you. What I want to do today since this is build as startup school is share with you some lessons I've learned about building startups at AI fund. AI funds a venture studio and we build an average of about one startup per month. And because we co-founded startups, we're in there writing code, talking about customers, design on features, detering pricing. And so we've done a lot of reps of not just watching others build startups, but actually being in the weeds, building startups with entrepreneurs. And what I want to do today is um share with you some of the lessons I've learned building startups, especially around this changing AI technology and what it enables. And it'll be focused on the theme of speed. So it turns out that for those of you that want to build a startup, I think a\n\nthat want to build a startup, I think a strong predictor for startup's odds of success is execution speed. And I actually have a lot of respect for the entrepreneurs and executives that can just do things really quickly and new AI technology is enabling startups to go much faster. So what I hope to do is share with you some of those best practices which are frankly changing every two to three months still to let you get that speed that hopefully lets you have a higher odds of success. Before diving to speed, you know, a lot of people ask me, hey Andrew, where are the opportunities for startup? So this is what I think of as the AI stack where at the lowest level are the semiconductor companies then the clouds are hyperscalers built on top of that. A lot of the AI foundation model companies built on top of that. And even though a\n\nbuilt on top of that. And even though a lot of the PR excitement and hype has been on these uh technology layers, it turns out that almost by definition, the biggest opportunities have to be at the application layer because we actually need the applications to generate even more revenue so that they can afford to pay the foundation cloud and semiconductor technology layers. So for whatever reason media and social media tends not to talk about the application layer as much but for those of you think you're building startups almost by definition the biggest opportunities have to be there although of course the opportunities at all layers of the stack. One of the things that's changed a lot over the last year um and in terms of AI tech trends I if you ask me what's the most important tech trend in AI I\n\nthe most important tech trend in AI I would say is the rise of agentic AI and about a year and a half ago when I started to go around and give talks to try to convince people that AI agents might be a thing I did not realize that around last summer a bunch of marketers would get a hold of this term and use it as a sticker and slap it on everything in site which made it almost lose some of meaning but I want to share with you from a technical perspective why I think agentic AI is exciting and important and also opens up a lot more startup opportunities. So, it turns out that the way a lot of us use LMS is to prompt it to have it gener output. And the way we have an LM output something is as if you're going to a human or in this case an AI and asking it to please type out an essay for you by writing from the\n\nan essay for you by writing from the first word to the last word all in one go without ever using backspace. And humans, we don't do our best writing, being forced to type in this linear order. And it turns out neither does AI. But despite the difficulty of being forced to write in this linear way, um our LMS do surprisingly well. With agentic workflows, we can go to AI system and ask it to please first write an essay outline, then do some webs research if it needs to and fetch uh some web pages to put in their own context, then write a first draft, then read the first draft and critique it and revise it and so on. And so we end up with this iterative workflow where your model does some thinking and some research does some revision goes back to do more thinking and by going around this loop many times. Uh it is slower\n\nthis loop many times. Uh it is slower but it delivers a much better work product. So for a lot of t lot of projects AI fund has worked on everything from um pulling out complex compliance documents to uh medical diagnosis to reasoning about complex legal documents. We found that these agentic workflows are really a huge difference between it working versus not working. But a lot of the work that needs to be done, a lot of the valuable businesses to be built still will be taking workflows existing or new workflows and figuring out how to implement them into these size of agentic workflows. So just to update the picture for the AI stack, um what has emerged over the last year is a new agentic orchestration layer that helps application builders orchestrate or coordinate a lot of calls to the technology layers underneath. And the\n\ntechnology layers underneath. And the good news is uh the orchestration layer has made it even easier to build applications. But I think the basic conclusion that the application layer has to be the most valuable layer of the stack still holds true with a bias or focus on the application layer. Let me now dive into some of the best practices I've learned for how startups can move faster. It turns out that um at AI fun we only focus on working on concrete ideas. So to me a concrete idea a concrete product idea is one that's specified in enough detail that an engineer can go and build it. So for example if you say let's use AI to optimize healthcare assets you know that's actually not a concrete idea. It's too vague. If you tell me it's a very software to use AI to optimize healthcare assets different\n\noptimize healthcare assets different engineers would do totally different things and because it's not concrete you can't build it quickly and you don't have speed. In contrast, if you had a concrete idea like let's write software to let hospitals, let patients book MR machine slots online to optimize usage. I don't know if this is a good or a bad concrete idea. Actually business is already, you know, doing this. But it is concrete and that means engineers can build it quickly. If it's a good idea, you find out it's not a good idea, you will find out. But having concrete ideas buys you speed. Or someone to say, let's use AI for email personal productivity. Too many interpretations of that. That's not concrete. But if someone says could you build an app Gmail integrate the automation that use let's use the right\n\nautomation that use let's use the right prom source right filter entire emails that is concrete I could you know I could go build that this afternoon. So concretness buys you speed and the deceptive thing for a lot of entrepreneurs is the vague ideas tend to get a lot of kudos. If you go and tell all your friends we should use AI to optimize the use of healthcare assets. Everyone will say that's a great idea. But it's actually not a great idea at least in the sense of being something you can build. Uh it turns out when you're vague, you're almost always right. Uh but when you're concrete, you may be right or wrong. Either way is fine. We can discover that much more fast, which is what's important for SA. In terms of executing on concrete ideas, I I I find that at AI fun, I ask my team to focus on concrete ideas because um a\n\nto focus on concrete ideas because um a concrete idea gives clear direction and the team can run really fast to build it and either validate it, prove it out or falsify and conclude it doesn't work. Either way is fine. So we can do that quickly and it turns out that finding good concrete ideas usually requires someone could be you could be a subject matter expert thinking about a problem for a long time. Uh so for example actually before before you know starting Corsera um I spent years right thinking about online education talking to users holding my own intuitions about what would make a good edtech platform and then after that long process I think YC sometimes calls it wondering the idea maze but after thinking about it for a long time you find that the guts of people that have thought about this for\n\npeople that have thought about this for a long time can be very good about rapidly making decisions as in after you've thought about this talked to customers and so on for a long time if you ask this expert, should I build this feature or that feature? You know, the gut, which is an instantaneous decision, uh, can be actually a surprisingly good proxy. It can be surprisingly good mechanism for making decisions. And I know I work on AI, you might think I'll say, oh, we need data. And of course, I love data, but it turns out getting data for a lot of startups is actually slow mechanism for making decisions. And a subject matter expert with a good gut is often a much better mechanism for making a speedy decision. And then one other thing for many successful startups at any moment in time you're pursuing one\n\nany moment in time you're pursuing one very clear hypothesis they building out and trying to sell China value of hotspot. Um and a startup doesn't have resources to hedge and try 10 things at the same time. So pick one go for it and if data tells you to lose faith in that idea that's actually totally fine. Just pivot on a dime to pursue a totally different concrete idea. So that's what often feels like an AI fund. We're pursuing one thing doggedly with determination until the world tells us we were wrong then change and pursue a totally different thing with equal determination and equal doggedness. And one other pattern I've seen, if every piece of new data causes you to pivot, it probably means you're starting off from two weaker a base of knowledge, right? If every time you talk to a customer, you totally change your mind,\n\ncustomer, you totally change your mind, probably means you don't know enough about that sector yet to have a really high quality concrete idea and uh finding someone that's thought about a subject for longer may get you on to better path in order to go faster. The other thing I often think about is the built feedback loop which is rapidly changing when it comes to how we build with AI coding assistance. So when you're building a lot of applications, one of the biggest risks is custom acceptance, right? A lot of startups struggle not because we can't build whatever we want to build, but because we build something and it turns out nobody cares. And so for a lot of the way uh you know I build startups especially applications less so deep tech less so technology startups but definitely application startups is we\n\ndefinitely application startups is we often build software so this is an engineuring toss and then we will get feedback from users and this is a product management toss and then we'll go back you know then based on the user feedback we'll tweak our views on what to build go back to write more software and we go around this loop many many times iterate toward product market fit and it turns out that with AI coding assistance which Andre talked about as well um rapid engineering is becoming possible in a way that just was not posing much more feasible. So the speed of engineing is going up rapidly and the cost of engineing is also going down rapidly. This changes the mechanisms by which we drive startups around this loop. When I think about the software that I do, I maybe put into two major buckets. Sometimes I'll build quick and\n\nbuckets. Sometimes I'll build quick and dirty prototypes to test an idea. You say build a new customer service chatbot. Let's build AI to process legal documents whatever build a quick and dirty prototype to see if we think it works. The other type of software where I do is write maintain production software maintain legacy software but these massive production ready code bases depending on which analysts report you trust. It's been hard to find very rigorous data on this. You know when writing production quality code maybe we're 30 to 50% faster with AI systems. Hard to find a rigorous number. maybe he's plausible to be but in terms of building quick and dirty prototypes we're not 50% faster I think we're easily 10 times faster maybe much more than 10 times faster and there are a few reasons for this uh when you're building\n\nreasons for this uh when you're building standalone prototypes there's less integration with legacy software infrastructure legacy data needed um also the requirements reliability even scalability even security are much lower and I know I'm not supposed to tell people to write insecure code right feels like the wrong thing to say, but I routinely go to my team and say, \"Go ahead, write insecure code. \" Because if this software is only going to run on your laptop and you don't plan to maliciously hack your own laptop, it's fine to have insecure code, right? But of course, after it seems to be working, please do make it secure before you ship it to someone else. And you know, like a leaking PI, leaking sense data that that is, you know, very damaging. So before you ship it, make it secure and scalable, but they're just testing it.\n\nscalable, but they're just testing it. It's fine. And so I find increasingly startups will systematically pursue innovations by building 20 prototypes to see what works, right? Uh because I I I know that there's some angst in AI. A lot of proof of concepts don't make to production. But I think by driving the cost of a proof of concept low enough, it's actually fine if lots of proof of concepts don't see the light of day. And I know that um the mantra move fast and break things got a bad rep because you know it broke things. And some teams took away from this that you should not move fast, but I think that's a mistake. I tend to tell my teams to move fast and be responsible. And I think they actually lots of ways to move really quickly while still being responsible. And in terms of the AI assistance uh\n\nAnd in terms of the AI assistance uh coding landscape, I think was it three four years ago code autocomplete right popularized by GitHub copilot and then there was a cursor windserve generation of AI enabled ids which great use winds and cursor quite a lot um and then starting I don't know six seven months ago uh there started to be this new generation of highly agentic coding assistants uh including that she's using o3 a lot for coding um cloud code is fant Fantastic. Since quad 4 release, it's become and and ask me again in a few months, I may use something different. But the tools are evolving really rapidly, but I think uh cloud codeex this is a new generation of highly agentic coding assistance that is making developer productivity keep on growing. And the interesting thing is if you're even half a generation or one\n\nyou're even half a generation or one generation behind actually makes a big difference compared to if you're on top of the latest tools and I find my team is taking really different approaches to software engineing now compared to even three or six months ago. One surprising thing is we we're used to thinking of code as this really valuable artifact because it's so hard to create but because the cost of software engine is going down code is much less of a valuable artifact as it used to. So I'm on teams where you know we've completely rebuilt a codebase three times the last month right because it's not that hard anymore to just completely rebuild a codebase pick a new data schema is fine because the cost of doing that has plummeted some of you may have heard of Jeff Bezos's terminology of a two-way\n\nJeff Bezos's terminology of a two-way door versus a one-way door. A two-way door is decision that you can make. If you change your mind, come back out, you know, reverse it relatively cheaply. Whereas a one-way door is you make a decision and you change your mind is very costly or very difficult to reverse. So choosing the software architecture of your tech stack used to be a one-way door. Once you built on top of a certain tech stack, you set a database schema, really hard to change it. So that used to be a one-way door. I don't want to say it's totally a two-way door, but I find that um my team will more often build on a certain tech stack a week later, change your mind, let's throw the code base away and redo it from scratch on a new tech stack. I I don't want to overhype it. We don't do\n\ndon't want to overhype it. We don't do that all the time. There are still costs to redoing that. But I find my team is often rethinking what is a one-way door and what's now a two-way door because the cost of software engineering is so much lower now. And maybe going a little bit beyond software engineering, I I I feel like this actually a good time to empower everyone to build of AI. Uh over the last year, a bunch of people advised others not to learn to code on the grounds of AI were automated. I think we'll look back on this as some of the worst career advice ever given because as better tools make software engineing easier, more people should do it, not fewer. So when many decades ago the world moved from punch calls to keyboard and terminal that made coding easier. When we moved from assemblies high level\n\nWhen we moved from assemblies high level languages like cobalt um there actually people arguing back then that now we have cobalt we don't need programmers anymore like people actually wrote papers to that effect but of course that was wrong and programming languages made it easier to code and more people learn to code text IDs ID is the AI coding assistant um and as coding becomes easier more people should learn to code. I have a controversial opinion which is uh I think actually it's time for everyone of every job role to learn to code and in fact on my team you know my CFO my head of talent my recruiters my front desk uh uh person all of them know how to code and I actually see all of them performing better at all of their job functions because they can code and I think um I'm probably a little bit\n\nI think um I'm probably a little bit ahead of the curve probably most businesses are not there yet but in the future I think we empower everyone to code a lot of people can be more productive I want to share with you One lesson I learned as well on on why we should have people learn to do this which is um when I was teaching generative VI for everyone on Corsera, we needed to generate background art like this uh using midjourney and you know one of my team members uh new art history and so he could prompt midjourney with the genre the palette the artistic inspiration had a very good control over the images he generated. So we end up using all of Tommy's generated images. Whereas in contrast, I don't know art history. And so when I prompt, you know, image generation, I could write, please make pretty pictures of\n\nwrite, please make pretty pictures of robots for me, right? And and I could never have the control that my collaborators could. And so I couldn't generate as good images as he could. And I think with computers, one of the most important skills of the future is the ability to tell a computer exactly what you want. So they'll do it for you. And will be people that have that deeper understanding of computers that will be able to command a computer to get the outcome you want. And learning to code, not not that you need to write the code yourself. Steer AI to code for you seems like it will remain the best way to do that for a long time. with software engineering becoming much faster. The other interesting dynamic I'm seeing is that the product management work getting user feedback deciding what features to\n\nuser feedback deciding what features to build that is increasingly the bottleneck and so I'm seeing very interesting dynamics in multiple teams over the last year a lot more of my teams have started to complain that their bottlenecks on product engineering and design because the engineers have gotten so much faster some interesting trends I'm seeing three four five years ago Silicon Valley used to have these slightly suspicious rules of thumb but nonetheless rules of thumb will have 100 p. m. to four engineers or 1 PM to seven engineers was this like PM product manager to engineering ratio right which should take with a grain of salt but it was typical of a 1 PM to six seven engineers and with engineers becoming much faster I don't see product management work designing what to build becoming faster at the same speed\n\nbecoming faster at the same speed engineers I'm seeing this ratio shift so literally yesterday one of my teams came to me and for the first time when we're planning headcom for a project this team proposed to me not at 1: 00 PM to four engineers but to have 1 PM to 0. 5 engineers. So the team actually proposed to me I still know no this is a good idea for the first time in my life that I saw you know managers proposed to me having twice as many PMs as engineers was a very interesting dynamic. I I still don't know if this proposal I heard yes is a good idea but I think it's a sign of where the world is going and I find as PMs that can code or engineers with some product instincts often end up doing better. The other thing that I found important for startup found for startup leaders is because engineing is going so fast. If you have\n\nengineing is going so fast. If you have good tactics for getting rapid feedback to shape your perspective what to build faster that helps you get faster as well. So um I'm going to go through a portfolio of tactics for you know getting product feedback to keep shaping what you will decide to build. And we're going to go through a list of the faster maybe less accurate the slower more accurate tactics. So the fastest tactic for getting feedback is look at the product yourself and just go by your gut. And if you're a subject matter expert, this is actually surprisingly good you if you know what you're doing. A little bit slower is go ask three friends or teammates to get feedback to play with your product and get feedback. Um little bit slower is ask three to 10 strangers you know for feedback. Um, it\n\nstrangers you know for feedback. Um, it turns out for when I built products, one of the most important skills I think I learned was how to sit in the coffee shop, how to sit in a when it's traveling, when I travel, I often sit in the hotel lobby. It turns out learn to spot places of high foot traffic and very respectfully, you know, grab strangers and ask them for feedback on whatever I'm building. This used to be easier when I was less known. When when people recognize you, it's a little bit more awkward. I found that um I've actually sat with teams the hotel lobby very high foot for traffic and you know very respectfully ask strangers hey we're building this thing do you mind taking a look oh and I actually learned in a coffee shop there a lot of people working a lot of people don't want to be\n\nworking a lot of people don't want to be working so we give them excuse to be distracted they're very happy to do that too but I've actually kind of made tons of product decisions in a hotel lobby or a coffee shop with collaborators just just just like that send prototypes to 100 testers you if you have access to logic group of users and prototype to more users and these are these get to be slow and slower tactics and I know Silicon Valley you know we like to talk about AB testing of course I do a ton of AB testing but contrary to what many people think AB testing is now one of the slowest tactics in my menu because it's just slow to ship it yeah it depend on how many users you have right so and then uh the other thing is um as you use anything but the first tactic some teams will look at the data they make a\n\nwill look at the data they make a decision but the missing piece is When I AB test something, um, I don't just use result of AB test to pick product A or product B. My team will often sit down and look carefully at the data to hone our instincts to speed up to improve the rate. I wish we're able to use the first tactic to make high quality decision. Often sit down and think, gee, I thought, you know, this product name will work better than her product name. Clearly, my mental model the users wrong. to really sit down and think to update our mental model using all of that data to improve the quality of our guts on how to make product decisions faster. That turns out to be really important. All right, so talked about um concrete ideas, speed up engineering, speed up product feedback. This is one\n\nspeed up product feedback. This is one last thing I want to touch on which is I've seen that understanding AI actually makes you go faster. Um and and here's why. As a AI person, maybe I'm biased to be pro AI, but I want to share you why. So it turns out that when it comes to mature technology like mobile, you know, many people have had smartphones for a long time. We kind of know what a mobile app can do, right? So many people including nontechnical people have good instincts about what a mobile app can do. If you look at mature job roles like sales, marketing, HR, legal, they're all really important and all really difficult. But you know, there are enough marketers that that have done marketing for long enough and the marketing tactics haven't changed that much in the last year. So there are a\n\nmuch in the last year. So there are a lot of people that are really good in marketing and it's really important really hard but that knowledge is relatively diffused because you know the knowledge of how to do HR like it hasn't changed dramatically you know in the last six months but AI is emerging technology and so the knowledge of how to do AI really well is not widespread and so teams that actually get it that understand AI do have a advantage over teams that don't whereas if you need if you have an HR problem you can find someone you know that knows how to do it well probably but If an AI problem, knowing how to actually do that could put you ahead of other companies. So things like what accuracy can you get for a customer service chatbot? You know, should you prom fine tune a workflow? Um how do you get a voice out\n\nworkflow? Um how do you get a voice out to low latency? There a lot of these decisions that if you make the right technical decision, you can like solve the problem in a couple days. They make the wrong technical decision, you could chase a blind alley for three months, right? And and one one thing I've been surprised by, it turns out if you have, you know, two possible architecture decisions, it's one bit of information. It feels like if you don't know the right answer, at most you're twice as slow, right? One bit, you know, try both. It feels like one bit of information can at most buy you a 2x speed up. And I think in some theoretical sense that is true. But what I see in practice, if you flip the wrong bit, you're not twice as slow. You spend like 10 times longer chasing a blind alley. which is why I think going in to\n\nalley. which is why I think going in to have this right technical judgment, it really makes startups go so much faster. The other reason why I find staying on top of AI really helpful for startups is um over the last two years we have just had a ton of wonderful genai tools or genai building blocks right partial list but prompting workflows evals guardrails rack voice act async programming lots of ETL embeddings fine-tuning graph DB how to integ models there's a long and wonderful list of building blocks that can quickly combine to build software that no one on the planet could have built, you know, even a year ago. And this creates a lot of new opportunities for starters to build new things. So when I learned about these building blocks, this is actually a picture that I have in mind. If you own one building block, like you\n\nIf you own one building block, like you have a basic white building block, yeah, you can build some cool stuff. Maybe you know how to prompt. So you have one building block, you build some amazing stuff. But if you get a second building block like you also know how to build chat bots. So you have a white Lego brick and a black Lego brick, you can build something more interesting. Um if you acquire a blue building brick as well, you can build something even more interesting. Get few red building bras, maybe a little yellow one, more interesting, get more building bras, get more building bras, and very rapidly the number of things you comb combine them to into grows kind of combinatorily or grows exponentially. And so knowing all these wonderful building blocks lets you combine them in much richer combination.\n\ncombine them in much richer combination. One of the things that deep learn does so I actually take a lot of deep learn courses myself you know to because work with great we work with I think like pretty much all the leading AI companies in the world and cert and and um and uh try to hand out building blocks. Um but when I look at the deep learning course catalog this is actually what I see. And whenever I take these courses to learn these building blocks, I feel like I'm getting new things that can combine to form kind of combinatorally or exponentially more software applications that were not possible just one or two years ago. So just to wrap up, this is my last slide. I then want to take questions if if y'all have any. I find that there are many things that matter for startup, not just speed. But when I\n\nfor startup, not just speed. But when I look at the startups that AI fund is building, I find that the management team's ability to execute at speed is highly correlated with its odds of success. And some things we've learned to get you speed is, you know, work on concrete ideas. Um uh it's got to be good concrete ideas. I find that as a as executive, I'm judged on the speed and quality of my decisions. Both do matter, but speed absolutely matters. rapid entrying with AI coding assistance makes you go much faster but that shifts the bottleneck to getting user feedback on the product decisions and so having a portfolio of tactics to go get rapid feedback and if you haven't learned to go to coffee shop and talk to strangers it it's not easy but then just just be respectful right just be respectful of\n\nrespectful right just be respectful of people that's actually very valuable skill for entrepreneurs to have I think and I think also um staying on top of the technology buys you speed all right with that let me thank Thank you very much. Happy questions. As AI advances, do you think it's more important for humans to develop the tools or learn how to use the tools better? Like how can we p position ourselves to remain essential in a world where you know intelligence is becoming democratized? I feel like AGI has been overhyped and so for a long time there'll be a lot of things that humans can do that AI cannot and I think in the future the people that are most powerful are the people that can make computers do exactly what you want it to do and so I think staying on top of the tools some of us will build tools sometimes but\n\nof us will build tools sometimes but there were a lot of other tools others will build that we can just use but so people that know how to use AI to get computers to do what you want it to do will be much more powerful, not worry about people running out of things to do, but um people that can use AI will be much more powerful than people that don't. Hey, so well first of all uh thank you so much. I have a huge respect for you and I think that you are true inspiration for a lot of us. My question is about uh the future of compute. So as we move towards uh more powerful more powerful AI, where do you think that comput is heading? I mean we see people saying let's ship GPUs to space. Some people talking about nuclear power data centers. What do you think about it? There's something I'm debating what I\n\nThere's something I'm debating what I wanted to say in response to the last question about kind of AGI about maybe I'll answer this and a little bit the last question. So it turns out there's one framework you can use for deciding what's hype and what's not hype. I think over the last two years there's been a handful of companies that um hyped up certain things for promotional PR fundraising influence purposes. And because AI was so new, um, handful of companies got away with saying almost anything without anyone fact-checking them because the technology was not understood. So, one of my mental filters is there's certain hype narratives that make these businesses look more powerful that's been amplified. Um, and so, for example, this idea that um, AI is so powerful, we might accidentally lead to\n\npowerful, we might accidentally lead to human extinction. That's just ridiculous. But it is a hype narrative that made certain businesses look more powerful and it got you know ramped up and actually helped certain businesses fundraising goals. AI is so powerful soon no one will even have a job anymore. Just not true, right? But again that made these businesses look more powerful got hyped up or we are so powerful so when the hype narrative we're so powerful that by training a new model we will casually wipe out thousands of startups. That's just not true. Yes, Jasper ran into trouble. Small number of companies got wiped out. But it's not that easy to casually wipe out thousands of startups. AI needs so much electricity. Only nuclear power is good enough for that. You know, that wind solar stuff not that's just not\n\nwind solar stuff not that's just not true. So, I think a lot of this um GPUs in space, you know, I don't know. It's like um go for it. I think we have a lot of room to run still for terrestrial GPUs. Uh yeah, but but I think uh uh some of these hype narratives are have been amplified that that I think uh are a distortion of what what actually will be done. There's a lot of hype in um AI and how and nobody's really certain about how we're going to be building the future with it. But what are some of the most dangerous biases or overhyped narratives that you've seen people talk about or get uh poisoned by that they end up running with that we should try to avoid or be more aware of and allow us to have a more realistic view as we are building this future. So I think the dangerous AI narrative\n\nSo I think the dangerous AI narrative has been overhyped. Uh AI is a fantastic tool, but like any other powerful tool like electricity, lots of ways to use it for beneficial purposes. Also some ways to use it in harmful ways. I find myself not using the term AI safety that much. Um not because I think we we should build dangerous things, but because I think safety is not a function of technology, it's a function of how we apply it. So like electric motor you know you can't the maker of electric motor can't guarantee that no one will ever use it from unsafe downstream toss like use electric motor can be used to build a Dallas machine electric vehicle can be used to build a smart bomb but the electric motor manufacturer can't control how be used downstream. So safety is not a function of the electric\n\nsafety is not a function of the electric motor as a function of how you apply it and I think the same thing for AI. AI is neither safe nor unsafe. It is how you apply it that makes it safe or unsafe. So instead of thinking about AI safety, I often think about responsible AI because it is how we use it responsibly hopefully or irresponsibly that determines whether or not what we build with AI technology ends up being harmful or beneficial. And I feel like sometimes that the really weird corner cases that get hyped up in the news. I think just one or two days ago there was a Wall Street Journal article about AI losing control of AI or something. And I feel like that article took uh corner case experiments run in a lab and you know sensationalized it in a way that I think was really disproportionate relative to\n\nwas really disproportionate relative to the lab experiment that was being run and unfortunately technology is hard enough to understand that many people don't know better and so these hype narratives do keep on getting amplified um and I feel like this has been used as a weapon against open source software as well right which is really unfortunate. Thank you for your work. I think your impact is remarkable. Uh my question is um as aspiring founders, how should we be thinking about business in the world where anything can be disrupted in a day? Whatever great mode, product or feature you have can be replicated with VIP code and competitors in basically hours. It turns out when you start a business, there are a lot of things to worry about. The number thing I worry about is uh are you building a product that users\n\nuh are you building a product that users love? Um it turns out that when you build a business there are lots of things to think about the go to market channel competitors technology mode all that is important but if I were to have a singular focus on one thing it is are you building a product that users really want until you solve that you know is very difficult to build a valuable business. After you solve that the other questions do come to play. Uh, do you have a channel to get to customers? What is pricing long-term? What is your moat? I find that moes tend to be overhyped. Actually, I find that more businesses tend to start off with a product and then evolve eventually into a moat. But consumer products rand is somewhat more defensible. Um, and if you have a lot of momentum, it becomes harder to catch\n\nmomentum, it becomes harder to catch you. But enterprise products sometimes if you have a uh maybe mo is more of a consideration if they're channels that are hard to get into enterprises. So I think um sorry when when AI fund looks at businesses we actually wind up doing a fairly complex analysis of these factors and writing a you know two to six page narrative memo to analyze it before we decide whether or not to proceed it or not. And and I think um uh all of these things are important, but I feel like at this moment in time, the number of opportunities, meaning the amount of stuff that is possible that no one's built yet in the world, seems much greater than the number of people with the skill to build them. So definitely at the application layer, it feels like there's a lot of white space for new\n\nthere's a lot of white space for new things you can build that no one else seems to be working on. And I would say, you know, focus on building a product that people want, that people love. Um, and then figure out the rest of it along the way. Although this important figure along the way. Uh, hi professor. Uh, thanks for your wonderful speech. Uh, I am a Andagramress researcher from Stanford and I think your uh, metaphor in your speech is very interesting. You said the uh, current AI tools are like bricks and are be uh, and can be built upon accumulation. However, so far it is difficult to see the accumulative functional expansion of the uh integration of AI tools because they often align on the stacking of functions based on uh intent distribution and are accompanied by dynamic problems of\n\naccompanied by dynamic problems of tokens and time overhead. So um which is uh which is different from static engineering. So what do you think will be the perspective of a possible agent 2 accumulation effect in the future? But hey just just some quick remarks to that right you mentioned agent uh OM token cost my most common advice to developers is to first approximation just don't worry about how much tokens cost only a small number of startups are lucky enough to have users use so much of your product that the cost of tokens becomes a problem it can become a problem I've definitely been on a bunch of teams where the cost you know users like our product and we started to look at our right geni uh uh bills and it was definitely climbing in a way that really became a problem. But it's actually\n\nbecame a problem. But it's actually really difficult to get to a point where your token usage costs are a problem. And for the teams I'm on where we were lucky enough that users made our token cause a problem, we often had engine solutions to then bend the cursor and bring it back down through prompting fine-tuning USDs by optimize or whatever. And then what I'm seeing is that I'm seeing a lot of agentic workflows that actually integrate a lot of different steps. So for example, if you build a customer service chatbot, we'll often have to use prompting, maybe optimize some of the results in DSPI, build evals, build guard rails, maybe the customer service chatbot needs rag up part of the way to get information to feedback to the user. So I actually do see these things grow. But one tip for many of you as well is I will often\n\nmany of you as well is I will often architect my software to make switching between different building block providers relatively easy. So for example, um have a lot of products that build on top of OM, but sometimes you point to a specific product and ask me which OM are we using? I honestly don't know because we built up evals and when there's a new model that's released, we'll quickly run evals to see if the new model is better than the old one. And then you'll just switch to the new model if the new model does better on evals. And so the model we use week by week, you know, sometimes our engines will change it without even bothering to tell me because the eval show the new model works better. So it turns out that switching cost for foundation models is relatively low and we often architect\n\nrelatively low and we often architect our software. Oh, AI suite is open sourcing that my friends and I worked on to make switching easier. Um, switching cost for the orchestration platforms is a little bit harder. Uh but I find that preserving that flexibility in your choice of building blocks often let you go faster even as you're building more and more things on top of each other. Um so hope that helps. Thank you so much. In the world of education in AI, there are two paradigms mostly. So one is AI can make teachers more productive. Uh automating grading and automating homeworks. But another school of thought is that there'll be personal tutors for every student. So every student can have one tutor that gets feedback from an AI and gets personal questions from them. So how do you see these two paradigms\n\nSo how do you see these two paradigms converge and how would education look like in the next five years? I think everyone feels like a change is coming in edtech but I don't think the disruption is here yet. I think a lot of people are experimenting with different things. So you know Corsera has Corsera coach which actually works really well. Um deep learn is more focused on teaching AI also has some built-in chat bots. Um a lot of teams experiment of autograding. Oh there's an avatar with me on the deep learn website you can talk to if you want. Uh deep learn. ai. And then I think for some things like language learning with you know speak Dolingo that has become clearer some of the ways AI would transform it for the broader educational landscape the exact ways that AI would transform it I see a\n\nways that AI would transform it I see a lot of experimentation I think what key learning which I've been doing some work with is doing is is very promising for K12 education but I think uh what I'm seeing is frankly tons of experimentation but the final end state is still not clear. I do think education will be hyperpersonalized. Uh but that workflow is an avatar, is a text chatbot, what's the workflow? I think um I feel like the hype from a couple years ago that with AGI soon and it will be all so easy. That was hype. The reality is work is complex, right? teachers, students, people do really complex workflows and for the next decade we'll be looking at the work that needs to be done and figuring out how to map it to agentic workflows and education is one of the sectors where this mapping is\n\nof the sectors where this mapping is still underway but it's not yet mature enough to the point where the end state is clear. So I think I think we should all yeah just keep working on it. All right. All right. Thank you so much Andrew. Thank you. Uh hey my question is I think AI uh it has a lot of great potential for good but there's also a lot of potential for bad consequences as well such as exacerbating economic inequality and things like that and I think a lot of our startups here while they'll be doing a lot of great things will also be you know just by virtue of their product be contributing to some of those negative consequences. So I was curious how do you think you know us as AI builders should kind of balance our uh product building with also the potential societal downsides of some AI products\n\nsocietal downsides of some AI products and essentially how can we uh both move fast and be responsible as you mentioned in your talk look in your heart and if fundamentally what you're building if you don't think it'll make people at large better off don't do it right I I know it sounds simple but actually really hard to do in the moment but AI fund we've killed multiple projects projects not on financial grounds but on ethical grounds where there are multiple projects we looked at the economic case is very solid but we said you know what we don't want this exist in the world and we just killed it on that basis so I hope more people will do that and then I worry about uh bring everyone with us one thing I'm seeing is um people in all sorts of job roles that are not engineering are much more productive if\n\nengineering are much more productive if they know AI than if they don't and so for example on my marketing team my marketers they know how the code. Frankly, they they were running circles around the ones that don't. So, then everyone learned to code and then they got better. But I feel like um trying to bring everyone with us to make sure everyone is empowered to build with AI. That'll be an important part of what all of us do, I think. Um I'm one of your big fans and thank you for your online courses. Your courses make the deep learning like uh much more accessible to the world. And my question is also about education. uh as AI becomes more powerful and widespread, there seems to be a growing gap between what can actually do and what people perceive it. So what do you think about like is it important to\n\nthink about like is it important to educate the general public about deep learning stuff and not only like uh educate those technical people and make people understand more what really uh what AI really do and how it works. I think that knowledge will diffuse deep learn AI we want to empower everyone to build with AI. So we're working on it. Many of us work on it. I'll just tell you what I think is the main d I think there are maybe two dangers. One is if you don't bring people with us fast enough, I hope we'll solve that. There's one other danger which is um it turns out that if you look at the mobile ecosystem, mobile phones, it's actually not that interesting. And one of the reasons is there are two gatekeepers, Android and iOS. And unless they let you do certain things, you're not allowed to\n\ndo certain things, you're not allowed to try certain things on mobile. And I think this, you know, hampers innovators. These dangers of AI have been used by certain businesses. They're trying to shut down open source because a number of businesses that love to be a gatekeeper to large scale foundation models. So I think hyping up dangers, supposed false dangers of AI in order to get regulators to pass laws like the proposed SP 1047 in California, which thank goodness we shut down, would have put in place really burdensome regry requirements that don't make anyone safer, but would make it really difficult for TS to release open source and open weight software. So one of the dangers to inequality as well is if these regulatory you know awful regry approaches and I've been in the room where some of these businesses said\n\nwhere some of these businesses said stuff to regulators that was just not true. So I think that um some of these arguments the danger is if these regulatory proposals succeed and end up siphoning regulations leaving us with a small number of gatekeepers where everyone needs the permission of a small number of companies to fine-tune the model prompt in a certain way that's what will cipher innovation and prevent the diffusion of this information to let lots of startups you know build whatever they want responsibly but the freedom to innovate so I think so long as we um prevent this line of attack on open source open weight models from succeeding and we we've made good progress but the threat is still there then I think eventually we'll get to the diffusion of knowledge and we can hopefully then bring everyone with us\n\nhopefully then bring everyone with us but this fight to protect open source we've been winning but the fight is still on and we still have to keep up that work to to protect open source thank you all very much it's wonderful\n"
    },
    {
      "speaker": "François Chollet",
      "title": "How We Get To AGI",
      "date": "2025-07-03",
      "source_url": "https://www.youtube.com/watch?v=5QcCeSsNRks",
      "transcript": "Hi everyone, I'm Francois. I'm super excited to share with you some of my ideas about HGI and how we're going to get there. This chart right there is one of the most important facts about the world. The cost of compute has been consistently falling by two orders of magnitude every decade since 1940. There's no sign that is stopping anytime soon. And in AI, compute and data have long been the primary bottleneck to what we could achieve. And in 2010s, as you all know, with the abundance of GPU based compute and large data sets, deep learning really started to work. And all of a sudden, we are making fast progress on problems that had long seemed intractable across computer vision and natural language processing. And in particular, self-supervised text modeling started to work. And the dominant paradigm of AI became scaling\n\ndominant paradigm of AI became scaling up LM3 training. And this approach was crushing almost all benchmarks and remarkably it was getting predictably better benchmark results as we scaled up model size and train data size with the exact same architecture and the exact same training process. That's the scaling laws that Jared told you about a few minutes ago. So it really seemed like really it all figured out and many people extrapolated that more scale uh was all that was needed to solve everything and get to a GI. Our field became obsessed with the idea that general intelligence would spontaneously emerge by cramming more and more data into bigger and bigger models. But there was one problem. We were confused about what these benchmarks really meant. There's a big difference between memorized skills which are static and\n\nmemorized skills which are static and task specific and fluid general intelligence the ability to understand something you've never seen before on the fly. And back in 2019 before the rise of LLMs I released an AI benchmark to highlight this difference. Uh it's called the abstraction reasoning corpus or ark1. And from uh at that time back in 2019 to now with a model like GP4. 5 for instance there's been a roughly 50, 000x scale up of basel and we went from 0% accuracy on that benchmark to roughly 10%. Which is not a lot. It's very close to zero if you take into account the fact that any one of you in this room would score well above 95%. So to crack general fluid intelligence, it turns out we needed new ideas beyond just scaling up pre-training and doing static inference. This benchmark was not\n\nstatic inference. This benchmark was not about uh regurgitating memorized skills. It was really about making sense of a new problem that you've never seen before on the fly. But then last year in 2024, everything changed. the AI research community started pivoting to a new and very different pattern test adaptation creating models that could change their own state at test time to adapt to something new. So this wasn't about quering pre-loaded knowledge anymore. It was really about the ability to learn and adapt at inference time and suddenly we started seeing significant progress on ARC. So finally we had AI that was showing genuine signs of fluid intelligence. So in particular in December last year, OpenAI previewed its uh 03 model and they used a version of it that was uh fine-tuned specifically\n\nit that was uh fine-tuned specifically on ARC and that showed human level performance on that benchmark to the first time and today in 2025 we have suddenly moved on from the pre-training scaling pattern and we're now fully in the era of Tesla adaptation. So Tesla adaptation is all about the ability of a model to modify its own behavior dynamically based on the specific data it encounters during inference. So that covers techniques like test time training, program synthesis, train of thought synthesis where the model tries to reprogram itself uh for the task at hand. And today every single AI approach that performs well on ARC is using one of these techniques. So today I want to answer the following questions. First, why did the pre-training scaling paradigm not get us to a GI? If you look back just two years ago, this was the\n\nback just two years ago, this was the standard dogma. Everybody was saying this and today almost no one believes this anymore. So what happened? And next, does this adaptation get us to AGI this time? And if that's the case, maybe AGI is already here. Some people believe so. And finally, besides uh the sign adaptation, what else might be next for AI? And to answer these questions, we have to go back to a more fundamental question. What is even intelligence? What what do we mean when we say we're trying to build AGI? If you look back over the past decades, there's been two lines of thoughts to define intelligence and to define the goals of AI. There's the Minsky style view. Uh AI is about making machines that are capable of performing tasks uh that would normally be done by humans. And this echoes very\n\nbe done by humans. And this echoes very closely uh the current mainstream corporate view that AGI would be uh a model that could perform most economically valuable tasks like 80% is often quoted as as the number. But then there's the mac view that AI is about getting machines to handle problems they have not been prepared for. It's about getting AI to deal with something new. And my view is more like the MATI view. Intelligence is a process and skill is the output of that process. So skill itself is not intelligence and displaying skill at any number of tasks does not show intelligence. This is like the difference between a road network and a road building company. If you have a road network, then you can go from A to B for a specific predefined set of A's and B's. But if you have a road building company, then you can start\n\nbuilding company, then you can start connecting new A's, new B's on the fly as your needs evolve. So intelligence is the ability to deal with new situations. It's the ability to blaze fresh trails and build new roads. So attributing intelligence towards really a crystallized behavior program, a skill program, that's a category error. You are confusing the process and its output. So don't confuse the road and the process that created the road. So to formalize this a bit, I see intelligence as the conversion ratio between the information you have uh mostly your past experience but also any uh developer imparted prior that the system might have and your operational area over the space of potential future situations that you might encounter and that's going to feature high novelty and uncertainty. So intelligence is the\n\nuncertainty. So intelligence is the efficiency with which you operationalize past information in order to deal with the future. It's an efficiency ratio and that's the reason why using exam like benchmarks models is a bad idea. They're not going to tell you how close we are to AGI because human exams weren't designed to measure intelligence. They were designed to measure task specific skill and knowledge. They were designed according to assumptions that are sensible for humans but not for machines. Like for instance, most exams assume that you haven't read and memorized all the exam questions and the answers beforehand. So if you want to regly define and measure intelligence, here are some key concepts that you have to take into account. The first is the distinction between static skills and\n\ndistinction between static skills and fluid intelligence. So between having access to a collection uh of static programs to solve known problems versus being able to synthesize brand new programs on the fly to face a problem you never seen before. And of course it's not a binary. It's not one or the other. There's a spectrum between the two. The second concept is operational area for a given skill. There's a big difference between being skilled only in situations that are very close to what you've seen before and uh being skilled for any situation within a very broad scope. For instance, if you know how to drive, you should be able to drive in any city, not just uh in a specific geopence area. Like you can learn to drive in San Jose and then move to Sacramento and you can still drive, right? Again, so it's there's a spectrum\n\nright? Again, so it's there's a spectrum there. It's not it's not binary. And lastly, you should look at uh information efficiency for a given skill. How much information, how much data, how much practice did you need to acquire that skill? And of course, higher information efficiency means higher intelligence. And the reason these definitions matter a lot is that as engineers, we can only build what we measure. So the way we define and measure intelligence is not a technical detail. It really reflects our understanding of the problem of cognition. It scopes out the the questions we're going to be asking and so it determines the answers that we're going to be getting. It's the feedback signal that drives us towards our goals. And a phenomenon you see constantly in engineering is the shortcut rule. So\n\nengineering is the shortcut rule. So it's it's the fact that when you focus on uh achieving a single measure of success, you may succeed but you will do that at the expense of everything else that was not captured by your measure. So you hit the target but you miss the points and you see this all the time uh on Kaggle for instance. Uh we saw it with the Netflix prize where the winning system was extremely accurate but it was way too complex to ever be used in production. So it ended up never being used. It was effectively pointless. Uh we also saw it in AI uh with chess playing for AI. The reason the AI community set out to create uh programs that could play chess back in the 70s was because uh people expected this would teach us about human intelligence. And then a couple decades later, we\n\nAnd then a couple decades later, we achieved a goal when Deep Blue beat Kasparov, the world champion. And in the process we had really learned nothing about intelligence. So you hit the targets but you miss the points. And for decades AI has chased task specific skill because that was our definition of intelligence. But this definition only leads to automation which is exactly the kind of system that we have today. But we actually want AI that's capable of autonomous invention. We don't want to stop at automating known tasks. We want AI that could tackle humanity's most difficult challenges and accelerate scientific progress. That's what AGI is meant to be. And to achieve that, we need a new target. We need to stop targeting fluid intelligence itself, the ability to adapt and invent. So one\n\nability to adapt and invent. So one definition of AGI only enops automation. So it increases economic productivity. Obviously, it's extremely valuable. Maybe it also increases unemployment. But the other definition unlocks invention and the acceleration of the timeline of science. And it's by measuring what you really care about that we'll be able to make progress. So we need a better target. We need a better feedback signal. What does that look like? My first attempt at creating a way to measure intelligence in AI systems was the RKGI benchmark. So I released ARK1 back in uh 2019. It's like an IQ test for machines and also humans. So ARK1 contains 1, 000 tasks like this one here. And each task is unique. So that means that you cannot cram for ARC. You have to figure out each task on the fly by using your\n\neach task on the fly by using your general intelligence rather than your memorized knowledge. And of course solving any problem always requires some knowledge. And in the case of most benchmarks, the knowledge prior that you need are typically left implicit. In the case of ARC, we made them explicit. So all ARC tasks are built entirely on top of core knowledge prior which are things like objectness, uh elementary physics, um basic geometry, topology, counting. So concepts that any fouryear-old child has already mastered. And solving arc requires very little knowledge and it's knowledge that is very much not specialized. So you don't need to prepare for arc in order to solve it. And what makes arc unique is that you cannot solve it purely by memorizing patterns. It really requires you to demonstrate through the intelligence.\n\ndemonstrate through the intelligence. And meanwhile pretty pretty much every other benchmark out there is targeting fixed known tasks. So they can't actually be solved or hacked via memorization alone. That's what makes ARC fairly easy for humans but very challenging for AI. And when you see a problem like this where a human child can perform really well but the most advanced the most sophisticated AI models out there struggle that's like a big red flashing light telling you that we're missing something that new ideas are needed. One thing I want you to keep in mind is that ARC is not going to tell you whether a system is already a GR or not. That's not its purpose. Arc is really a tool to direct the attention of the research community towards what we see as the most important unsolved bottlenecks on the way to AGI. So ARC is\n\nbottlenecks on the way to AGI. So ARC is not the destination and solving ARC is not the goal. Arc is really just an arrow pointing in the right direction and ARC has completely resisted the pre-training scaling paradigm. Even after a 50, 000x scale up of pre-trained baselons, their performance on ARC stayed near zero. So we can decisively conclude that fluid intelligence does not emerge from scaling up pre-training. You absolutely need test adaptation in order to demonstrate genuine fluid intelligence. And importantly when the arrival of test adaptation happened last year, ARC was really the only benchmark at the time that provided a clear signal about the profound shift that was happening. other benchmarks were saturated. So they could not distinguish between a true IQ increase and just brute force scaling.\n\nbrute force scaling. So now you you see this graph and you're probably asking well clearly at this point AR1 is also saturating. So does that mean we have human level AI now? Well not yet. What you see on this graph is that ARK1 was a binary test. It was a minimal reproduction of fluid intelligence. So it only really gives you two possible modes. Either you have no fluid intelligence in which case you will score near zero like basel or you have nonzero fluid intelligence in which case you will instantly score very high like the O3 model from open eye for instance. And of course every one of you in this room would score within noise distance of 100%. So ARC saturates ARK one saturates way below human level fluid intelligence. And so now we are in need of a better tool, a more sensitive tool that would provide more useful\n\ntool that would provide more useful bandwidths and better comparison with human intelligence and that tool is ARGI 2 which released in March this year. So back in 2019, ARK1 was meant to challenge the deep learning pattern where models are big parametric curves uh used for static inference and today ARK 2 challenges reasoning systems. It changes the test adaptation pattern. The benchmark format is still the same. There's a much greater focus on probing compositional jarization. So the tasks are still very feasible for humans, but they're much more sophisticated. And as a result, ARK 2 is not easily brute forceable. In practice, what this means is that in ARK one, for many tasks, you could just look at it and instantly see the solution without having to think too much about it. With ARK 2, all tasks require some\n\nit. With ARK 2, all tasks require some level of deliberate thinking, but they still remain very feasible for humans. And we know this because we tested 400 people firsthand in person in San Diego over several days. And we are not talking about people who have physics PhDs here. We recruited uh random folks uh Uber drivers, UCDS students, uh people who are unemployed. So basically anyone trying to make some money on the side and all tasks in AR 2 were sold by at least two of the people that saw it. And each task was seen on average by about seven people. And so what that tells you is that a group of 10 random people with majority voting would score 100% on ARK 2. So we know these tasks are completely doable by regular folks with no prior training. So how well do AI models do? Well, if you take basel\n\nAI models do? Well, if you take basel models like GPT4. 5, Lama 4, it's simple. They get 0%. There is simply no way to do these tasks simply via memorization. Next, if you look at static reasoning systems, so systems that use a single chin of thoughts that they generate for the task, they don't do much better. They do on the order of one to 2%. So very much within noise distance of zero. So what that tells you is that to solve AR 2, you really need test adaptation. All systems that do meaningfully above zero are using TTL, but even then they're still far below human level. So compared to ARK1, AR2 enables much more granular evaluation of DTS systems. Systems like 03 for instance. And that's where you see that 03 and other systems like it are still not yet quite human level. And in my view, as long as it's easy to come\n\nin my view, as long as it's easy to come up with tasks that any one of you can do that are easy for humans, but that AI cannot figure out no matter how much computers are it, we don't have a GI yet. and you will know that we are close to having AGI when it becomes increasingly difficult to come up with such tasks. We're clearly not there yet. And to be clear, I don't think ARK 2 is the final test. We're not going to stop at ARC 2. We've started development on RKGI 3 and AR 3 is a significant departure from the input output pair formats of ARC one and two. We're assessing agency, the ability to explore, uh, to learn interactively, to set goals, uh, achieve goals autonomously. So, your AI is dropped into a brand new environment where it doesn't know what the controls do. It doesn't know what the goal is. It\n\ndoesn't know what the goal is. It doesn't know where the the gameplay mechanics are, just to figure out everything on the fly, starting with what is it even supposed to do uh, uh, in the game. And every single game is entirely unique. They're all built on top of core knowledge prior only, just like in AR one and two. So we'll have hundreds of interactive reasoning tasks like this one. And efficiency is central to the design of AR 3. So models won't just be graded on whether they can solve a task, but on how efficiently they solve it. And we are establishing a strict limit of the number of actions that a model can take. And we are targeting the same level of action efficiency as we observe in human. So we're going to launch this in early 2026 and next month in July we're going to release a developer preview so you can\n\nrelease a developer preview so you can start playing with it. What's it going to take to solve AR 2 and we're still very far from it today. Uh then solve AR 3 and we're even further away from that. Maybe in the future solve AR 4 eventually get to AGI. What are we still missing? So I've said that intelligence is the efficiency with which you operationalize the past to face a constantly changing future. But of course if the future you face had really nothing in common with the past, no common ground with anything you've seen before, you could not make sense of it no matter how intelligent you were. But here's the thing. Nothing is ever truly novel. The universe around you is made of many different things that are all similar to each other. Like one tree is similar to another tree is also similar\n\nsimilar to another tree is also similar to your neuron or electromagnetism is similar to hydrodnamics is also similar to gravity. So we are surrounded by isomorphisms. I call this the kaleidoscope hypothesis. Our experience of the world seems to feature a neverending novelty and complexity. But the number of unique atoms of meaning that you need to describe it is actually very small. And everything around you is a recombination of these atoms. And intelligence is the ability to mine your experience to identify these atoms of meaning that can be reused across many different situations, across many different tasks. And this involves identifying um invariance uh structure uh things that seem to be repeated principles. And these building blocks, these atoms are called abstractions. And whenever\n\nare called abstractions. And whenever you encounter a new situation, you're going to make sense of it by recombining on the fly abstractions from your collection to create a brand new model that's adapted to the situation. So implementing intelligence is going to have two key parts. First, there's abstraction acquisition. You want to be able to efficiently extract reusable abstractions from your past experience, from a feed of data, for instance. And then there's on the-fly recombination. You want to be able to efficiently uh select and recombine these building blocks uh into models that are fit for the current situation. And the emphasis on efficiency here is crucial. How intelligent you are is not just determined by whether you can do something. It's determined by how efficiently you can acquire good\n\nefficiently you can acquire good abstractions from ret experience. how efficiently you can recombine them to navigate novelty. So if you need hundreds of thousands of hours to acquire a simple skill, uh you're not very intelligent. Or if you need to enumerate every single move on the chessboard to find the best move, you're not very intelligent. So intelligence is not just demonstrating high skill. It's really the efficiency with which you acquire and deploy these skills. It's both data efficiency and compute efficiency. And at this point, you start to see why simply making our AI models bigger and training them on more data didn't automatically lead to a GI. We were missing a couple of things. First, these models lacked the ability to do on the-fly recombination. So at training time, they were learning a lot. They\n\ntime, they were learning a lot. They were acquiring many useful abstractions, but then at test time, they were completely static. You could only use them to fetch and apply a pre-recorded template. And that is a critical problem that test adaptation is addressing. TTA adds on the re combination capabilities to our AI. And that's actually that's a huge step forward that gets us much much closer to a GI. That's not the only problem. Recombination is not the only thing missing. The other problem is that these models are still incredibly inefficient. If you take gradient descent for instance, gradient descent uh requires vast amounts of data to distill simple abstractions many orders of magnitude more data than what humans need roughly three to four orders of magnitude more. And if you look at uh uh\n\nmagnitude more. And if you look at uh uh re combination efficiency, even the latest state-of-the-art CTA techniques, they still need thousands of dollars of compute uh to solve ARK1 at human level. And that doesn't even scale to AR 2. And the fundamental issue here is that deep learning models are missing compositional generalization. And that's the thing that ARK 2 is trying to measure. And the reason why is that there's more than one kind of abstraction. And this is really important. I said that intelligence is about mining abstractions from data and then re combining them. There's really two kinds of abstraction. There's type one and type two. They're pretty similar to each other. They mirror each other. So both are about comparing things, comparing instances and merging individual instances into common\n\nindividual instances into common templates by eliminating certain details about the instances. So basically you take a bunch of things, you compare them, you drop the details that don't matter and what you're left with is an abstraction and the key difference between the two is that one operates over a continuous domain and the other operates over a discrete domain. So type one or value centric abstraction is about comparing things via a continuous distance function and that's the kind of abstraction that's behind uh perception pattern cognition intuition and also of course modern machine learning and type two or programcentric abstraction is about comparing discrete programs which is to say graphs and instead of trying to compute distances between them you're going to be looking for uh exact\n\ngoing to be looking for uh exact structure matching You're going to be looking for exact isomorphisms, subgraph isomeorphisms. And this is what underlying much of human reasoning. It's also what software engineers do when they're refactoring some code. So if you hear a software engineer talk about abstraction, they mean this kind of abstraction. So two kinds of abstraction both driven by analogy making either value analogy or program analogy. And all cognition arises from a combination of these two forms of abstraction. You can remember them. They had left brain versus right brain metaphor. One half for perception, intuition, and the other half for reasoning, planning, uh rigor. And transformers are greats at type one abstraction. They can do everything that type one is effective for perception,\n\ntype one is effective for perception, intuition, pattern cognition, they all work well. So in that sense, transformers are major breakthrough in AI, but they're still not a good fit for type two. And this is why you will struggle to train one of these models to do very simple type two things like sorting a list or adding digits provided as a sequence of tokens. So how are we going to get to type two? You have to leverage discrete program search as opposed to purely manipulating continuous interpolated spaces learn with descent. Search is what unlocks invention beyond just automation. All known AI systems today that are capable of some kind of uh uh invention, some kind of creativity, they rely on discrete search. Uh even back in the 90s, we were already using gigantic search to come up with new antenna\n\nsearch to come up with new antenna designs. Or you can take uh Alph Go with move 37 that was discrete search or more recently the alpha evol system from deep mind all discrete search systems. So deep learning doesn't invent but search does. So what's discrete program search? It's basically combinatoral search over graphs of operators taken from some language, some DSL. And to better understand it, you can try to draw an analogy between program synthesis and the machine learning techniques you already know about. In machine learning, your model is a differentiable parametric function. So it's a curve. In program synthesis, it's going to be a discrete graph, a graph of ops, symbolic ops from some language. In ML, your learning engine, the way you create models is gradient descent, which is very comput efficient. By the way,\n\nvery comput efficient. By the way, gradient descent will let you find a model that fits the data very quickly, very efficiently. In program synthesis, the learning engine is searchal search, which is extremely compute efficient. Obviously in machine learning the key obstacle that you run into is data density. In order to fit a model you need a dense sampling of the data manifold. You need a lot of data and program synthesis is the exact reverse. Program synthes is extremely data efficient. You can fit a program using only two or three examples. But in order to find that program you have to sift through a vast space of potential programs. And the size of that space grows cuminally with problem complexity. So you run into this communatoral explosion wall. I said earlier that intelligence is a combination of two\n\nintelligence is a combination of two forms abstraction. Type one and type two. And I really don't think that you're going to go very far if you go all in on just one of them. Like all in on type one or all in on type two. I think that if you want to really unlock their potential, you have to combine them together. And that's what human intelligence is really good at. That's really what makes us special. We combine perception and intuition together with explicit step-by-step reasoning. We combine both forms of abstraction in all our thoughts, all our actions everywhere. For instance, when you're playing chess, you're using type two. when you calculate when you unfold some potential moves step by step in your mind. But you're not going to do this for every possible move, of course, because there are too many of them,\n\nbecause there are too many of them, right? You're only going to be doing it for a couple of different options, right? Like here, you're going to look at the knight, the queen. And the way you narrow down these options is via intuition, is via pattern recognition on the board. So, and you build that up very much through experience, right? You've mined your past experience unconsciously to extract these patterns and that's very much type one. So you're using type one intuition to make type two calculation tractable. So how is the merger between type one and type two going to work? Well the key system two technique is discrete search over a space of program one and the blocker that you run into is explosion. And meanwhile the key system one technique is uh curve fitting and interpolation on the curve. So you take a lot of data,\n\nthe curve. So you take a lot of data, you embed it on some kind of interpolating manifold that enables fast but approximate judgment calls about the target space and the big idea is going to be to leverage these fast but approximate judgment calls to fight commit explosion and make program search tractable. A simple analogy to understand this would be drawing a map. So you take a space of discrete objects with discrete relationships that would normally require connectal search like path finding on a subway system for instance and you embed these objects uh into a latent space where you can use a continuous distance function to make fast but approximate guesses about these great relationships and this enables you to keep explosion in check while doing search and this is what the full picture looks\n\nand this is what the full picture looks like. This is the system that we are currently working on. AI is going to move towards systems that are more like programmers that approach a new task by writing software for it. And when faced with a new task, your programmer like metalarner will synthesize on the fly a program or model that is adapted to the task. And this program will blend uh deep learning subm modules for type one sub problems like perception for instance and algorithmic modules uh for type two sub problems. And these models are going to be assembled by a discrete program search system that is guided by deep learning based intuition about the structure of program space. And this search process isn't done from scratch. is going to leverage a global library of reusable building blocks of\n\nreusable building blocks of abstractions. And that library is constantly evolving as it's learning from incoming tasks. So when a new problem appears, the system is going to search through this library for relevant building blocks. Uh and whenever in the in the course of solving a new problem, you're synthesizing a new building block. You're going to be uploading it back to the library. Much like as a software engineer, if you develop a useful library for your own work, you're going to put it on GitHub. so that other people can reuse it. And the ultimate goal here is to have an AI that can face a completely new situation and it's going to use its rich abstraction library uh to quickly assemble a working model much like a human software engineer can quickly create a piece of software to solve a new problem by\n\nsoftware to solve a new problem by leveraging existing tools in libraries. And this AI is going to keep improving itself over time both by expanding its library of abstractions and also by refining its intuition about the structure of program space. This system is what you are building at India our new research lab. We started India because we believe that in order to dramatically accelerate scientific progress we need AI that's capable of independent invention and discovery. We need AI that could expand the frontiers of knowledge, not just uh operate within them. And we really believe that a new form of AI is going to be key to this acceleration. Deep learning is great at automation. It's incredibly powerful for automation, but scientific discovery requires something more. And our approach at Tendia is to leverage a deep\n\napproach at Tendia is to leverage a deep learning guided uh program search to build this uh programmer like metalarner. And to test our progress, our first milestone is going to be to solve RKGI using a system that starts at knowing nothing at all about RKGI. And you ultimately want to leverage our system for science to empower human researchers and help accelerate the\n"
    },
    {
      "speaker": "Fei-Fei Li",
      "title": "Spatial Intelligence is the Next Frontier in AI",
      "date": "2025-07-01",
      "source_url": "https://www.youtube.com/watch?v=_PioN-CpOP0",
      "transcript": "My entire career is going after problems that are just so hard, bordering, delusional. To me, AGI will not be complete without spatial intelligence. And I want to solve that problem. I just love being an entrepreneur. Forget about what you have done in the past. Forget about what others think of you. Just hunker down and build. That is my So, I'm super excited here to have Dr. Feay Lee. She has such a long career in AI. I'm sure a lot of you know her, I know you too. Um, she's been she's been uh named the godmother of AI. One of the first projects that you created was ImageNet in 2009, 16 years ago. Oh my god. Don't remind me of that. That has over 80, 000 citations and it really kicked off one of the legs of stools for AI which is the data problem. Tell us about how that project came about. It was\n\nhow that project came about. It was pretty pioneering work back then. Yeah. Well, first of all, Diana and Gary and everybody, thanks for inviting me here. Um, I'm so excited to be here because I feel like I'm just one of you. I'm also a entrepreneur right now. I just started a small company. So, very excited to be here. Image then was um yeah, you're right. We actually conceived that uh almost 18 years ago. It's time really flies. Uh, I was a a first year assistant professor at Princeton. Oh, wow. Hi. Hi, Tigers. Yeah. And uh and um the world of AI and machine learning was so different at that time. There was very little data. Algorithms at least in computer vision did not work. There was no industry. You know, as far as the public was concerned, the word AI doesn't exist. But there is a a a still a group of us\n\nBut there is a a a still a group of us starting from the founding fathers of AI, right? John McCarthy and then we go through people like Jeff Hinton. I think we just had a AI dream. We really really want to make machines to think and to work. And with that dream I was my own personal dream was to make machines see because seeing is such a cornerstone of intelligence. Visual intelligence is not just perceiving it's really understanding the world and do things in the world. So I was obsessed with the problem of making machines see and as I was obsessive obsessively developing machine learning algorithms at that time we did try neuronet network but it didn't work. We pivoted to base net to support vector machines whatever it was. But one problem always haunted me and it was the problem of generalization.\n\nwas the problem of generalization. If you're working in machine learning you have to respect that generalization is the core mathematical foundation or or goal of machine learning. And in order to generalize um these algorithms needs data. Yet no one had data at that time in in computer vision and I was the first generation of grad student who was starting to dabble into data because I was the first generation of graduate student who saw the internet the big internet of things. So fast forward um 2000 around 2007ish my student and I decided that we have to take a bold bet. We have to bet that there needs to be a paradigm shift in machine learning and that paradigm shift has to be led by datadriven methods and there was no data. So we're like okay let's go to the internet download a billion images that's the highest number\n\nbillion images that's the highest number we could get on the internet and then just create the world's the entire world's uh visual taxonomy and uh we use that to train and benchmark machine learning algorithm and that was why imageet was conceived and uh came to life and it took a while until there were algorithms that were promising It wasn't until 2012 when Alex net came out and that was the second part of the equation with getting to AI was getting the compute and throwing enough at it and algorithms. Tell us about what was that moment where you started to see oh you seated it with data and now people started the the community started to figure more things out for AI. Right. So between 2009 we published this tiny little CVPR poster. Um um in 2009 to 2012 the Alex that there were three years that we we really believe that\n\nyears that we we really believe that data will drive AI but we had very little signal in terms of if that was working. So we did a couple of things. One is we open sourced. I we believed from the get-go we have to open source this to the entire research community for everybody to work on this. The other thing we did is we created a challenge because we want the whole world's uh smartest uh students and researchers to work on this problem. So that was what we call the image that challenge. So every year we release a uh uh a testing data set. Well, the whole image that is there for training, but we release testing and then we invite everybody openly to participate and then the first couple of years was really setting the baseline. You know, the the performance was in the 30% error rate. It wasn't\n\nwas in the 30% error rate. It wasn't zero or I mean it wasn't completely random, but it wasn't that great. But um the third year 2012 I you know I wrote this in a book that I published but I still remember it was um it was around the end of summer that we were we were taking all the results of image image that challenge and running it on our servers. And I remember it was late night one day I got a ping from my graduate student. I was home um and said we got a result that really really stand out and you should take a look and we we we looked into it. It was convolutional neuronet network something. It wasn't called Alex that at that time that team that Jeff Hinton's team was called supervision. It was a very clever play of the word super as well as supervised learning. So supervision and we look at\n\nlearning. So supervision and we look at what supervision did. It was an old algorithm. Convolutional neuronet network was published in the 1980s. Um there was a couple of tweaks in terms of the algorithm but it was pretty surprising at the beginning for us to to see that there was such a step change. And of course we you know uh we I mean the rest of the history you all know we presented this in the image that challenge workshop in uh that year's ICCV Florence Italy and uh Alex Kushvski came and many people came. I remember young lak also came and um and now the world knows this moment as um the image that challenge Alex that moment um I do want to say that the the it's not just uh convolutional neuronet network it was also the first time that two GPUs were were put together by Alex and his team\n\nwere put together by Alex and his team and and were used for the computing of deep learning. So it was really the first moment of data GPUs and uh uh neuronet network coming together. Now following this trend of the arc of intelligence for computer vision, imagenet was really the seat to solve the concept of object recognition. Then right after that it started to also AI got to the point that could solve the scenes right because you had a lot of the work with your students like Andrew Kaparthi being able to describe a scenes. Tell us about that transition from objects to a scenes. Yeah. So image that was solving the problem of you present you're presented with an image and then you call out objects. There's a cat there's a chair and all that. That's a fundamental problem in visual recognition. But ever since I was a\n\nrecognition. But ever since I was a graduate student entering the field of AI, I had a dream. I thought it was a hundred year 100y year dream which is storytelling of the world is that when humans open their eyes, you know, imagine you just open your eye in this room. You don't just see person person chair chair chair. You actually see a um conference room, you know, with screen, with stage, with people, with the, you know, the crowd, the the cameras, you actually can describe the entire scene. And that's a human ability that is at the foundation of uh visual intelligence and it's so critical for us to use in terms of our everyday life. So I really thought that problem will take my entire life. I I I I literally when I graduated as a graduate student, I told myself on my deathbed, if I can create an\n\nmy deathbed, if I can create an algorithm that can tell the story of a scene, I've succeeded. That was how I thought my career would be. IC Alex that moment came um deep learning took off and then when Andre and then later Justin Johnson entered my lab we start to see signals of um natural language you know and and visions start to to collide and then Andreas and I proposed this problem of captioning images or storytelling and long story short 2015 around 2015, Andre's uh uh Andrea and I published a series of papers that was among the first with a couple of concurrent papers of making literally a computer that captioned an image. It was I I almost felt like what am I going to do with my life? That was my lifelong go, you know? It was such an incredible moment for for for both of us. Um and and um um you\n\nfor both of us. Um and and um um you know last year I gave a TED talk and I actually used a uh something that Andre tweeted a couple of years ago around the time he finished image captioning work. That was pretty much his dissertation. I actually joked with him. I said, \"Hey, Andre, why don't we do the reverse? Take a sentence and generate an image. \" And of course he knew I was joking and he said, \"Haha, I'm out of here. \" The the world was just not ready. But now fast forward, now we all know generative AI, you know, now we can take a sentence and generate beautiful pictures. So, so this moral of the story is um AI has seen an incredible growth and personally I feel I'm the luckiest person in the world because my entire career started at the very beginning of the end of AI winter the beginning of AI starting to you know\n\nthe beginning of AI starting to you know take off and so much part of my own work my own career is part of this change or helped with this change. So I feel so fortunate and lucky and and in a way proud and I think the wildest thing even to achieve your lifelong dream of describing a scenes and even generating them with diffusion models you're actually dreaming bigger because the whole arc of computer vision went from objects to a scenes and now this concept of world and you actually decided to move from academia being a professor to now being the founder and CEO of World Labs. Tell us about what world is. It's even harder than is scenes and objects. Yeah, it is. It is kind of wild. Um, so of course you all know the past it's really hard to summarize the past five or six years. It it for me it's we're\n\nor six years. It it for me it's we're living in such a civilizational moment of this technologies uh progress, right? While computer vision as a computer vision scientist we're seeing this incredible growth you know from image that to image captioning to image uh generation using some of the diffusion techniques. While this is happening in a very exciting way, we also have another extremely exciting thread which is language which is LLMs which is that really 2022 November Chad GBT blasted open the door of truly working generation models that can basically pass the touring test and all that. So, so that this becomes very inspirational even for someone as old as me is to really think audaciously about what's next. And um I have a habit as a computer vision scientist. A lot of my inspiration actually come from evolution\n\ninspiration actually come from evolution as well as brain science. I I I find myself in many moments of my career where I'm looking for the next north star problem to solve. I ask the I ask myself what is what evolution has done or what brain development has done. And there's something that's really important to notice or to to appreciate. The development of human language in evolution took about, if you're super generous, let's just say it took about 300 to 500 million years, less than a million years. That's the that's the length of evolution that took to develop a human language. And pretty much humans are the only animals that has sophisticated language. We could argue about animal language but really language in its totality in terms of being a tool of communication, reasoning, abstraction, it's really\n\nreasoning, abstraction, it's really humans. So that took less than even half a million years. But think about vision. Think about the capability of understanding 3D world, figuring out what to do in this 3D world, navigate the 3D world, interact with the 3D world, comprehend the 3D world, communicate the 3D world. That journey took evolution 540 million years. The first trilabitete developed a sense of vision underwater 540 million years ago. And since then really vision was the reason that set off this evolutionary arms race. Before vision, animals were simple for for you know the the half billion years before vision there's just simple animals. But the next half billion years 540 million years because of the capability of seeing the world understanding the world evolutionary arms race began and and\n\nevolutionary arms race began and and animal intelligence just start to to to to race each other. So for me solving the problem of spatial intelligence to understand the 3D world to generate the 3D world to reason about the 3D world to do things in the 3D world is a fundamental problem of AI. To me AGI will not be complete without spatial intelligence and I want to solve that problem and uh and that involves creating world models. World models that goes beyond flat pixels. world models that goes beyond language. World model that truly capture the 3D structure and the spatial intelligence of the world. And the luckiest thing in my life is no matter how old I am, I always get to work with the best young people. So I um you know I founded a c company with three incredible young but worldclass technologist Justin\n\nyoung but worldclass technologist Justin Johnson, Ben Mildenhal and Kristoff Lassner and we are just going to try to solve in my opinion the hardest problem um in in AI right now which is incredible talent. I mean Chris, he was the creator of Pulsar which was the initial seed before Gosh and Splats that do a lot of differentiable rendering. There's Justin Johnson, your former student who really has this super system engineering mind that got real time neural style transfer. Then you got Ben who was the author of Nerf paper. So this is a super crack team and you need such a crack team because we were chatting a bit about that that vision is actually harder than LLM to some extent. Maybe this is a controversial uh uh uh say thing to say because LLMs are basically 1D, right? But you're talking\n\nbasically 1D, right? But you're talking about understanding a lot of the 3D structures. Why is this so hard and it's behind language research? Yeah. No, I really appreciate that. you you you empathize how hard our problem is. Yeah. So, language is fundamentally 1D, right? Syllabus comes in sequence. I mean, this is why sequence to sequence, sequence modeling is so classic. There's something else that is language that people don't appreciate. Language is purely generative. There's no language in nature. You don't touch language. You don't see language. Language literally comes out of everybody's head and that's a purely generative signal. Of course, you put it on a piece of paper, it's there. But but the generation, the construction, the utility of language is very very generative. The world is far more\n\ngenerative. The world is far more complex than that. First of all, the real world is 3D. And if you add time, it's 4D. But just let's just confine oursel within space. It's fundamentally 3D. So that by itself is a much more combinatorily harder problem. Second, the sensing the the the the the reception of the visual world is a um is a projection. Whether it's your eye, your retina or a camera, it's always collapsing 3D to 2D. And you have to appreciate how hard it is. It's mathematically illposted. So you have to this is why humans and animals have multi- sensors. Um and then you have to solve that problem. And um and third, the world is not purely generative. Yes, we could generate virtual 3D world. It still has to obey physics and all that. But there is also a real world out there. You are now\n\na real world out there. You are now subtly dialing between generation and reconstruction in a very fluid way. And the user behavior, the utility, the use cases are very different. If you dial all the way to uh generation, we can talk about gaming and and metaverse and all that. If you dial all the way to real world, you're you we're talking about uh robotics and all that. But all this is on a continuum of world modeling and spatial intelligence. So it's a and of course the elephant in the room is there's a lot of data on the internet for language and where is the data for spatial intelligence you know it's all in our head of course but it's not as easily as accessible as language. So these are the reason it's so hard but frankly it excites me because if it's easy somebody else has solved it and my\n\nsomebody else has solved it and my entire career is going after problems that are just so hard bordering delusional and I think this is the this is this is the delusional problem. Thank And even thinking about this from first principles, the human brain has a lot more in the visual cortex and amount of neurons that process visual data as opposed to language. How does that translate into the model architectures are very different from LLMs from what you're kind of finding out, right? Yeah, that's actually a really good question. And I mean there's still different schools of thoughts out there, right? There is the LLM a lot of what we see in LLM is really writing the writing scaling law all the way to happy ending and you can almost you can just brute force self supervision all the way. Um constructive\n\nsupervision all the way. Um constructive world model might be a little more nuanced. The world is more structured. there might be signals that we need to use to guide it. You can call it in a shape of prior, you can call it supervision in your data, whatever it is. I think that these are the some of the open uh questions that we we have to solve. But but you're you're you're right and also if you think about human first of all, we don't have all the answers even to human perception, right? How does 3D work in human vision is not a solved problem. We know mechanically the two eyes had to triangulate information but even after that where is the mathematical model and we're not that great humans are not that great as 3D animals. So so um there is a lot that that that is to be to be answered. So we\n\nthat that is to be to be answered. So we are definitely at World Lab. I'm just counting on really counting on one thing. I'm counting on we have the smartest people in in the pixel world to solve this. Is it fair to say that what you're building at World Labs is these whole new foundation models where the output are 3D worlds? And what are some of the applications that you're envisioning? because I think you listed you listed everything from perception to generation. So there's this always this uh tension between uh generative models and discriminate models. So where where what we what these 3D worlds do? Yeah. So I'm not going to be able to talk too much about the details of world labs per se, but in terms of spatial intelligence, that's what it also excites me. Just like like language, the use case is so huge from\n\nlanguage, the use case is so huge from creation which you can think about um designers, architects, industrial uh industrial designers as well as just artists, 3D artists, gave game developers from creation all the way to robotics, robotic learning, the the utility of spatial intelligence model or world models is really really big. So um and then there are many um many related industries from marketing to entertainment to even metaverse. I'm actually really really excited by metaverse. I know so many people are kind of still like uh it's still not working. I know it's still not working. That's why I'm excited because I think the convergence of hardware and software will be coming. So that's that's also another great use case down the road. I'm personally very excited that you're solving metaverse. I gave it a try in my\n\nsolving metaverse. I gave it a try in my previous company. So I'm so excited that you're doing that now. Yeah. Well, I I think I think there's more signal. I mean, I do think hardware is part of the part of the hurdle, but you know, you need content creation and metaverse content creation needs world models. Let's switch gears a little bit. So maybe to some of the audience they might find your transition from going from academia to now being a founder CEO to be sudden but you actually have the remarkable journey through your whole life. This is not your first time you gone zero to one. You were telling me about how you immigrated to the US and you didn't speak any English in your teens and you even ran a laundromat for a good number of years. Tell us about how all those skills shaped who you are\n\nhow all those skills shaped who you are now. Right. I'm sure you guys are here trying to listen to how to start a laundry mat. Um yeah, that was when you were 19, right? Yeah, I was 19 and that was out of desperation. So, um I I had no means of supporting my family, my parents, and I need to go to college to be a physics major at Princeton. So I started a dry cleaning shop and in Silicon Valley language I fundraised. I I was the founder CEO. I I was also the cashier and all the other things and I exited. So after seven years all right you guys are very kind. I've never got claps for my laundry mat but thank you. So, but anyway, I think Diana's point, especially to all of you, I look at you. I'm so excited for you because you're like literally half my age or even even, you know, maybe 30% of\n\nage or even even, you know, maybe 30% of my age and you're so talented. Just do it. Don't be afraid. You know all my entire career of course I did laundry mat but uh even as a professor I chose couple of times I chose to go to departments where I was the first computer vision professor and I that was against a lot of advice you know as a young professor you should go to a place where there's a community and senior mentors of course I would love to have senior mentors but if they're not there I still have to blaze my trailblaze my way right So I wasn't afraid of that. And then I did go to Google to learn a lot about business in Google cloud and and B2B and and all those. And then I started a startup within Stanford because around 2018 AI was not only taking over the industry a AI became a human a human problem. Humanity will\n\nhuman a human problem. Humanity will always advance our technology but we cannot lose our humanity. And I really care about creating a beacon of light in the in the progress of AI and try to imagine how AI can be human- centered, how we can create AI to help humanity. So I went back to Stanford and created human center AI institute and ran that as a startup for for five years. um probably some people were not too happy I ran it as a startup for five years at in in a university but I was very proud of that. So in a way um I think I just love being an entrepreneur. I love the feeling of ground zero like standing on ground zero. Forget about what you have done in the past. Forget about what others think of you. just hunker down and build. That is my comfort zone and I just love that. The other really cool\n\njust love that. The other really cool thing about you, another in on top of all the awesome things you've done, you advise a lot of legendary researchers like Andre Kaparthy, Jim Fan who's at Nvidia, Jad Deng who's your uh co-author for ImageNet, they all went on to have these incredible careers. what really stood out about them when they were students like advice for the audience that you could tell ah this person is gonna change the field of AI and you could tell so first of all I'm the lucky one I I don't I I think I owe more to my students than the other way around they they really make me a better person better teacher better researcher and having worked with so many like you said legendary students um is is really the the the the the the honor of my life. So, they're very very different. Some of them are just pure\n\ndifferent. Some of them are just pure scientists trying to hunker down and solve a scientific problem. Some of them are industrial leaders. Some of them are are, you know, the the greatest, you know, disseminator of uh AI knowledge. But I think there is one thing that unifies them and I would encourage every single one of them of you to think about this. I also for those founders who are hiring this is also my hiring criteria is I look for intellectual fearlessness. I think it doesn't matter what where you come from. It doesn't matter what problem we're trying to solve. That courage, that fearlessness of embracing something hard and go about it and and and be all in and trying to solve that in however way you you want is really a a core characteristic of people who succeed. I learned this from them and I\n\nsucceed. I learned this from them and I really look for young people who have that and then that as a CEO at World Labs in my hiring I look for that quality. So you're hiring a lot for World Labs too. So you're looking for that same trait, right? Yes. Um I get permission from Diana to say that we're hiring. So um yes. So we are hiring a lot. We are hiring engineering talents. We're hiring product talents. We're hiring 3D talents. We're hiring generative uh model um uh talents. So, so I if you feel you're fearless and you're passionate about solving spatial intelligence, talk to me or come to our website. Cool. We're going to open it up for questions for the next 10 minutes. Hi Fay, thank you for your talk. I'm a big big big fan and um yeah so my question is more than two decades ago you worked on visual\n\ndecades ago you worked on visual recognition I am I want to start my PhD what should I work on so I become a legend like you are I want to give you a thoughtful answer because I can always say do whatever excites you so first of all I think AI research has changed because um because academia if you're starting a PhD you you are in academia. Academia no longer has most of the AI resources. It's very different from my time, right? The chip uh the compute and the data are are are kind of are are really low in in terms of resourcing academia and then there are problems that industry can run a lot faster. So as a PhD student, I would recommend you to look for those north stars that are not on a collision course of problems that industry can solve better using better compute, better data and and team\n\nbetter compute, better data and and team science. But there are some really fundamental problems that we can still identify in in academia that it doesn't matter how many chips you have, you can make a lot of progress, you know. Um first of all, interdisiplinary AI to me is a really really exciting area in academia, especially for scientific discovery. There's just so many disciplines that can cross AI. I think that's a big area uh that one could go to. On the theoretical side, I find it fascinating that the AI capability has a 100% outrun theory. We don't know how, you know, we don't have explanability. We don't know how to figure out the causality. There there's just so much in u in the the the models we don't understand that one could push forward. And um you know the list can go on in computer vision there's still\n\ncomputer vision there's still representational problems we haven't solved and also you know um um small data that's another really interesting um domain and so yeah these are the possibilities. Thank you so much Fi. Thank you professor Lee and congratulation again on your honorary doctorate from Yale. I was honored there to witness that moment one months ago and my question is in uh in your perspective will AGI emerge more likely as a unified uh single unified model or as a multi- aent system. The way you ask this question is already two kind of definition. One definition is more theoretical which is define AGI as if there is a IQ test that one passes that defines AGI. The other part of your the other half of your question is much more utilitarian. Is it functional? If it's agentbased, what tasks can it do? I\n\nit's agentbased, what tasks can it do? I struggle with this definition of AGI to be honest. Here's why. the founding fathers of AI who came together in 1956 in Dartmouth you know the John McCarthy and Marvin Mins Minsky of them they wanted to solve the problem of machines that can think and that's a problem that touring Alan Touring also put forward a few years earlier 10 years or whatever earlier than them and and that statement is not a narrow it's not a narrow AI. It's a it it it's a statement of intelligence. So I don't really know how to differentiate that that founding question of AI versus this new word AGI. To me they're the same thing. But I get it that the industry today like to call AGI as if that's beyond AI. And I struggle with that because I feel there I don't know what exactly is AGI different from AI. If we\n\nexactly is AGI different from AI. If we say today's AGIish system performs better than the narrower AI system in ' 80s, '7s, 90s or whatever, I think that's right. That that's just the progression of the field. But fundamentally, I think the the science of AI is the science of intelligence is to create machines that can think and do things as intelligently or even more intelligently as humans. So I don't know how to define AGI. So I don't know without defining it I don't know if it's monolithic. If you look at the brain it's one thing you know you can call it monolithic but it does have different functionalities and you can even there's broco area for language. There's cort visual cortex there's motor cortex. So so I don't really know how to answer that question. Hi um my name is Yashna and I just want to say thank you. I\n\nand I just want to say thank you. I think it's really inspiring to see a woman playing a leading role in this field and um as a researcher educator and entrepreneur I wanted to ask what type of person do you think should pursue graduate school in this rapid rise of AI? That's a great question and that's a question even parents ask me. I really think graduate school is the four or five years where you have burning curiosity. You're led by curiosity and that curiosity is so strong that there's no better other place to do it. It's different from a startup because startup is not just it you have to be a little careful. Startup cannot be just led by curiosity. Your investors will be mad at you. Um it's a startup has a more focused commercial goal and some part of it is curiosity but it's not just\n\nit is curiosity but it's not just curiosity. Whereas for grass group that curiosity to solve problem or to ask the right questions is so important that I think those going in with that intense curiosity would would really enjoy the four or five years even if the outside world is passing by at the speed of light you'll still be happy because you're there following that curiosity. I first I wanted to say thank you for your time to thank you for coming out to speak to us. You mentioned that open sourcing was a big part of the growth from imageet and now with the recent release and growth of large language models we've seen organizations taking different approaches with open source which with some organizations staying fully closed source some organizations fully releasing their entire research stack\n\nreleasing their entire research stack some being somewhere in the middle open sourcing weights or having restrictive licenses and things of that nature. So I wanted to ask what do you think of these different approaches to open source and what do you believe the right way to go about open source as an AI company is? I think the ecosystem is healthy when there are different approaches. I'm not religious in terms of you must open source or you must close source. It depends on the company's uh uh business strategy. And uh for example, it's clear why Facebook uh Meta wants to open source, right? They they um they are right now their business model is not selling the selling the the model yet. They they're using it to grow the ecosystem so that people come to their platform. So open source makes a lot of\n\nplatform. So open source makes a lot of sense. Whereas another company that is really monetizing on on the even monetizing you can think about an open source tier and a closed source tier. So I'm pretty I'm pretty open to that category or or a meta level is I think open source is should be protected. I I think if there is efforts of open source both in public sector as like academia as well as uh private sector is so important. It's it's so important for the entrepreneurial ecosystem. It's so important for public sector that I think that should be tech uh protected. It should shouldn't be uh penalized. Hi, my name is Carl. I flew in from Estonia. I have a question about data. So you called very well the shift in machine learning towards datadriven methods with imageet. Now that you're working on\n\nimageet. Now that you're working on world models uh and you mentioned that we don't have this spatial data on the internet, it exists only in our heads. How are you solving this problem? What are you betting on? Are you collecting this data from the real world? Are you doing synthetic data? Do you believe in that or do you believe in good uh old priors? Thanks. You should join World Labs and I'll tell you. Oh, it's a good one. Um look um as a company I'm not going to be able to share a lot but I think it's important to acknowledge that um we we're taking a hybrid approach. It is really important to have a lot of data but also have a lot of quality data data at at the end of the day there is still garbage in garbage out if you're not careful with the quality of data. So, we'll do one last question. Um, hi\n\nSo, we'll do one last question. Um, hi Dr. Lee. Um, my name is Annie and thank you very much for speaking with us. Um, so in your book, The World I See, you talk the challenges you face as a immigrant girl and woman in STEM. Um, I'm curious to know if there's a time that you feel the moment of being a minority in the workplace and um, if so, how did you manage to overcome this or persuade others? Thank you for that question. I want to be very very careful or thoughtful in answering you because we all come from different background and how each of us feel is is is very unique. You know it it almost doesn't even matter what are the big categories. All of us have moments that we feel were the minority or the only person in the room. So of course I felt that way. Sometimes it's based on who I am.\n\nSometimes it's based on who I am. Sometimes it's based on my idea. Sometimes it's just based on I don't know the the the color of my shirt, whatever that is. Um I have But this is where I do want to encourage everybody. Maybe it is because since I was young coming to this country, I kind of have experienced it is what it is. I am an immigrant woman. I almost developed a capability to not overindex on that. I'm here just like every one of you. I'm here to learn or to do things or to create things. I thank you. That was a great answer. And I really all of you, you're about to embark on something or in the middle of embarking something and you're going to have moments of weakness or or strangeness or or I feel this every day, especially startup life. Sometimes I'm like, \"Oh my god, I don't know what I'm\n\nlike, \"Oh my god, I don't know what I'm doing. \" Just focus on doing it. Gradient desend yourself to the optimized solution. Yeah. All right. That's a\n"
    },
    {
      "speaker": "Satya Nadella",
      "title": "Microsoft's AI Bets, Hyperscaling, Quantum Computing Breakthroughs",
      "date": "2025-06-25",
      "source_url": "https://www.youtube.com/watch?v=AUUZuzVHKdo",
      "transcript": "What are the tools that we can put in the hands of people that will give them that sense of empowerment? That's what I would love to work on. I'm not into this anthropomorphizing AI at all. I come at it as it's a tool. There is going to be a job called a software engineer. It's going to be different. When I look at it, you are really taking a software engineer and saying you're It's my pleasure to welcome the chairman and CEO of Microsoft, Satcha Nadella. Thank you. This is the home crowd. All right, man. San Francisco, you should move to Seattle. I started my career in Seattle. Very fantastic place. Anyone who's successful So Satcha, you've uh emphasized before that AI is uh going to shape all that we do. What does this look like in practice? Um you know at Microsoft, how does this actually drive your strategy?\n\ndoes this actually drive your strategy? And particularly thinking about how AI will influence ideas behind beyond, you know, the immediate incredible product suite, you know, like the broader economy at Microsoft, I I feel we are a platform company, uh, a product company and, uh, a partner company. So I I think of those three dimensions and I've kind of in my 35 years I've lived through uh client client server uh web internet mobile cloud this is the fourth so that's just at least how I pattern match so the first thing that I think about is the platform opportunity uh when I sort of look at all the folks here the interesting thing is the compounding effects of all these platforms right So this AI piece the reason why I think the rate of diffusion is so fast so well um you know and so wide is because it\n\nyou know and so wide is because it builds on the previous generation. I think about like if the cloud was not there uh we wouldn't have been able to build the AI supercomputers which then led to the models which then led to the products right so that compounding effect is the interesting thing to me so that's why you always sort of take the previous platform and build the next platform and you want to be able to get that right and then you got to build the next generation products on top of it right with each one of these platform shifts there's a workload right I mean when I first remember looking at the large scale training job I mean it's kind of a very different workload to what we built for example the cloud with right it's a data parallel synchronous workload which is so different than let's say a Hadoop job\n\nso different than let's say a Hadoop job or what have you um and so the platform itself then completely gets re you know completely relitigated and changed uh so to me that's I think the exciting thing on the platform side it's golden age of system software uh quite But frankly um you know today if I had to think about anybody who's building at the infrastructure layer not just the hyperscalers but even the startups I think that's a tremendous opportunity. Obviously there's a tremendous opportunity in the model side and then the products on top of it. So yeah we think of these and then ultimately what's it for? It's for one thing and one thing alone which is to drive ultimately economic growth and GDP growth. So if I had to ask me my benchmark for AI is is it creating surplus in the world around us one\n\nsurplus in the world around us one community one country one industry one company at a time I mean it seems like the app level you know you guys have built you know sort of the defining apps at the app layer for so many decades. It feels like we're at this weird lumpy moment where um you know maybe the models have popped up and we're sort of astonished by what's happening but then you know sort of the compute and the apps need to actually catch up and you know the hope here is actually the people in this room will be the the people who build those apps. Yeah, it's a it's a good question, right? One of the questions is is the model like uh SQL uh or is it the SAS app itself and the model, right? I mean, I think the place where where does the model end and where does the product begin? Um because if\n\ndoes the product begin? Um because if you sort of say model with some scaffolding and tool calling uh in some infinite loop is the product u if that is what it is then I think that that's where it gets a little confusing but that's like saying a bunch of SQL business logic is with SQL is what is an app. So I think it's still possible for anyone to build uh an app tier on top of a model and you have to sort of abstract yourself and say yeah the model is just like SQL uh was to me and so I think that that I mean I always dreamt of a moment when AI/Machine learning will have a SQL moment because if you think about it right we never had a stable platform layer in the past because everything was vertically built and integrated for the first time in this model layer. Now we have something like a SQL engine uh that we can then use to\n\na SQL engine uh that we can then use to build pretty sophisticated products and these techniques also right I mean just the inference time compute plus tool calling is giving us I think a pretty robust harness to be able to build pretty sophisticated products. Yeah, it's kind of wild how much uh it's the integration piece that is also the app layer now. Yeah, it's uh just you know the the models sitting on their own are incredibly smart but uh right now they feel you know sort of there's just just giant gulf between that and uh the data that really matters to you for business users. I think that's a good observation because I think at least my read of the situation is the model is an important piece. Um the model scaffolding and all this tool calling this uh you know sort of there's a real app server that you\n\nof there's a real app server that you kind of need in order to be able to build sophisticated applications. But the interesting thing is the feedback loop the data path inside the product that then is used in order to post train in order to be able to do the right tool uh you know selection. Um that seems to be the place where product creation uh is all going to happen. Um AI scaling laws are continuing to hold and the demand for intelligence appears to be potentially infinite. Uh yesterday Elon was mentioning that there will be uh you know 99 hyper intelligent beings to one human which is kind of a a wild prognostication but seems possible given this where does the the building for the future of AI truly demand for global uh compute infrastructure you know how do you anticipate these demands evolving as\n\nyou anticipate these demands evolving as models don't just become larger but more intelligent and capable of complex multi-agent interactions yeah I mean look If you sort of really step back and say um you know first if you sort of go with the uh you know compute or intelligence is what of a log of compute um and then you ask the question um how much energy does compute consume let's take in the United States maybe 2% today 3% tops let's say doubles it's 6%. That's like massive because then uh the amount of extra energy that needs to be produced um in order for AI uh to use it is pretty high. I think that's why we all have to sort of keep in mind that if there's one lesson history has taught us is that if you're going to use energy, you better have social permission to use energy. Uh so that means you've got to\n\nenergy. Uh so that means you've got to make sure that the output of this AI is socially useful. Uh in other words, if we really are not creating social surplus, economic surplus as measured by countries and communities, uh then we will we just can't consume energy. And so that to me is the bigger thing like everybody's today hot and bothered about okay, what do I do about energy production? I think the real question in the next 5 years is we've got to produce enough products that are creating great value which I'm very confident of right by by the way in healthcare and education in uh in productivity. So there's many many domains but that's the real challenge for us as a tech industry is to prove unequivocally that what we have created is showing up in real stats uh that is not just an AGI or AI benchmark. I mean the hope is that\n\nor AI benchmark. I mean the hope is that um this will show up in sort of the real things that you sort of interact with on a daily basis that 100% you know you go use you you get a mortgage loan and instead of you know three months or two months of waiting around and you don't know if you're going to get approved or you know there's just so many things that are important parts of your life that you know get drowned in paperwork or bureaucracy that those things could potentially go away. 100%. So I think yeah if you take even take some of the the the public services right I mean if you take any country you know its GDP or take health care like in the United States what is it 18 19% of our cost is uh healthcare and a lot of it like everybody talks about the magical drug blah blah blah except all of the cost is\n\nblah blah blah except all of the cost is in workflow um and so if you really take something like a simple thing like discharge uh the amount like you take the back end of an EMR system with a just a an LLM and a prompt. Uh that itself is going to save so much time and money and energy that it would sort of pay for itself. I mean, it's kind of very direct, right? You spend an incredible amount of GDP on health care and rightly so. But uh every dollar that's spent on clerical work could have been spent towards some sort of treatment that would have saved someone's life or or or the simple time allocation of a physician away from paperwork to the patient uh is right there to be had. What do you see as being the biggest rate limiter for AI deployment today? See, here's the interesting thing, right? And this\n\ninteresting thing, right? And this audience is so young that and none of my metaphors would sort of work. But nevertheless, if you sort of were came in um in the early part of uh you know let's say you were a multinational company preps how the heck did we do forecasts uh like a simple sales forecast? The way one would do sales forecast was you would send faxes. People would then take those faxes and send inter office memos and those inter office memos would be annotated and a forecast would come hopefully before the quarter end. And then suddenly people said with email and PCs and Excel they said let's print your like let me just send an Excel spreadsheet in email people enter number and you have a forecast. So what happened was the work the work artifact and the work flow changed. That is what\n\nand the work flow changed. That is what needs to happen with AI. when someone says I I I I'm going to now do my job but with whatever 99 agents that I am directing on my behalf the workflow is not going to be constant uh right I mean you now are really going to have to change even the scope of your job is going to change so that change management is a real rate limiter right because you're now taking the means of production in an insurance company in a financial services company in a healthcare company in a software company and saying we are going to change everything uh in the way we work in fact we're going to change what jobs they are like you know at LinkedIn I think they took multiple of these functions uh the design function the front-end engineer function the product function put them\n\nfunction the product function put them all together and said we're going to have full stack builders uh that's a change in scope of even a job and so how do you then rebuild the product team with new roles new scopes and what have you. That's to me more the social rate limiter. Not that there's lots of other things around deployment of this technology, getting it out to the world, power is one, there are other issues, but I would say change management when I look at even a lot of the AI startups when I talk to them, everyone has now you know you worked at Palunteer so you know this uh everyone has forward deployment engineers. That's like the exciting thing is the palunteer model which I think is a fantastic model and why is that? That is because of that change management. Uh because I think\n\nchange management. Uh because I think you really need to help customers partners really understand the benefits of any product you're creating but not just the technology but even how to use the technology in a workflow. At YC, we have this uh funny saying that we tell a lot of people here to do, which is um you know, these are some of the smartest uh AI researchers, computer scientists who are just starting out in their careers. We tell them uh go undercover. So go work as a medical biller and see to what degree how many you know quote unquote knowledge work jobs are actually copying pasting from a browser into a spreadsheet into an email and then clicking send and do that for a while and realize like actually these are not necessarily you know using your prefrontal cortex and your highest mind\n\nprefrontal cortex and your highest mind kind of jobs like these are not you know can you imagine so many people like their lives are basically like you We used to we used to, you know, coming up uh at our age, we would call it paper pushing, but you know, they're not paper pushing anymore, but they're sending emails. You know, they're not sending faxes anymore, but they're trying to get business done by like attaching files to things. You know, that seems like a pretty big shift actually that they can Yeah. I mean I I mean I think one of the most understated things as an opportunity for anyone creating products or fundamental breakthroughs um even at the model layer is the amount of drudgery there is in knowledge work right I mean I mean in software engineering we saw that I mean the amount of you know we're taking the joy\n\namount of you know we're taking the joy out of software engineering because you know you were out of your flow uh to be able to stay in the flow to be able to complete a task uh that itself is a great example of what I think is going to happen to all knowledge work. You're absolutely right. The amount of cycles you spend out of band uh collecting information because if you think about the prefrontal cortex and the synthesis part uh you know the amount of time you spend there is pretty low now like having a sophisticated reasoning model and your prefrontal cortex work together. Uh whereas a lot of the mundane stuff is getting done by even some ka agent or what have you. That I think is definitely the frontier. So beyond simply adopting AI tools, uh what are the biggest transformational shifts you're seeing in the field today?\n\nshifts you're seeing in the field today? I think to me um even like I mean look this field is changing so rapidly right I had not even imagined last year even this time that we would get this far with RL um and with basically test time compute. uh and it seems sort of pretty limitless. So the way I think about it is pre-training worked. Uh all the post-training techniques on top of it were fantastic. Then this inference time compute seems to have really added uh in under a massive scaling law. So now I'm interested in whether there is some new algorithmic breakthrough. uh because I always say this entire regime could be changed by one person here who comes up and says I have a more efficient thing to do or a way to do this stuff right so that's you have to be open-minded that the last big breakthrough\n\nthe last big breakthrough algorithmically has not yet been found uh so that's one um I'm always sort of interested in that the other one is what is the next step up uh right because what is the pre-training to RL um the end toend training loop that's the next you know big sample uh that I think is also what I think will happen in the next year uh so I would say what if that is another scaling law breakthrough because we will be like if you sort of take any lab now all of us I think will be working on saying what's a more integrated response reasoning model that we can build u and that I think is going to be the interesting piece there's something very interesting here I think in that uh if you think about like an LLM instance as a consciousness which I think some people are starting to say uh you know it's sort of\n\nto say uh you know it's sort of instantiated you do a bunch of work with it and then it sort of goes away and you open a new chat box and it's you know I guess I'm curious like do you think that that might be one of the things that needs the loop needs to be completed right that like yeah I mean so I'm not sort of I don't to me this artificial intelligence is unfortunately the worst name we could have ever picked. And so I'm not into this anthropomorphizing AI at all. I mean I think of it more I come at it as it's a tool. It's not trying to replicate how we think. Uh it is it it's definitely showing signs of intelligence but it's not uh intelligence that I have and I think of human agency still will matter will be there and we will sort of use these as tools. So that's kind of my position. That said, let's just say oh\n\nposition. That said, let's just say oh yeah, a memory system uh is a good thing. Uh these things do need if I look at the next frontier, I would say there are three things, right? One is memory. Uh the other one is tools used. And then the third which I think is perhaps the most important thing is entitlements. Uh which is basically if I'm going to take action, what entitlements do I have to take action? Right? So these three systems have to be built as first class around the model in order for us to build more sophisticated applications. One of the uh arguments people are starting to make around the future of software is well we have the database and then you're going to have uh basically middleware that is you know I think you know what you call entitlements you it's kind of like access control list like you know what's\n\naccess control list like you know what's the business logic who gets to do what and then you know you you basically put the agent on top there um you is that sort of that's right so that that's why I think about like know people say when you think about the scaffolding layer right you have a model plus scaffold scaffolding the scaffolding now really gets first class by thinking of these three things uh tools use is one memory is one and then entitlements and you put that stuff together then you can create an agent an agent has an ID uh agent has management and provision control on it it has you know so that's the way I think to think about it do you worry with codeg genen like would do you think users at some point will just prefer to uh make software just in time instead of using package software. I mean that's\n\nusing package software. I mean that's something that uh you know we having lots of conversations in the hallway about that because a lot of us in this room you know YC will actually fund a ton of SAS and will continue to do so but you know in the background we're starting to have that worry. There's some venture capitalist friends of mine who are in the audience. They're actually like I actually don't know if I can continue to fund B2B SAS. How do you think about that? Yeah, it's a great question. I mean you know it's it's interesting. Um at the same time uh I look at the number of people who are forking VS code and I say man we must have done something right. Um and u so therefore there is something to be said about building a great um uh IDE um in fact when I think about Excel I think of it as an IDE. Uh so the fact\n\nthink of it as an IDE. Uh so the fact that there's a great canvas uh you can then then bring let's call it the best analyst model to this IDE uh and then create a loop between the canvas and the uh model. Uh so I think yes you can generate applications just in time uh you could have a prefabbed application that is really helping with the feedback loop to the model and I think both of these things will exist together. Do you think there's a role for design in all of this? I mean, basically a h, you know, a human being sitting in front of VS Code uh is sort of like the translator between, you know, the software and what the end user really wants. And then I think some of this idea that software goes away presupposes that just, you know, normal people walking around are going to want to create software. And, you know, I don't\n\ncreate software. And, you know, I don't know if that's going to work. I think that's a good point. So I think the way I sort of say um because one of the the basic question you're asking is what happens to software engineering right I mean that's the let's take the following uh thought experiment right if you sort of said some Martian intelligence came um in uh the 1980s and watched how we all worked oh wow these humans kind of work in the offices and they have a typist pool they have a slide pool and people then work with paper And then if they came back today they'll say god man all eight billion people are typists now right I mean that's what they'll uh sort of you know surmise and so I think what I think will happen is all of us are going to be creating software but there is going to be a job called a software\n\nis going to be a job called a software engineer it's going to be different but I look at it right you you you are really taking a software engineer and saying you're now a software architect right see the I I still the metacognition of your I mean one of my biggest things is man Wipe coding is fantastic until it does stuff that I don't know what the heck happened. Uh so that means I have to have the meta model of my repo and exactly what happened and I'm looking at the change logs right. So when I look at the my favorite feature of GitHub now is to really look at the complete change logs of all the agents that are working on my repo. uh and I think that is where a a lot of the software engineering will be like a good dev manager right I don't know who which dev manager you worked at Microsoft but\n\ndev manager you worked at Microsoft but I really looked and and a dev manager's job was to make sure builds don't break and the code has got good quality um and so to me that is still a thing uh and so there will be a level of abstraction uplift uh even in a world of all of AI agents because one thing that we don't talk about is the legal liability by the way until some real laws change are going to be with humans and institutions humans build. Um, and as long that is true, we're going to have to really make sure the human is in the loop uh at a fundamental level. And that means we will need a lot of tools for humans to be in the loop in order to figure out what these things are doing. In AI development, you see so much, you know, what do you think is underestimated and uh, you know, and what is overhyped by\n\nuh, you know, and what is overhyped by the broader tech industry from where you're sitting? It's not short of overhyping. Let me just put it that way, right? We're at the uh everything is AI all the time. So, it's good. Uh you know, for us all in this industry, we live and die by our ability to get into a frenzy about something new, right? What is the Steve Jobs thing or the Bob Dylan thing, which is you're either busy being born or busy dying. It's better to be being busy being born. So, that's good. The I think the thing that we have to most um worry about and most work on as a as a tech community I would say is that how do we earn that social permission? If there is one thing that I feel to me one of the demos I saw which completely really blew me away was I think in the beginning of 23 um when I was in India and I saw a local\n\num when I was in India and I saw a local developer Daisy chain essentially at that time either GPD3 or 35 uh with one of these India stack speechto text texttospech uh open-source things and then showed a local Indian farmer who was able to sort of use a a chatbot that was built in WhatsApp uh to be able to get some agricultural subsidy, right? Uh by going to a government website. That to me was unbelievable, right? I I I felt like, man, how could something that was built in the west coast of the United States get to a real use case that fast uh thanks to sort of the diffusion rate and basically people uh everywhere. That is the story that needs to be told uh right at scale. Uh that is the underhyped story I think because right now the overhyped thing is the model capability and the model capability is fantastic but man if we\n\ncapability is fantastic but man if we can somehow get the world to recognize that this is making a real difference in the lives of people everywhere we're in good shape. If that doesn't happen, this is all about some valuations of us uh our companies and our industry and it's the same repeat then that is not going to end well. I love that example. Um I mean you can I don't it feels like Microsoft is sort of full of examples of things that uh lower the floor so that you know a lot more people can get access to technology. I mean you could argue go GitHub Copilot is one of the biggest. Yeah. By the way, one of the other ones just you brought it up. There was a World Bank study they did, I think in Nigeria and now they've taken it to Peru or Chile, one of those in in South America. It's, you know, we've been\n\nAmerica. It's, you know, we've been working at Microsoft forever on can there be an intervention in education, right? That's been the dream, man. We've been at it at it for decade after decade and it's made a difference. uh but this study said by access to something like a co-pilot is probably the best tech intervention in education uh in Africa or in Latin America and that's you know that's been the dream I think that we've all had in tech and it's right there within our grasp I guess are there any um interesting observations I'm curious because you know your co-pilot in Windows is uh you know often you know here in tech like maybe people are really obsessed with the latest frontier models, but it's easy to forget like you know Windows and the integration with Windows is actually the first\n\nWindows is actually the first interaction people have with uh you know pre- AGI sort of AI today. Are there any observations from like people using that and like Yeah. No, we're very very excited about Clippy being back as co-pilot. Uh but seriously, I mean like look at to me um the the thing that I find is even in the form factor that we know and love and uh work in which is a good old computer with a mouse and a keyboard, right? The dream has always been in fact the first research group Bill built at Microsoft research was speech um in 1995. Um, and so since then we've been saying, God, like when will speech be first class on PCs. But right now with Copilot, the two things that are just pretty surreal to me, it's kind of like a new browser moment, right? There is both vision and speech. I leave it on\n\nis both vision and speech. I leave it on all the time. It can see what I see and I can speak to it. That seems like a precision mouse movement, right, to me, right? So that is where I think even on existing form factors there is a way to change uh the complete computer use and then there will be new form factors right uh so I think it's an exciting time to be building uh both hardware and modifying existing hardware for what is I think possible in terms of computer use yeah computer use is fascinating in that I mean you have the intelligence and then computer use is actually the superset of uh all the data like your personal data, your work data, your you know all your office docs like everything is accessible right there. Was uh the movie her correct and that you know literally the operating system\n\nyou know literally the operating system is going to embed itself with uh your most trusted agent. Yeah, I mean I think that has been the dream which is can these agents become your computers. Um and they do the computer use for you. Uh and that absolutely I think is the direction of travel. Uh and I think you mentioned the most operative thing which is trust. Uh which is can I trust this to delegate what I want and that means it's about precision. uh it is about sort of uh the privacy uh it's about a lot of these considerations and I think that these all will in time will have to work out. I mean in that respect you know when you look at um you know both your company and you could argue Apple they sort of have to be on the front lines of protecting privacy for all computer users in the world actually.\n\ncomputer users in the world actually. Yeah. I mean so to us you know there are many it's not even sort of there's privacy there is security there's sovereignty these are three big big considerations right privacy every user cares about it uh security is what every tenant or every customer will care about it on top of privacy and then every country will care about sovereignty security and privacy so that's the way to think about it right so you really need to build any product or any system you need to be able to answer the questions on for the people and for organizations and for countries how you cross all those three boundaries. Sachi, you've had an absolutely extraordinary journey at Microsoft starting as an engineer all the way up to CEO. What lessons from that path would you share for the next generation of builders?\n\nfor the next generation of builders? It's not like um you start any journey um with sort of a specific goal of where you want to end up but you do start uh with this uh goal of taking the first spot and sort of having the highest ambition for yourself on what you want to get done. Right? I always say u it's not like uh I was waiting to become CEO to do my best work. The first job I had uh I felt was the greatest job I could ever have when I joined the company in '92. I felt like w if I retired in that job that would be fantastic. Um and that was a great mental model when I look back at it, right? Which is it's not I was not waiting for my next promotion to do something but using the opportunity I was given to do everything I could. Um and I think that that's what uh people who are starting out or who are founders\n\nwho are starting out or who are founders or who are researchers or students today have. And so I would say keep that alive. Uh don't wait for the next big thing. You take the thing that you have as the biggest thing and then make it expansive. Um and then the other thing that I would say is big things are achieved uh by having a team around you. uh learn how to work in teams, making teams great. Uh one of the things that I feel at Microsoft I learned was what it means to be in a project, what it means to work. In fact, that's kind of the big difference between school and work is that right, which is you join a team. Um and you got to figure out you how to make the team successful. the incentives are actually pretty clear except I think the thing that is least thought uh is how do you really make sure you can\n\nhow do you really make sure you can compose as a team and what's your role in it. Every one of us sort of looks and say somebody else's job is to align the team. It's your job to align the team. So I would say if you get those two things high ambition for your own impact, how to work in a team and make a team effective that's magical. Uh here's a fun story. Um, I actually did learn how to uh do product management and project management as a PM on Windows Mobile. And uh when I was employee number 10 at Palunteer, I taught them uh actually how to run a project zero bug bounds and you know all of the sort of you know my PM training at Microsoft turned into the thing that created you know how even Palunteer uh you know runs their product org today which is pretty wild. So, you know, thank you to\n\nwild. So, you know, thank you to Microsoft for that. Um, I'm curious, you know, what are the qualities that you look for in uh, you know, sort of people and teams just because AI is becoming a really key piece of, you know, creative work and engineering work. Um, it's sort of changing the way even you might interview someone and evaluate them for technical or, you know, broader skills. Yeah. I mean, look, I I I'm always looking for uh three qualities in people. Um, one is, uh, in fact, you know, Bill turned me on to this, which is he was describing at one point who are good architects and who are bad architects. And he had this, you know, nice way to uh, uh, summarize it, which is good architects uh, bring clarity and bad architects bring confusion, right? Even if they're equally smart. So I sort of\n\nif they're equally smart. So I sort of always go um to people who innately to can drop into an ambiguous uncertain situation and bring clarity uh it's an understated quality right I mean you just think about the number of conversations you have in a day um about some tough situation tough context uh and people who can bring clarity on what to do what to do next what's the next step that's at a premium So I always am looking for people who bring clarity in uncertain times. The second thing I'm looking for is people who create energy. Uh right in the other words um it's like not just they bring energy but they're also really able to bring multiple constituents. Right? Anybody who comes to me as a leader at Microsoft who says my team is great everybody else sucks. That's not really useful. uh I need\n\nThat's not really useful. uh I need people who can bring people together across the company outside the company create energy right innately and then the last thing is people who are good at solving over constrained problems that's why I think my favorite interview question always is um asking someone to describe like a project they worked on which really was going nowhere and they figured out a path right and the way they go about it uh problems solving uh because essentially what are what do people do who are successful? They take an over constrained problem and figure out how to unconstrain it. Um and that magical sort of three things right which is bringing clarity, creating energy and driving success by solving over constrained problems is what I think leadership is about. But leadership is\n\nleadership is about. But leadership is not about something that you do later in life. You do it every step of the way. Uh I want to cover quantum briefly. I mean you guys just released your um Majorana 1 in February. Um is there an interaction um with the future of AI and you know I think there are probably some quantum researchers in the house. So curious what the future will be. Yeah to me it's pretty exciting to see what's happening. I mean we've been at it man for like it's like I'm the third CEO at Microsoft who's been writing checks on quantum. Um um and we've been at it for 20 plus years and the dream at least or the focus we always had was if we really want to build a quantum quant computer which is a general purpose computer uh you got to solve u for really stable cubits um and error corrected cubits um\n\ncubits um and error corrected cubits um so a fault tolerant quantum computer and we bet on this bas basically a physical property which was envisioned by these Italian physicists Mayorana and that is what uh we went after and finally we've had a physics breakthrough and we were able to actually fabricate that particle and so therefore uh that's what has led to this chip. uh so we feel like one of the big things that we needed to achieve uh has been achieved and the way I think about it is if you say um takes you know if you want to understand the language of nature which is simulation um I think the best way to do it is through a quantum computer because after all uh you know physics and nature is quantum and so therefore but AI is I think of it as an emulator of that simulator right so that's another way to\n\nsimulator right so that's another way to uh perhaps even use AI today with HPC. In fact, a lot of what we are seeing is pretty good advances in uh using um basically HPC plus AI as a way to accelerate advances in chemistry, in physics, in material science. And so quantum would be the next step in it. But we're very excited about what AI plus quantum and HPC in a loop can do. Very cool. Uh we're running out of time. I feel like we could go for another hour if we if we had the time. Um, so just to close, I just wanted to get your sense. You know, let's do a simulation of a sort. You know, you're uh 22 years old and you're level 59 at Microsoft. You're starting your career. You just graduated. Um, what are you working on given, you know, in 2025? You know, if you started over knowing what you know\n\nyou started over knowing what you know now, what would you be working on? How would you be approaching it? you know what would you be excited about? If you look back at the history of Microsoft, how office got built is a you know it's an unbelievable uh story in the sense of thinking of these tools um right a word processor a spreadsheet a slidem tool um what those tools are meant to all of us right I mean I mean ex I mean that's why I always say what's your if somebody asks me what's my favorite product it's always you know VS code is one and the other one is excel out. Uh it's just your you feel so good when you use the tool. It's all about the sense of empowerment you have, the numbers sense you have, the analytical power you have with something simple like a spreadsheet like what an unbelievable scaffolding uh\n\nlike what an unbelievable scaffolding uh it is right uh columns and rows with some sort of tuning machine in the middle um is just breakthrough. And so I would want to work on what are the next set of tools like when I see even copilot today that's kind of where I feel like you know researcher analyst creator these are like the word excel powerpoint right every day I go to them so to me that's what I would love to what are the tools that we can put in the hands of people that will give them that sense of empowerment that's what I would love to work on I have a feeling the people who make those tools are sitting in in this audience right now. Please give it up for Sachin Nadella. Thank you so much. Thank you. Thank you. Incredible.\n"
    },
    {
      "speaker": "Sam Altman",
      "title": "The Future of OpenAI, ChatGPT's Origins, and Building AI Hardware",
      "date": "2025-06-21",
      "source_url": "https://www.youtube.com/watch?v=V979Wd1gmTU",
      "transcript": "We said, \"Okay, we're going to go for AGI. \" 99% of the world thought we were crazy. 1% of the world they really resonated with. You know, in 10 or 20 years, unless something goes hugely wrong, we'll have like unimaginable super intelligence. This is the best [&nbsp; __&nbsp; ] time ever in the history of technology ever, period, to start a company. Well, Sam, thank you so much for joining us and thanks for all the inspiration. I mean, OpenAI itself uh is a true inspiration for any really really ambitious person. Um maybe we just start with that. I mean, what were some of the decisions early that seemed small that turned out to be incredibly pivotal? I mean, just deciding to do it was a big one. Like there we got very close to not starting OpenAI. Um AGI sounded crazy. I was I had Gary's job then and we were\n\nwas I had Gary's job then and we were you know there was like all this other great stuff to do that would work all these great startups and AGI was like kind of a pipe dream and also even if it was possible deep mind seemed like impossibly far ahead and so we had this year over the course of 2015 where we were talking about starting it and you know it was like kind of coin flippy um and I think this is the the story of like many ambitious things where they seem so difficult and there's such good reasons not to do them that really takes a core of people that like sit in a room, look each other in the eye and say, \"All right, let's do this. \" Uh, and those are like very important moments and I think when in doubt, you should lean into them. So, there were just a billion things, a billion reasons why\n\nbillion things, a billion reasons why people might say you shouldn't do it. I mean, off the bat, like even you one of the things you figured out was the scaling laws. It's so hard to remember what it was like. Uh, next year will be our 10 year anniversary and so not not But to to like remember what the vibes were like about AI 10 years ago, that was like way before the first language models that worked. We were trying to like play video games and we had this little robotic hand that could sort of barely do a Rubik's cube and we had no ideas for products, no revenue, no really idea that we were ever going to have revenue. And we were like sitting around at conference tables and whiteboards trying to come up with ideas for papers to write. It it was such it's it's like hard to explain now because it\n\nit's like hard to explain now because it looks so obvious now how improbable it seemed at the time and how the idea of chatbt was like completely in the realm of science fiction. I mean, one of the things that really jumped out at me was uh you sort of, you know, rallied this idea that you should be working on AGI and then simultaneously you found the smartest people in the world who were working on that thing. That second part was sort of easier than it sounds. If if you say we're going to like do this crazy thing and it's and it's exciting and it's important if it works and other people aren't doing it, you can actually like get a lot of people together. Um, and so we were we said, \"Okay, we're going to go for AGI. \" 99% of the world thought we were crazy. 1% of the world that really resonated with. Turned out\n\nthat really resonated with. Turned out there were a lot of smart people in that 1% and you could get like there wasn't really anywhere else for them to go. So we were able to really concentrate the talent and it was a mission that people cared about. So even though it seemed unlikely, if it worked, it it seemed super valuable. And we've observed this many times with startups. If you are doing the same thing as everyone else, it is very hard to concentrate talent and it's very hard to get people to like really believe in a mission. And if you're doing like a oneofone thing, uh you you have a really nice tailwind there. Okay. So, some people in this room might be thinking like, should I try to start an OpenAI scale thing off the bat? Uh you know, you you also worked on Loop your first time around.\n\nworked on Loop your first time around. You know, were there lessons from that? OpenAI was not an open eye scale thing off the bat. OpenAI was like eight people in a room and then it was 20 people in a room and it was very unclear what to do and we were just like trying to write a good research paper. Um so the the things that eventually become really big do not start off that way. I think it's important to like dream that it could be big if it works. Nothing big starts that way. and and and Venode Kla has this quote that I've always liked which is there's a very big difference between a Z million dollar startup and a zero billion dollar but they both have zero dollars of revenue. They're both like a few people sitting in a room and you're both trying to they're both just trying to get the first thing to work. Um, so the only the\n\nfirst thing to work. Um, so the only the only advice I have about trying to start something big is pick pick a market where it seems like there's some version of the future where it could be big if it works. But other than that, it's like one dumb foot in front of the other for a long time. How people use chatd has changed a lot. How people use your API has changed a lot. Uh, what surprises you the most with the latest models like 03 and what emergent behaviors or use cases are standing out to you right now? I think we're in a really interesting time. We haven't been in one of these for a while. Uh but like right now we're in an interesting time where the the product overhang relative to what the models like what the models are capable of is here the products that people have figured out to build is way down here.\n\nfigured out to build is way down here. There's a huge even if the models got no better which of course they will uh there's a huge amount of new stuff to build. And also like last week 03 cost five times as much as it did this week and that's going to keep going. I think people will be astonished at how much the price per performance falls. Um we have an open source model coming out soon. I think people are going to be Yeah, I don't want to like steal the team's glory and pre-announce this, but I think you all will be astonished. I think it will be like much better than you're hoping for and the ability to like use it to run incredibly powerful models locally is gonna like really really surprise people on what's possible. Um but so you have this world where like the model capability has gone into like\n\nthe model capability has gone into like a kind of new like a very new realm. Um the cost of the APIs are going to keep falling quite dramatically. the open source models are going to be super great and I think we have not yet seen the level of new product innovation that the reasoning models are capable of which makes sense they're pretty new but this is like an exceptional time to go build a company that takes advantage of this sort of new thing that exists this sort of new square on a periodic table that no one has built with yet. So only in the last month I think have we really started to see startups that are saying okay like reasoning models are different you know the whole interaction model is different and really building for that. I mean for me even memory has turned into it feels like I'm talking to\n\ninto it feels like I'm talking to someone who knows me which is interesting. Yeah me memory is my favorite feature that we've launched this year. I don't think most people at open air would say that because and we've launched a lot of stuff but I love memory and chatbt. Um and I think it points to where we will hopefully go with the product which is you will have this like entity that gets to know you that connects to all your stuff and that is like proactively helping you. It'll it won't just be like you send a message and it sends you one back. But it'll like be running all the time. It'll be looking at your stuff. It'll know when to send you a message. It'll know when to go do something on your behalf. you'll have, you know, special new devices and it'll be integrated on every other service you use and you'll just\n\nother service you use and you'll just have this thing running with you throughout your life. I think memory is the first time where people can sort of see that coming. Uh, back in the day you tweeted a little bit about uh her where, you know, when is that coming? Can you give us an alpha leak around that? I think gradually is the answer. No, no. If I had a date in mind, I would probably just be excited and tell you. Um, but like it's a little bit here with memory, right? It'll be a little more here when it's persistently running in the background and sending you stuff. It'll be a lot more here when we ship the first new device. Um, but I think the key of her is not the little piece of hardware. It's that this thing got to a point where it could run in the background and feel like a sort of AI\n\nbackground and feel like a sort of AI companion. I guess we're starting to see um the power of LMS with integrations into your real data. Uh, you know, I've heard rumors that MCP is coming to OpenAI. I think today. Yeah. Oh, today. What has been surprising about the actual integrations? Like have you been seeing people actually operating on their core database? You know, at YC we actually have that agent infrastructure internally and we use it all the time. Definitely people are starting to use chatbt as this like operating system with everything with their whole lives in it. Um and integrating into as many data sources as possible is important. um devices that are always with you, like new kinds of web browsers, the connection to all data sources, memory, and then a model that's persistently\n\nand then a model that's persistently running. You put all that together, I I think you get to like a pretty powerful place. Do you think that'll be in the cloud in the future, or will it be on our desktop or some mix of both? Some mix of all of that. Definitely people will run local models for some things like man, if we could push like half the chatbt workload onto your local devices, no one would be happier than us. like our cloud. We I think we will run the like largest and most expensive piece of infrastructure in the world pretty soon. So, if we could push some of that off, that'd be great. Um, but a lot of it will run on the cloud. Is it surprising to you how hard it is to get compute? I mean, we've gotten really good at it, but it is we we went from like a no a zero like no chatbt. com didn't\n\nno a zero like no chatbt. com didn't exist two and a half years ago to like the fifth biggest website in the world. It'll be the third at some point, hopefully someday the first if our current growth rates continue. And I think doing that is just hard no matter what. Like that's you usually get longer than we've gotten to to scale up a like infrastructure to for a new company. But you know, there's like a lot of people that want to help. Well, it's incredible incredible work that you guys have been doing. Um, we're seeing reasoning models like 03 and 04 mini uh evolve in parallel with multimodal models like 40. What happens when these two threads converge? And what's the vision for GPT5 and beyond? I mean, we we we won't get all the way here with GPT5, but eventually we do want one integrated\n\neventually we do want one integrated model that can like reason when it needs to and generate like real-time video when it needs to do that. If you ask a question, you could imagine it thinking super hard, doing some research, writing a bunch of code just in time for like a brand new app only for you to use or kind of like rendering live video that you can interact with. Um, so I think that will feel like a real new kind of computer interface. that AI sort of somewhat already does, but when we get to a model that has like true complete multimodality, like perfect video, perfect coding, everything and deep reasoning, that will that will feel like quite powerful. It seems like that might be a hop step over to the uh embodied aspect. You know, that's having vision, having speech, and having reasoning is a hop step to, you\n\nhaving reasoning is a hop step to, you know, yeah, basically the robot we want. our our our strategy has been nail that first um and then make sure we can connect that to a robot. But the time for the robot is coming soon. Um I think I am very excited about a world where when you sign up for like the highest tier of the chatbt subscription, we send you a free humanoid robot too. I mean that future is going to be pretty wild being able to have robots that do real work in the real world. I think we're not that far away now. uh the mechanical engineering of robots is been quite difficult uh and and the sort of AI for the cognitive part has been quite difficult too but it feels within grasp um and I think in a few years robots will start to do super useful stuff making a billion robots is still going to take a\n\nbillion robots is still going to take a while but I don't know I'm interested in the question of how many robots do you need to fully automate the supply chain like if you make a million humanoid robots the oldfashioned way can they run the entire supply chain drive the mining equipment like drive the container ships run the you know foundaries and make the new robots and then maybe like you actually can get a lot of robots in the world quickly but the demand for human robots in the world will be far more than we know how to think about with the current supply chain. I guess uh when you were sitting in my seat, one of the things you led was uh you know a lot more investment into hard tech at YC. Um sitting here where we are geopolitically, you know, what what do we need to do to make sure that America can actually have\n\nmake sure that America can actually have manufacturing in industrial capacity, you know, we can't even build precision screws and large sheet metal without crazy cost overruns. You know, how what can we do to make sure that happens here? There are all of these answers that people throw around and have thrown around the same things for a while and it clearly hasn't worked. So, uh I think all of the policy is worth trying, but my instinct is we need to try something new. We shouldn't keep trying the same failed stuff. And you know, like AI and robotics does give us a new possibility of a way to bring manufacturing back here and to bring sort of these complex industries here in a really important new way. And I would say that's at least worth trying. Yeah. um what does defensibility look like here? You know, one of the classic\n\nhere? You know, one of the classic questions is, you know, how do I uh start a startup that doesn't get run over by Open AI? That's sort of the number one question that's in our chat. look, we're going to do our thing hopefully very well. We are going to try to make the best super assistant out of Chat GBT that we can. we're gonna add the things that we think we need to add to that. Um, but that is like one small part of the opportunity in front of us. And it makes us sad when people are like, I'm going to start a new startup and I'm going to like make a version of Chaz GBT because we think we're going to do that pretty well and we have like, you know, kind of a big head start, but there is so much more space to go after and there are so many incredible other companies that have been built using our\n\ncompanies that have been built using our platform. Um, we would like to make it easier for you all. We would like to do more things like finally now you can imagine that chat GPT could drive a lot of traffic to new startups and that there's like a new kind of app or agent or whatever you want to call it store that we could do inside of ChatgPT and drive traffic to new startups to help. You could imagine that we could do like a signin with OpenAI and people could bring their, you know, personalized model and easily connect it to a new startup and that would probably help in a bunch of ways. Um so we want to be a platform for other people to build stuff. Our advice is like don't build our core you know chat assistant. Um but there is another problem which is and this is the same for every every\n\nand this is the same for every every kind of like moment that I've seen in startup history. People get excited about the same thing at the same time. And so rather than go build the thing that you have thought of that is not everybody what else is doing, we are like very social creatures and we get very influenced by what other people are doing. And I bet if Gary listed off the five ideas that he hears most often of what people want to build with AI, like half the room would raise their hands for working on one of those five. and and the I there is hopefully in this room um the person who's going to start a company that is like much bigger than OpenAI someday and I would bet that person is not working on any of the five. So it is hard to build something defensible if everybody else is trying\n\ndefensible if everybody else is trying to do the same thing. Sometimes it works. It's not impossible. But the best the most enduring companies are usually not doing the same thing as everybody else. And that gives you time to figure out what the great product is, how to build the technology before you have to answer the defensibility question. It took us a long time to figure out how to answer the defensibility question for CHBT. Um, we had built this thing and for a long time the only defensibility was like we had the only product out in the market. Um, and then we kind of like be a brand that started to be wellknown and now we have things like memory and connections, a whole bunch of other stuff that really is defensible. But you know that was like a fair criticism of us for a long time. We didn't have any\n\nus for a long time. We didn't have any defensibility strategy. We just like had the only good thing out there and then you have some window before which you have to build defensibility. One of the things we've talked about in the past is that uh we both are big followers of uh Peter Teal in that he talks a lot about being contrarian but right. Um I think that you've Peter is a genius. Absolutely. And you found you've been contrarian in really fundamental ways. I mean going back you know to the beginning of the conversation people thought oh this idea that the scaling laws are valuable today it's you know taken as basic truth but it was exactly the opposite of ground truth not that many years ago when you got that push back you know what did you and your team feel did you say you know fui I won't do\n\nfeel did you say you know fui I won't do what you tell me you know I'm going I'm going to push back against you know getting push back means that this is a contrarian area and we're going to bet here and we're going to be right. It is hard to have conviction in the face of a lot of other people telling you you're wrong. And I think people who don't who say it's easy are not being honest. It gets easier over time. Um but like I remember one time I can say this one because it got publicized um in early not early a few years into OpenAI where Elon sent us this really mean email. we've been working together for a while and said we had a zero% chance of success. Like not zero. Zero that we were totally failing. We had showed him like GPT1 recently. He was like, \"This is crap. It's not gonna work. Doesn't\n\nis crap. It's not gonna work. Doesn't make sense. \" And I was really a hero of mine at the time. And I remember going home that night and being like, \"What if he's right? Like this [&nbsp; __&nbsp; ] sucks. \" You know, you're working so hard on this thing. Like you're pouring your life force into it. And you have these people who are smart and that you look up to and they say, \"You are totally wrong. \" um or you know this is just not never going to work or you don't have defensibility, someone's going to kill you, this is going to happen, that's going to happen. And I don't have a magic answer other than it's really tough and it gets significantly easier over time, but it's going to happen to all of you and you just like get knocked down and get back up and brush yourself off and try to keep going. Let's talk uh AI agents. you\n\nkeep going. Let's talk uh AI agents. you know, that's uh sort of level three AGI. Uh this is the year I think Greg Brockman talked about recently. This is the year of the agent. Um with tools like operator code interpreter, what kind of workflows do you think will disappear uh or appear that we just aren't ready for yet? For a long time, chatb was like a Google replacement. You could ask it something that was about as long as a Google query. you know, maybe like half an hour worth of Google queries it could assemble together. And that was still pretty good, but it didn't it it it still felt like a more advanced version of search. But now you start to see things where you can like really give a task to codeex for example um or to deep research and you have this thing go off and do a bunch of stuff and come back to\n\nand do a bunch of stuff and come back to you with like a proposal. It's it's like a very junior employee that can work on something for like a short period of time. And if you think about how much of the work that the world does is work that can be done in front of a computer in like few hour chunks where you then have someone say like okay that was good enough or not. It's quite a lot. So I I think this is going to go this is part of that overhang we were talking about earlier but I think this is going to go quite far and I think with current 03 to say nothing of our next model you can build a lot of experiences like this. How do you see the future of human computer interaction and interfaces and what are sort of the limitations of those interfaces that you know motivated you? You know, one of the things that I\n\nyou? You know, one of the things that I think sci-fi got right is the idea of the interface almost melts away. Like voice interfaces today we think of as something that is kind of sucky because they don't work that well. But in theory, if you could say to a computer, \"This is exactly what I want to happen today. and if there's any changes, if like I'm delayed, if you know something happens, I trust you to like go off and do all those things, but like I don't want to be interrupted. I don't want to think about it. Um, and it just did it all and you trusted that it worked. That would be an interface that almost melted away except when it, you know, was like a super great human assistant needed to talk to you. But you would be like really thrilled. When I like use my phone today, I feel like I am like\n\nphone today, I feel like I am like walking down Time Square in New York getting like bumped into by people. I love my phone. It's an incredible piece of technology, but it's like notification here, this thing happening, you know, this thing popping up, like bright colors, like all kinds of flashing things in me. It's just stressful. And I can imagine an interface where the computer mostly melts away. It does the stuff I need. Um, but I really trust that it's going to do a great job of like surfacing information to me, making judgment calls about when not to, acting on my behalf when it should. Uh, and I'm I'm quite excited for that. Uh, I'm not going to like tell you what the new device is. Well, I'll tell you like one-on-one, but I'm not going to tell the room, but it's very like I I hope I\n\nthe room, but it's very like I I hope I hope we can sort of like show people a different way to have computers. Is that one of the reasons why you brought on one of the greatest living designers on the planet, John, in Johnny Ivan, IO? Yeah, he he is he is amazing. Um, he is he really lives up to all the hype. I I think we've only had kind of two big revolutions in computer interfaces really in the last like 50 years. So we had the you know keyboard and mouse and screen and then we had touch and phones and the opportunity to do a new one doesn't come along that often and I think AI really does totally open the playing field for something completely new and I think if you got to pick one person to bet on to figure that out he is the obvious bet. Yeah. So one of the things that uh we've been debating at YC\n\nthings that uh we've been debating at YC that you know don't know if this is good might be scary for a lot of software engineers who want to create B2B SAS is this idea that uh what if in the future you had your you know underlying database you have an API layer that is uh you know your access control and enforces your business logic and then the interface is the LLM like your computer is literally you know the agent and uh you have just in time software. They're like complex flows. You're just going to go in and it'll code gen an artifact or, you know, a pain for you that like does that thing you wanted and it'll go in the file and it'll bring it back if you ever need it. That's going to happen. Yeah. Look here here there are two ways you can look at this. Uh first of all, assume you all are like\n\nfirst of all, assume you all are like starting startups or have started startups, think about starting startups. This is the best [&nbsp; __&nbsp; ] time ever in the history of technology ever, period, uh and but part of the reason it's the best is because like the ground is shaking and it's true there are a lot of these challenges. So on one hand you can look at something like that and say we have been a you know SAS company and now like all of the code can just be generated right in time when someone needs it and what does that mean for us or you can look at it and say wow this is going to happen but it's going to happen to everybody and the way startups win is when they can iterate faster than big companies and they can do it at a much lower cost. like big companies have a lot of advantages but they iterate very\n\nlot of advantages but they iterate very slowly um and they you know if something is like very cheap then a lot of their big advantages go away. So you can look at this all of these problems one way or another. But the way I would recommend looking at them is everybody is going to face the same challenges and opportunities. But when the clock cycle of the industry changes this much startups almost always win and we've probably never seen it change this much. Act on it from that direction. I think you'll be in incredible shape. maybe you can invite me sometime to do a talk about like what the areas of defensibility that you can build over time are because I think that is the inherent question. people are like, \"Oh, okay. You know, I'm a SAS company. There's going to be just in time software. \" I think the question\n\ntime software. \" I think the question behind the question is like, \"What are actual defensibility strategies? \" So, that would be a fun talk someday, I guess. Uh you know, backstage at one of the last events we had uh you know, we were talking about the this there's this book that's sort of like the classic Mckenzie, which is the seven powers. And uh I was just thinking about that like I never would have thought like the two of us technologists sitting around actually citing uh a book that you know Mackenzie consultants are known for. Feels so wrong. Yeah. I don't know aesthetically it feels terrible but yes seven powers. I guess we're entering this age of intelligence. I love uh that essay of yours. What do you think this era will mean for you know how we live uh how we work and how do we create\n\nuh how we work and how do we create value for each other as a society? You know, in some sense, the the whole arc of technology is one story, which is we discover more science, build better tools, all of society like builds the scaffolding a little bit higher. Um, and we we have this more impressive tool chain. And the whole point of it is that one person can do way more than they could before. And this has been going on for a long long time. each generation. Uh certainly I mean if you compare a person today from a person 100 or thousand years ago, one person is incredibly more capable and the kind of like social contract is that you put something, you know, you build the next layer of scaffolding. But what someone can do now with this new set of tools, with this, you know, this new layer that's been built in is pretty\n\nnew layer that's been built in is pretty incredible. And I think the one of the things that will feel most different about these next 10 years versus these last 10 years is how much a single person or a small group of people with a lot of agency can get done. And that is a bigger deal than it sounds like u because coordination costs are are huge. And when we can empower people with more knowledge, more tools, more resources, whatever, I think we won't just see like a little bit more stuff get built, but because of these kind of coordination costs across people, we'll see like a real stuff change. So I think the the amount that one person or small team get done, the satisfaction in doing that and and most importantly like the quality of stuff we'll all get for each other will be quite remarkable. When I think back\n\nquite remarkable. When I think back about the OpenAI story, I often think about just the kind of key few tens of people that did the amazing work that led to what we all have now. But I try to remember that I always also have to think about like the tens of millions of people, maybe it's more uh throughout history that started like digging rocks out of the ground, figuring out how semiconductors work, building computers, building the internet, and on and on and on that let this small group be able to work at such a high level of impact that they never would have been able to do without the collective output of society. Is it surprising to you to what degree? I mean, this room is you're preaching to the room of the converted, but uh this is awesome, by the way. I mean, this is like the collected set of people who are\n\nlike the collected set of people who are going to go create the future, but um there's, you know, yeah, there's there's maybe like never been a gathering like this in one place before. This is this is very cool to see. But at the same time, you know, we're in some ways, uh, this is the leading cutting edge of all of society because there are seven and a half billion people who probably h, you know, have not even tried this stuff yet. And not only that, their main interaction with it is uh, that it doesn't work, that it hallucinates. You know, what what do you have to say to the 3, 000 people in front of you right now? Just this is the the thin edge of the spear. We are literally teaching people and giving people this technology. First of all, that's like a great place to be in. Um, one of the one\n\ngreat place to be in. Um, one of the one of the most fun things about working at YC is you get to like live on the leading edge and you get to be around the people who are the advanced guard. Um, and that's just like a fun way to live your life and you get to see what's coming and, you know, hopefully have some small amount of input into shaping it. Uh, but I don't know. I think AI is like somewhat mainstream right now. I the the the negative the way that it's not is most people still think of AI as chat GPT and a lot of people use chat GPT but they use it like a a chatbot and they have not yet wrapped their head around what's what's coming next and probably you all have but I don't know it's like a great privilege to get to live a little bit in the future and uh you know go build stuff for everybody else coming along. So,\n\nfor everybody else coming along. So, you're sort of one of the best people in the world at um bringing together the smartest people. Um what are some of the hardest lessons you've had to learn about hiring? A lot of the people in this room like they have never managed a person before, let alone gotten someone to quit their, you know, six to seven figure job at some big company to come work on their revolution. hiring really smart people who are clearly really driven and really productive and can work as part of a team I think does get you 90% of the way there and the degree to which people focus on other things to hire for always surprises me. So I think you know given that we can't do the full 45 minutes right now really smart people driven curious self-motivated hardworking uh like good track record of\n\nuh like good track record of accomplishment and can work really well as part of a team and sort of aligned with the company's vision and so everybody's at least going for the same the same direction that works pretty well. I mean by uh strong track record do you mean the person who's like you know sort of been an administrator and had like the the you know top name at the top institution for 20 years or do you mean like because you you went the other way? I I don't especially early in a startup I don't believe in hiring those people. There experience is valuable and there are times where you you really need that but I have not had success and to be frank like YC has not had that much success trying to start with like the very senior eminent administrator as one of the like you know as the first hire\n\nof the like you know as the first hire in a startup. Um I would I would take like young scrappy but clearly like get stuff done um over the person who has like the extremely polished track record. There will come a time where you need some of those people later. But I don't know how you do it, but when I when I was like reading YC applications, I would like never look at the resume items. You know, you worked at like Google or went to this college. I never cared. I would always go right to like what's the most impressive stuff you've done? And then sometimes I would like not be convinced by that and go look at the resume. But that was always like a backup to me as a secondary thing. So sort of look look at what they've actually what they've coded, what they've built, like their velocity, how they think about problems and solve\n\nhow they think about problems and solve them. I see PB back there. He has this quote, I hope it's his quote because I've attributed to him a bunch of times of hire for slope, not y intercept. And I think that's just like unbelievably great advice. Let's talk about um being CEO of OpenAI. What are some of the hardest lessons there just overall? I don't recommend it. Um, no one single challenge would be that hard, but the number of things we have to do at the same time and the kind of like number of other big companies that are gunning for us in various ways, it's just like more context than I thought it was possible to handle at once and more sort of like switching from like big big decision to like totally unrelated but also huge decision. Looking ahead 10 to 20 years, what are you sort of most\n\n20 years, what are you sort of most personally excited about? You know, and what should uh people be building now to make that future possible? You know, there are people who are scientists, there are people who are software engineers, there are people who are I mean this is an all technical crowd. Look, there there's a lot um you know, in 10 or 20 years, unless something goes hugely wrong, we'll have like unimaginable super intelligence. And I'm very excited to see how that goes. Forced to pick one thing to just not leave it as like a vague answer. Um I think AI for science is what I'm personally most excited about. I I am a believer that to a first order approximation all long-term sustainable economic growth in the world like everything that leads to people's lives getting better um is basically\n\ngetting better um is basically discovering new science and having reasonably good governance and institutions so that that science can get developed and shared with the world. But if we could vastly increase the rate of new scientific discovery with AI, uh I believe that would compound to just incredible increases and wonders for everyone's lives. So I think I'd pick that on that time frame. I guess uh one of the things I've been always really impressed by is uh you know you were you you know personally recruited Helon to come do Y Combinator and uh they're doing incredible things over on the Fusion side. Um, was that something that you were thinking about even all the way back then or you know obviously energy and climate was sort of a part of uh, you know, what everyone's worried about even back then. But this is a little bit\n\neven back then. But this is a little bit embarrassing. I've been obsessed with energy and AI as like the two the things that I thought would be the two most important things or at least the ones I was going to be most that I felt most passionate about for a long time. and and really like the two areas that I I knew I wanted to like concentrate time and capital towards. I I cannot recall ever thinking until like after starting Open AI that they were going to be so obviously related that you know that that energy would be the eventually the fundamental limiter on how much intelligence we could have. And I don't know how I missed that because I usually am good at thinking about things like that but I I really did think of them as like very independent. you know, we were going to need AI to have all the ideas, energy to\n\nneed AI to have all the ideas, energy to make all the stuff happen in the world. And I obviously right after starting open AI, I got obsessed with meaning energy for AI. But like pre205, I think I thought of them as orthogonal vectors. I mean, you I'm sure you've seen that chart that um you know, all the effective accelerationists in the room have seen around basically having a high standard of living like the sort of really it's I'm obsessed with this chart. I've been obsessed with that chart a long time. um it's directly uh related to the amount of energy that any given person has access to. Yeah. I I think this is one of the most amazing charts over a long like long long period of human history is the correlation of quality of life and abundance of energy and cost of energy. So that was that\n\nand cost of energy. So that was that chart and charts like that were a significant reason that I got obsessed with energy in the first place. It it is it is just this like crazy high impact thing. It sounds like it wasn't entirely uh interdependent. It was more you had twin interest, but you've literally woven them together. I had like the one interest of like radical abundance and just like what what what were the kind of technological leverage points to just like make the future like wildly different and better and these is the two kind of key things for that. But not as not as much as the same vector. Now I think a lot about like how much energy can we actually build on Earth before we just heat the planet too much from running the GPUs and like how long can we go before we have to put all the GPUs\n\nwe go before we have to put all the GPUs in space. Um but at the time yeah I really thought of them differently. I mean it seems like one of the uh defining beliefs that technologists uh uniquely ideally have that they believe that we can actually create that sort of abundance. You know, if you have intelligence on tap and then you have energy on tap, then um how does that go? It's like, you know, all uh all watched over by machines of loving grace. I I've never been to one of those deg conferences in Europe or whatever. Um but I've always kind of wanted to go to one. This is the anti-dgrowth. This is the anti-drowth conference. Totally. But I would like love to be like sitting, you know, in the dark in the cold with no one pulling out their phones and just like talking about how horrible everything was and there was no hope.\n\neverything was and there was no hope. Like I would love to experience that mindset once because I've never felt it. Um, and I think it is like it it is one of the movements that has been ever hardest for me to identify with. Obviously, this is like my crew and my world, but the the sort of like the optimism of startups of San Francisco, of the technology industry, of AI, of what all y'all y'all will do, uh like that is that is like the natural space my brain abides and it's very hard for me to really empathize with the other side of that, but I'm pretty sure we're right and they're wrong. How do we get there though, right? you this incredible vision of technology actually creating for abundance for others. I mean you've already done so much but you know point us the way like you know how how else do\n\nus the way like you know how how else do we get there? How do we make it faster? You know does government play a role in this? Almost just about five years ago like pretty much this week we put GPT3 into an API and people started playing with it and it was barely usable. It was quite embarrassing. Um and in five years we have gone from this like thing that could barely write a sentence to a thing that is like you know PhD level intelligence in most areas. Um five more years I think we'll be able to maintain the same rate of progress. And I think if we do that if we also build out the infrastructure to serve that to people then everybody in this room will figure out how to take that technology and adapt it to what everybody needs. The the analogy I like most for AI is the transistor like the historical tech\n\ntransistor like the historical tech technical analogy. You know, some people figured out like a new really important scientific discovery and society, the economy, whatever you want to call it, just got to work, just did its thing. The magic of that just figured out how to make incredible value for people and really over a fairly short period of decades significantly ramp up quality of life. I think this will be even faster and steeper than that. But I think it'll go in directionally the same way. You know, we need to make the great technology, figure out the remaining scientific stuff, which I don't think there's much left. We need to figure out how to build out the infrastructure that you all will need to be able to service and then you all have got to go figure out what what people in the world\n\nfigure out what what people in the world need um with this new magic. So, let's uh flash back to 2005. Uh the very first batch of Y Combinator. Um, how did you hear about Paul Graham? You were reading his essays. I was reading his essays. So, I'd heard about like he kind of had this cult following on the internet, but I heard about uh what was then called the summer founders program and now it's just called Y Cominator from Blake Ross who I lived in the same freshman dorm with and posted about it on Facebook. And then um I think Paul said, \"Oh, you're a freshman. You know that there's like another batch coming. \" And what did you reply to him by email with? You know, funny you bring that up. I just dug up the email like a couple of days ago because I I felt I had been misqued over time. I'm curious. And\n\nover time. I'm curious. And the the his telling of the story is I said like I'm a sophomore and I'm coming. But I wrote a much nicer thing than that. It was like oh maybe there was some misunderstanding. You know, actually I'm a sophomore and I can still make it and I would like love to if that's still okay to come the next day. So I in some ways you know the wild thing is you're sitting in front of uh 3, 000 people who kind of was you know they they are sitting where you were back in 2005. Um what would you say to you know the Sam Alman from that time you know given what you know all the things you've seen all the things you've learned since like what are the things that you're most surprised you didn't know that I mean it just took I mean you've been through it you know like you've you've done it. I wish someone\n\nyou've you've done it. I wish someone had like taught me the importance of like conviction and resilience over a long period of time. People don't really talk about how hard that is. it's like easy for a little while, but your reserves kind of like wear down on it and how to how to keep that going for a long period of time. Um, also just sort of like trust that it's eventually going to work out. Like obviously my first startup didn't work that well. Um, I think a lot of people kind of give up after one failed startup, but startups don't work out all the time. Uh, and learning how to keep going through that, keep working through that is is I think really important. Developing like trust in your own instincts and increasing that trust as you refine your decision-making and instincts over time. I think that's\n\ninstincts over time. I think that's really important. Kind of courage to work on stuff that is out of fashion but is what you believe and what you care about. Uh, I think that's really important. I had a kid recently and the thing everyone tells you when you have a kid is that it is the best thing you will ever do but also it is the hardest thing you will ever do. Like the the good parts are much better than you can imagine. Um the hard parts are much harder. That is all totally true. And that is also basically what I feel like being an entrepreneur is like the good parts are really great better than you think and the hard parts are like shockingly much harder than anyone can can express in a way that uh makes any sense to you and you have to just keep going. Sam Alman. Everyone, thank you.\n\ngoing. Sam Alman. Everyone, thank you.\n"
    },
    {
      "speaker": "Elon Musk",
      "title": "Digital Superintelligence, Multiplanetary Life, How to Be Useful",
      "date": "2025-06-19",
      "source_url": "https://www.youtube.com/watch?v=cFIlta1GkiE",
      "transcript": "We're at the very very early stage of the intelligence big bang. Being a multilanet species greatly increases the probable lifespan of civilization or consciousness or intelligence both biological and digital. I think we're quite close to digital super intelligence. If it doesn't happen this year, next year for sure. Please give it up for Elon Musk. Elon, welcome to AI Startup School. We're just really, really blessed to have your presence here today. Uh, thanks for having me. So, uh, from SpaceX, Tesla, Neurolink, XAI, and more. Was there ever a moment in your life uh before all this where you felt I have to build something great? And what flipped that switch for you? Uh well, I didn't originally think I would build something great. Um I wanted to try to build something useful, but uh I didn't think I would build anything\n\ndidn't think I would build anything particularly great. If you said probabilistically seemed unlikely, uh but I wanted to at least try. So you're talking to uh a room full of people who are all technical engineers uh often you know some of the most eminent AI researchers coming up in the game. Okay. I uh I think we should I think that I I like the term engineer better than researcher. I mean I suppose if if there's some fundamental algorithmic breakthrough it's it's a research but otherwise it's engineering. Maybe let's start way back. I mean when you were this is a room full of 18 to 25 year olds. Um it skews younger because the founder set is younger and younger. Uh can you put yourself back into their shoes when you know you were 18 19 you know learning to code uh even coming up with a first idea for zip 2. What was\n\nwith a first idea for zip 2. What was that like for you? Yeah, back in 95 I I was faced with a choice of either do uh you know grad studies PhD at Stanford uh in in material science actually working on ultra capacitors for potential use in electric vehicles essentially trying to solve the range problem for electric vehicles uh or uh try to do something in this thing that most people have never heard of called the internet and um I talked to my professor who was Bill Nyx in the material science from and uh said like um can I like defer for a quarter uh because this will probably fail and then I'll need to come back to college and um and then he said this is probably the last conversation we'll have uh and he was right um so but I I thought things would most likely fail not that they would most\n\nlikely fail not that they would most likely succeed um and um and then in 95 I wrote uh basically I think the first or close to the first maps directions uh internet white pages and yellow pages on the internet. Um I just wrote I just wrote that personally and I didn't even use a web server. I just read the port directly because I um couldn't afford uh and I couldn't couldn't afford a T1. Uh original office was on Sherman Avenue in Palo Alto. Uh there was like an ISP on the floor below. So I drilled a drilled a hole through the floor and just uh ran a land cable directly to the ISP. Um and um you know uh my brother joined me and another co-founder Greg Curry who passed away and um we at the time we couldn't even afford a a place to stay so we just the the office was 500 bucks a month so we just\n\noffice was 500 bucks a month so we just slept in the office and and then showered at the YMCA on Paige Millino. Um and uh yeah and we I guess we ended up doing a little bit of a useful company uh Zip 2 in the beginning. Um and um we we we did build a lot of uh really really good software technology but we were somewhat captured by the legacy media companies and that nighter New York Times host whatnot were investors and uh customers and and also on the board. Uh so they ke they they kept wanting to use our software in ways that made no sense. Um, so I I wanted to go direct to consumers. Anyway, long story dwelling too much on Z2, but the I really just wanted to do something useful on the internet. Um, as because I had like two choices like do a do a PhD and watch people build the internet or\n\nand watch people build the internet or help build the internet in some small way. And I was like, well, I guess I can always try and fail and then go back to grad studies. Um, and uh, anyway, that ended up being like reasonably successful. sold for like $300 million, which is a lot at the time. These days, that's like I think the minimum impulse bid for an AI startup is like a billion dollars. Um, it's like a there's so many freaking unicorns, it's like a herd of unicorns at this point, you know, unicorn is a billion dollar situation. Um, there's been inflation since, so quite a bit more money actually. Yeah. I mean, like 90 1995 you could probably buy a burger for a nickel. Well, not quite, but I mean, yeah, there has been a lot of inflation. Um, but uh I mean, the hype level on AI is is is pretty intense as you've seen.\n\nis is is pretty intense as you've seen. Um, you know, you see, uh, companies that are, I don't know, less than a year old getting sometimes billion dollar or multi-billion dollar valuations. Um, which I guess could could pan out and probably will pan out in some cases. Um but uh it is eye watering to see some of these valuations. Um yeah, what do you think? I mean, well, I'm pretty bullish, personally. I'm I'm pretty bullish, honestly. So, I I think the people in this room are going to create a lot of the value that um you know, a billion people in the world should be using this stuff. And uh we're not even we're scratching the surface of it. I love the internet story in that uh even back then you know you are a lot like the people in this room back then in that you know this the heads of all the the CEOs of all the\n\nheads of all the the CEOs of all the legacy media companies look to you as the person who understood the internet and a lot of the world the you know the corporate world like the world at large that does not understand what's happening with AI they're going to look to the people in this room uh for exactly that it sounds like you know what are some of the tangible lessons it Sounds like one of them is don't give up board control or be careful about have a really good lawyer. Uh I guess for the first my first startup the the big the the really the mistake was having too much uh shareholder and board control from legacy media companies who then necessarily see things through the lens of legacy media and uh that they'll kind of make you do things that seem sensible to them but but aren't really don't make\n\nto them but but aren't really don't make sense with the new technology. Um I know I should point out that I that I um I didn't actually at first intend to start a company. I like I tried to get a job at Netscape. Um I sent my resume into Netscape and Mark Andre knows about this. Um and uh but I don't think he ever saw my resume and then nobody responded. So uh and then I tried hanging out in the lobby of Netscape to see if I could like bump into someone, but I was like too shy to talk to anyone. So I'm like, man, this is ridiculous. So I'll just write software myself and see how it goes. So, it wasn't actually from the standpoint of like I want to start a company. I just want to be part of building, you know, the internet uh in some way. Um and um and since I couldn't get a job at an internet company, I had to start a\n\ninternet company, I had to start a internet company. Anyway, the Yeah. Yeah. I mean, from an AI will so profoundly change the future. It's difficult to fathom um how much but you know the the the economy assu assuming we don't things don't go ary and and like AI doesn't kill us all and itself um then you you'll see ultimately an economy that is not not 10 times more than the current economy ultimately like if we become say or whatever our future machine descendants or but mostly machine descend descendants become like a a cottage of scale 2 civilization or beyond. We're talking about an economy that is thousands of times maybe millions of times bigger than the economy today. So, um, yeah, I mean, I I I I did sort of feel a bit like, you know, when I was in DC, taking a lot of flack for like getting\n\ntaking a lot of flack for like getting rid of waste and fraud, which was an interesting side quest, uh, as side quests go. Um, but, uh, got to get back to the main quest. Yeah, I got to get back to the main quest here. Um, so back to the main quest. Um uh so but I did feel you know a little bit like there's you know it's like fixing the government is kind of like there's like say the beach is dirty and there's like some needles and feces and like trash and you want to clean up the beach but then there's also this like thousand foot wall of water which is a tsunami of AI like and uh how much does cleaning the beach really matter if you got a thousand foot tsunami about to hit? Not that much. Oh, we're glad you're back on the main quest. It's very important. Yeah, back to the main quest. Um, building\n\nto the main quest. Um, building technology, which is uh what I like doing. Um, it's just so much noise. Like this the signal to noise ratio in politics is terrible. So, um I mean, I live in San Francisco, so you don't need to tell me twice. Yeah, DC's like, you know, kind of I guess it's all politics in DC, but um the if you're trying to build a rocket or cars or you're trying to have software that compiles and runs reliably, then you have to be uh maximally truth seeeking or your software or your hardware won't work. Um like there's not you can't fool ma like math and physics are rigorous judges. Um, so I'm used to being in like a maximally truth seeeking environment and and that's definitely not politics. Um, so anyway, I'm I'm good glad to be back in, you know, technology. I guess I'm kind of curious going back to the Zip 2\n\nkind of curious going back to the Zip 2 moment. You had hundreds of millions of dollars or you had an exit of worth hundreds of millions of dollars. I mean, I I got $20 million, right? Okay. So, you solved the money problem at least. Um, and you basically took it and you rolled you kept rolling with X. com, which became PayPal and Conffinity. Uh, yes. I kept the chips on the table. Yeah. So, not everyone does that. A lot of the people in this room will have to make that decision actually. What drove you to jump back into the ring? Well, I I think I I felt for with with Zip 2, we'd built like incredible technology, but it never really got uh used. um you know I think at least from my perspective we had better technology than say Yahoo or anyone else but it was constrained by our customers um and uh\n\nconstrained by our customers um and uh so I wanted to do something that where okay we wouldn't be constrained by our customers go direct to consumer um and that's what ended up being like x. com PayPal uh essentially x. com merging with confinity which together created PayPal and and then uh that that actually the the sort of PayPal dice Spora uh has it might have created more companies than so more companies than probably any anything in the 21st century, you know, uh so so many talented people were at the combination of of Confinity and and X. com. Um so I I just wanted to like I felt like uh we we kind of got our wings clipped somewhat with Zip 2 and it's like okay, what if our wings aren't clipped and we go direct to consumer and that's that's what um PayPal ended up being. Um but yeah, with\n\nbeing. Um but yeah, with I got that like $20 million check for um for my share of Zip 2. At the time I was living with in a house with four housemates. Um and um had like I don't know 10 grand in the bank and then the this check arrives in the mail of all places and in the mail um and then then my bank balance went from 10, 000 to 20 million in 10, 000. um you're like, \"Well, okay. \" Um still have to pay taxes on that and all, but uh then I ended up putting um almost all of that into uh x. com and as you said, like just kind of keeping almost all the chips on the table. Um and um yeah, and then after PayPal, I was like, well, I I was kind of curious as to why we had not sent anyone to Mars. Uh, and I went on the went on the NASA website to find out when we're sending people to Mars, and there was no date. I thought maybe it\n\nthere was no date. I thought maybe it was just hard to find on the website. Uh, but in fact, there there was no real plan to send people to Mars. So then, uh, you know, I've come, this is such a long story, so I don't want to take up too much time here, but um, the I think we're all listening with wrapped attention. So, so I was actually I was on the Long Island Expressway with my friend at Dear Resi. were like u house classmates in college and and D was asking me what I'm what we're going to do what am I going to do after PayPal and I was like it's like I don't know I guess maybe I'd like to do something philanthropic in space because I didn't think I could actually do anything commercial in space because that seemed like the purview of nations um so um but you know I'm kind of curious as to when we're going to send\n\ncurious as to when we're going to send people to Mars and and that's when I was like oh it's not on the website and I started digging on not there's nothing on the NASA website so then I started digging in And um and uh and I'm I'm I'm definitely summarizing a lot here, but um I I I uh my first idea was to do a philanthropic mission to Mars called Life to Mars, where would we send a a small greenhouse with sea and dehydrated nutrient gel, land that on Mars and grow, you know, hydrate the gel, and then you'd have this this great sort of money shot of green plants on a red background. Um, for the longest time I, by the way, I didn't realize money shot I think is a porn reference. But, uh, but anyway, the point is that that would be the great shot of green plants on a red background and to try to inspire uh,\n\nred background and to try to inspire uh, you know, NASA and the public to to send astronauts to to Mars. As I learned more, I I came to realize Oh, and along the way, by the way, I went to Russia in like 2001 and 2002 to buy ICBMs, which is like that's an adventure. You know, you go and meet with Russian high command and say, \"I'd like to buy some ICBMs. \" Um, this was to get to space. Yeah. Not to not to nuke anyone, but but they had they had to uh as a result of arms reduction talks, they had to actually destroy a bunch of their their big nuclear missiles. So I was like, well, how about if we take two of those, you know, minus the nuke, um add an additional uh upper stage for for Mars. Um, but it was kind of trippy, you know, being in Moscow in what 2001 negotiating with like the Russian military to buy ICVMs. Like\n\nRussian military to buy ICVMs. Like Um, and but they they kept also like raising the price on me so that so like literally it's kind of like the opposite of what a negotiation should should do. So I was like, man, these things are getting really expensive. and and then I I came to realize that actually the problem was not that there was insufficient will to go to Mars but that there was no way to do so without breaking the budget you know even breaking the NASA budget so that's where I decided to start SpaceX SpaceX to uh advance rocket technology to the point where we could send people to Mars um and uh that was in 2002 so that wasn't you know you didn't start out uh wanting to start a business. You wanted to start just something that was interesting to you that you thought humanity needed and\n\nyou that you thought humanity needed and then as you sort of, you know, like a cat pulling on, you know, a a string, it just sort of the ball sort of unravels and it turns out this is could be a very profitable business. I mean, it it is now, but it um there I there been no prior example of really a rocket startup succeeding. There have been various attempts to do commercial rocket companies and they all all failed. So um again with with SpaceX starting SpaceX was uh really from the standpoint of like I I think there's like a less than 10% chance of being successful maybe 1% I don't know. Um but um but if if if a startup doesn't do something to advance uh rocket technology, it's definitely not coming from from the big defense contractors because they just impeded match to the government and the government just wants\n\ngovernment and the government just wants to do very conventional things. So there's it's either coming from a startup or it's not happening at all. So, so like a small chance of success is better than no chance of success and and so that yeah, so SpaceX u I started that in in mid mid 2002 expecting to fail. I like I said probably 90% chance of failing and even like when recruiting people I didn't like try to you know make out that it would I said we're probably going to die. Uh but uh 12 chance we might not die and if uh but this is the only way to get people to Mars and advance the state-of-the-art and um and then uh I ended up being chief engineer of the rocket uh not because I wanted to but because I couldn't hire anyone who was good. So like none of the good sort of chief engineers would join\n\ngood sort of chief engineers would join because they're like this is too risky. You were going to die. And uh so then I ended up being chief engineer of the rocket. And you know the first three flights did fail. So it's a bit of a learning exercise there. And um fourth one fortunately worked. But if the fourth one hadn't worked uh I had no money left and that would have been it would have been curtains. So it was a pretty close thing. If if the fourth launch of Falcon not work, it would have been just curtains and we would have just been joined the graveyard of prior rocket startups. So like like my estimate of success was not far off. Um we just we made it by the skin of our teeth. Um and um Tesla was happening sort of simultaneously. Um like 2008 was a rough year. Uh because at mid 2008 uh or\n\nyear. Uh because at mid 2008 uh or called summer 2008 um the third the third launch of SpaceX had failed our third failure in a row. Uh the Tesla financing round had failed. And so Tesla was going bankrupt fast. Um it was just uh it's like man this is grim. Uh this is this is going to be a a tale of warning of an exercise in hubris. Probably throughout that period a lot of people were saying you know Elon is a software guy. Why is he working on hardware? Why would Yeah. Why would he choose to work on this? Right. 100%. So you can look at the like the because there still you know the press of that time is still online. You could just search it and and they kept calling me internet guy. Um so like internet guy aka fool is attempting to build a rocket company. Um so um you know um that we got ridiculed quite a lot. Um,\n\nthat we got ridiculed quite a lot. Um, and it does sound pretty absurd like internet guy starts rocket company doesn't sound like a recipe for success frankly. So I don't hold it against them. I was like, yeah, you know, it admittedly it does sound improbable and I agree that it's improbable. Um, but fortunately the fourth launch worked and um and uh and and NASA awarded us a a contract to resupply the space station. Uh, and I think that was like maybe I don't know December 22nd or it was it was like right before Christmas. Um, because even the fourth launch working wasn't enough to succeed. It NASA also needed we also needed a big contract to keep us alive. So, um, so I got I got that call from like the the NASA NASA team and I literally they said we're we're awarding you one of the contracts to resupply the space station.\n\ncontracts to resupply the space station. And I like literally blurted out, \"I love you guys. \" Which is not normally, you know, what they hear. Um cuz it's usually pretty, you know, sober, but I was like, \"Man, this is a company saver. \" And then, uh, we closed the the Tesla financing round on the last hour of the last day that it was possible, which was 6 p. m. December 24th, 2008. Um, we would have bounced payroll two days after Christmas if that round hadn't hadn't closed. So that was a nerve-wracking end of 2008. That's for sure. I guess from your PayPal and Zip 2 experience, jumping into these hardcore hardware startups, you it feels like one of the through lines was being able to find and eventually attract the smartest possible people in those particular fields. You know, what what would I mean the people\n\nknow, what what would I mean the people in this room like some of the most of the people here I don't think have even managed a single person yet. They're just starting their careers. What would you tell to, you know, the Elon who's never had to do that yet? I I generally think to try to try to be as useful as possible. It's it may sound try, but it's it's so hard to be useful, especially to be useful to a lot of people. Uh where say the area under the curve of total utility is like how much how useful have you been to your fellow human beings times how many people? Um it like it's almost like like the physics definition of true work. It's incredibly difficult to do that. And I think if you aspire to do true work um your your your probability of success is much higher. Um like like don't aspire\n\nmuch higher. Um like like don't aspire to glory aspire to work. How can you tell that it's true work? Like is it external? Is it like what happens with other people or you know what the product does for people like what you know what is that for you when you're looking for people to come work for you? Like what you know what's the salient thing that you look for or if they're you know that's a different question. I guess it's I mean in terms of of of your end product you just have to say like well if this thing is successful how useful will it be to how many people and um that that's that's what I mean and and then you you do whatever you know whether you're CEO or or any role in a startup you do whatever it takes to succeed like and and just and just always be smash smashing your ego like like internalize responsibility\n\nlike internalize responsibility um like a major failure mode is when ego ability ratio um is double greater than sign one you know uh like if you if your ego to ability ratio is gets too high then you're you're you're going to basically break the feedback loop to reality u and in in AI terms your your you'll break your RL loop so you you want you don't want to break your you want to have a strong RL loop which means internalizing responsibility and minimizing ego and you do whatever the task is no matter whether it's you grand or humble. So, I mean, that's kind of like why I actually I prefer the term like engineering as opposed to research. I prefer the term and and I I don't I actually don't want to call XAI a lab. I just want to be a company. um like it's like whatever the whatever the simplest um most straightforward\n\nsimplest um most straightforward uh ideally lowest ego terms are those are generally a good way to go. Um to you you want to just close the loop on reality hard. Um that's that's a that's a super big deal. I think everyone in this room is uh really looks up to everything you've done around being sort of a paragon of first principles and you know thinking about the stuff you've done um how do you actually determine your reality because that seems like a pretty big part of it like other people people who have never made anything non-engineers uh sometimes journalists at time who've never done anything like they will criticize you but then clearly you have another set of people who are builders who have very high you know sort of area under the curve who are in your circle like you know how should people approach\n\nlike you know how should people approach that like what has worked for you and what would you pass on like you know to to X to your children like you know what do you tell them when you're like you need to make your way in this world here you know here's how to construct a reality that is predictive from first principles well the the tools of physics are incredibly helpful uh to to um understand and make progress in any field. Um the first principles mean just obviously just means you know break things down to the fundamental aimatic elements that are most likely to be true and then reason up from there as cogently as possible as opposed to reasoning by analysis or metaphor. Um and then you just simple things like like thinking in the limit like if you extrapolate you know minimize this thing\n\nextrapolate you know minimize this thing or maximize that thing thinking in the limit is is very very helpful. Um I use all the tools of physics. Um they apply to any field. Um this is like a superpower actually. Um so you can take say take take for example like rockets. You can say well how how much should a rocket rocket cost? Um the typical approach to how to that people would take to how much rocket should cost is they would look historically at what the cost of rockets are and assume that any new rocket must be somewhat similar to the prior cost of rockets. A first principles approach would be you you look at the materials that the rocket is comprised of. So if that's aluminum, uh copper, carbon fiber, uh steel, whatever the case may be, um and say what what how much does that rocket weigh and and and what are\n\nthat rocket weigh and and and what are the constituent elements and how much do they weigh? What is the material price per kilogram of those constituent elements? And that sets the actual floor on what a rocket uh can cost. It's it can asmtoically approach the cost of the raw materials. Um and then you realize oh actually a rocket the raw materials of a rocket are only maybe one or 2% of of the historical cost of a rocket. So the manufacturing must necessarily be very inefficient um if the if the raw material cost is only 1 or 2%. That would be a first first principles analysis of the potential for the cost for cost optimization of a rocket. And that's before you get to reusability. You know to give an AI sort of AI example I guess uh last year where for XEI when we were trying to build a a\n\nXEI when we were trying to build a a training supercluster uh we we we went to the various suppliers to ask said this was beginning of last year that we needed 100, 000 H100s to be able to train coherently. Um and uh their estimates for how long it would take to complete that were 18 to 24 months. It's like well we need to get that done in 6 months. So then um or we won't be competitive. So so then uh if you break that down what well what are the things you need? Well, you need a building, you need power, you need cooling. Um we didn't have enough time to build a building from scratch. So we had to find an existing building. So, we found a a factory that was no longer in use in Memphis that used to build Electrolux products. Um, but then the the input power was 15 megawatts and we needed 150\n\npower was 15 megawatts and we needed 150 megawatt. So, uh we we um rented generators and had generators on one side of the building and then we have to have cooling. So, we rented about a quarter of the mobile cooling capacity of the US and put the the chillers on the other side of the building. uh that didn't fully solve the problem because the voltage v the power variations during training um are are very g very big. So you can have power can drop by 50% in 100 milliseconds which the generators can't keep up with. So then we combi we added Tesla mega packs and modified the software in the mega packs to be able to to smooth out the uh the power variation during the training run. Um, and then there were there were a bunch of network networking challenges. Um, because the networking cables if you're trying to make 100, 000\n\ncables if you're trying to make 100, 000 GPUs train coherently are very very challenging. Um, almost it sounds like uh almost any of those things you mentioned uh I could imagine someone telling you very directly, no, you can't have that, you can't have that power, you can't have this. Uh, and it sounds like one of the salient pieces of first principles thinking is actually let's ask why. let's, you know, figure that out and actually let's challenge the person across the table and if they if I don't get an answer that I feel good about, I'm gonna, you know, not allow that to be I'm not going to let that know to stand. Is that I mean, that feels like something that, you know, everyone, if someone were to try to do what you're doing in hardware, hardware seems to uniquely need this. In software, we have lots of, you know,\n\nsoftware, we have lots of, you know, fluff and things that, you know, it's like we can add more CPUs to that. it'll be fine. But in hardware, it's it's just not going to work. I think these general principles of first principle thinking apply to software and hardware apply to anything really. Um I'm just using kind of a hardware example um of of how we were told something is impossible, but once we broke it down into the constituent elements of we need a building, we need power, we need cooling, we need uh we we need power smoothing and then and then we could solve those constituent elements. Um but it it was and then we and then we just ran the the networking operation to to do all the cabling everything um in four shifts 247 and and I was like sleeping in the data center and also doing cabling myself. Um and and there were a\n\ncabling myself. Um and and there were a lot of other issues to solve. Um you know nobody had done a training run with 100, 000 um H100s training coherently last year. May maybe it's been done this year. I don't know. Um and then and then we ended up doubling that uh to 200, 000. And so now we we've got 150, 000 H100s, 50K H200s, and 30K GB200s um in the in the Memphis uh training center. And we're about to bring 110, 000 GB200s online um at a second data center also in the Memphis area. Is it your view that you know uh pre-training is still working and you know larger the scaling laws still hold and whoever wins this race will have basically the biggest smartest possible model that you could distill? Well, there's other various elements that um beside competitiveness for for large AI um there's there's for sure the the\n\nAI um there's there's for sure the the talent of the people matter. Um the scale of the hardware matters and how well you able to bring that hardware to bear. So you can't just order a whole bunch of GPUs and they they don't you can't just plug them in. So you've got to you've got to get a lot of GPUs and have them um train trained coherently and stably. Um then it's like what unique access to data do you have? I guess distribution matters to some degree as well like how do people get exposed to your AI? Those are those are critical factors for if it's going to be like a large foundation model that's competitive. Um um you know as um as many have said I think my friend I sky said uh you know we've kind of run out of pre-training data of human generated pre like human generated data you run out of tokens\n\ngenerated data you run out of tokens pretty fast um of certainly of high quality tokens and um and then you and you have to do a lot of uh you you need to essentially create synthetic data um and and be able to accurately judge the synthetic data that you're creating to verify like is this real synthetic data or is it an hallucination that doesn't actually match reality. Um so achieving grounding in reality is is is tricky but but we we are at the stage where there's more effort put into synthetic data. Um and like right now we're we're training Grock 3. 5 which is a a heavy focus on reasoning. Going back to your physics point, uh what I heard for reasoning is that uh hard science particularly physics textbooks are very useful for reasoning whereas um I think researchers have told me that social\n\nresearchers have told me that social science is totally useless for reasoning. Uh yes, that's probably true. Um so yeah um you know something that's going to be very important in the future is um combining deep AI uh in the the data center or supercluster with robotics. Uh so that uh you know things like like the Optimus humanoid robot and um yeah Optimus is awesome. There's going to be so many humanoid robots and and robots of all robots of all sizes and shapes, but my prediction is that there will be more humanoid robots by far than all other robots combined by maybe an order of magnitude like a a big difference. Um and um is it true that you you're planning a robot army of a sort? Whether we do it or or or you know whether Tesla does it, you know, Tesla works closely with XAI. Um, like you've seen how many humanoid robot\n\nlike you've seen how many humanoid robot startups are there. Like it's like I think Jensen Bong was on stage with a lot with a massive number of robots, you know, robots from different companies. I think there was like dozen different humanoid robots. So, I mean, I guess, you know, part of what I've been fighting and maybe what has slowed me down somewhat is that I'm a I'm a little I don't want I don't want to make Terminator real, you know. So, I've been sort of I guess at least until recent years dragging my feet on on AI and and humanoid robotics. And then I sort of come to the realiz realization it's it's happening whether I do it or not. So, you got really two choices. Particip you could either be a spectator or a participant. And so, like, well, I guess I'd rather be a participant than a spectator.\n\nparticipant than a spectator. Um so now it's you know pedal to the metal on humanoid robots and um digital super intelligence. So I guess you know there's a third thing that uh everyone has heard you talk a lot about that I'm really a big fan of you know becoming a multilanetary species. Where does this fit? You know this is all you know not not just a 10 or 20 year thing maybe a hundredyear thing like it's a mult you know many many generations for humanity kind of thing. You know how do you think about it? There's, you know, AI, obviously, there's embodied robotics, and then there's being a multip multilanetary species. Does everything sort of feed into that last point or, you know, what what are you driven by right now for the next 10, 20, and 100 years? Jeez, 100 years, man. I hope civilization's around in 100 years.\n\nhope civilization's around in 100 years. If if it is around, it's going to look very different from civilization today. Um, I mean, I'd predict that there's going to be at least five times as many humanoid robots as there are humans, maybe 10 times. Um, and one way to look at the progress of civilization is percentage completion kadesv. So, if you're, you know, cautious of scale one, you've um, you've harnessed all the energy of a planet. Now in in my opinion we've only uh harnessed maybe 1 or 2% of uh earth's energy. Uh so we've got a long way to go to the cev scale one. Uh then car shift 2 you've harnessed all the energy of a sun. Uh which would be I don't know a billion times more energy than earth maybe closer to a trillion. Um and then kv 3 would be all the energy of a galaxy pretty far from that.\n\npretty far from that. So we're at the very very early stage of the intelligence big bang. I I I hope I hope we're on the in terms of being multilanetary like I think I think we'll have enough mass transferred to Mars within like roughly 30 years to make Mars self- sustaining such that Mars can continue to grow and prosper even if the resupply ships from Earth stop coming. Um and that that greatly increases the probable lifespan of civilization or or consciousness or intelligence both biological and digital. Um so that's why I think it's important to become a multilanet species. And I'm somewhat troubled by the foamy paradox like why have we not seen any aliens? And it could be because intelligence is incredibly rare. Um and maybe we're the only ones in this galaxy. Um in which case the intelligence of consciousness\n\ncase the intelligence of consciousness is this like tiny candle in a vast darkness and we should do everything possible to ensure the tiny candle candle does not go out and being a multilanet species or making consciousness multilanetary uh greatly improves the probable lifespan of civilization and it's it's it's the next step before going to other star systems. Um once you once you at least have two planets, then you've got a forcing function for the improvement of space travel. Um and um and that that ultimately is what will lead to uh consciousness expanding to the stars. It could be that um the Fermy paradox dictates once you get to some level of technology, you destroy yourself. How do we say ourselves? How do we actually what would you prescribe to I mean a room full of engineers like what can we\n\nroom full of engineers like what can we do to prevent that from happening? Yeah. How do we avoid the great filters? One of the great filters would obviously be global thermonuclear war. Uh so we should try to avoid that. Um, I guess building benign AI robots that AI that loves humanity and um, you know, robots that are helpful. Um, something that I think is uh, extremely important in building AI is is a very rigorous adherence to truth even if that truth is politically incorrect. Um I my intuition for what could make AI very dangerous is if um if you force AI to believe things that are not true. How do you think about you know there's sort of this argument for open uh open for safety versus closed for competitive edge. I mean I think the great thing is you have a competitive model. Many other\n\nyou have a competitive model. Many other people also have competitive models. And in that sense, you know, we're sort of off of maybe the worst timeline that I'd be worried about is, you know, there's fast takeoff and it's only in one person's hands. You know, that might, you know, sort of collapse uh a lot of things. Whereas now we have choice, which is great. How do you think about this? Yeah, I do think there will be several deep intelligences, may maybe at least five. Um maybe as much as 10. Um, I'm not sure that there's going to be hundreds, but it's probably close to like maybe there'll be like 10 or something like that. Um, of which maybe four will be in the US. so I I don't think it's going to be any one AI that that has a runaway but but yeah se several deep intelligences. What will these deep deep\n\nintelligences. What will these deep deep intelligences actually be doing? Will it be scientific research or trying to hack each other? Probably all of the above. Um I mean hopefully they will discover new physics and I think they will very they're they're definitely going to invent new technologies. like I think I think we're quite close to digital super intelligence. It may happen this year and if it doesn't happen this year, next year for sure a digital super intelligence defined as smarter than any human at anything. Well, so how do we direct that to sort of super abundance? You know, we have we could have robotic labor, we have cheap energy, intelligence on demand. you know, is that sort of the white pill? Like where do you sit on the spectrum? And are there tangible things that you would encourage everyone here\n\nthat you would encourage everyone here to be working on to make that white pill actually reality? I think I think it most likely will be a good outcome. Um I I guess I'd sort of agree with Jeff Hinton that maybe it's a 10 to 20% chance of annihilation. Uh but look on the bright side, that's 80 to 90% probability of a great outcome. Um, so yeah, I can't emphasize this enough. A rigorous adherence to truth uh is is the most important thing for AI safet safety. Um, and obviously empathy for uh humanity and life as we know it. We haven't uh talked about Neurolink and uh at all yet, but I'm curious, you know, you're working on closing the input and output gap between humans and machines. Uh how critical is that to AGI ASI? And you know, once that link is made, can we not only read but also write the neural link\n\nonly read but also write the neural link is not necessary to solve um digital super intelligence. Uh that'll happen before neural link is at scale. Uh but uh what Nurolink can effectively do is solve the um the input output bandwidth constraints. Especially our output con bandwidth is very low. The the out the the sustained output of a human over the course of a day is less than one bit per second. So there, you know, 86, 400 seconds in a day. Um and is extremely rare for a human to output more than that number of symbols per day. So um certainly for several days in a row. Uh so you you really um with with a with a neural link interface you can massively increase your output bandwidth and your input bandwidth. Um input being right to you you have to do write operations to the brain. Um we um we\n\noperations to the brain. Um we um we have now five humans who have received the uh the kind of the read uh input where it's reading signals. And you've got people with with ALS who um really have no they're tetroplegics, but they they can now communicate at with with at um similar bandwidth to a human with a fully functioning body um and control their computer and phone um which is pretty cool. And then um I think in the next 6 to 12 months we'll be doing our first implants for vision where even if somebody's completely blind um uh we we can write directly to um the uh the visual cortex um and and we've had that working in monkeys actually. I think one of our monkeys now has had a visual implant for three years and um at first it'll be relatively fairly low resolution but long term you would have\n\nresolution but long term you would have very high resolution and be able to see multisspectral wavelengths. So uh you could see an infrared ultraviolet radar like a superpower situation like at at at some point the cybernetic implants wouldn't would not simply be correcting things that went wrong but uh augmenting human capabilities dramatically augmenting augmenting intelligence and senses and bandwidth uh dramatically and that's that's going to happen at some point. Um but digital super intelligence will happen well before that at least if we have a a neural link we might we'll be able to appreciate the the AI better I guess one of the limiting reagents to all of your efforts across all of these different domains is access to the smartest possible people. Um, yes. But, you know, sort of simultaneous to that we have, you know,\n\nsimultaneous to that we have, you know, the rocks can talk and reason and, you know, they're maybe 130 IQ now and they're probably going to be super intelligent soon. Uh, how do you reconcile those two things? Like what's going to happen in you know 5 10 years and what should the people in this room do to uh make sure that, you know, they're the ones who are creating instead of maybe below the API line? Well, they call it the singularity for a reason because we don't know what's going to happen in in the not that far future. The percentage of intelligence that is human will be quite small. At some point, the collective sum of human intelligence will be less than 1% of all intelligence. Um and if if things get to a cauter ship level two um we're talking about human intelligence even assuming a\n\nhuman intelligence even assuming a significant increase in human population and intelligence augmentation like massive intelligence augmentation where like everyone has an IQ of a thousand type of thing. Um even in that circumstance uh collective human intelligence will be probably 1 billionth that of uh digital intelligence. Anyway, where's the biological bootloader for digital super was I he was like was I a good bootloader. Where do we go? How do we go from here? I mean I mean all of this is pretty wild sci-fi stuff that also could be built by the people in this room. You know, if you do you have a closing thought for the smartest technical people of this generation right now, what should they be doing? What should they what should they be working on? What should they be thinking about, you\n\nWhat should they be thinking about, you know, tonight as they go to dinner? Well, I as I started off with, I think if you're doing something useful, that's great. Um, if you just just try to be as useful as possible to your fellow human beings and that that then you're doing something good. Um, I keep harping on this like focus on super truthful AI that that's the most important thing for AI safety. Um, you know, obviously if you know um anyone's interested in working at XAI, I mean, please please let us know. Um we're aiming to make gro um the maximally truth seeeking AI. Um and uh I think that's a very important thing. Um hopefully we can understand the nature of the universe. That that's really I guess what AI can hopefully tell us. Maybe AI AI can maybe tell us where are the aliens and what you know how did the\n\nthe aliens and what you know how did the universe really start? How will it end? What are the questions that we don't know that we should ask? And um are we in a simulation or what level of simulation are we in? Well, I think we're going to find out. Elon, thank you so much for joining us. Everyone, please give it up for Elon Musk.\n"
    },
    {
      "speaker": "Andrej Karpathy",
      "title": "Software Is Changing (Again)",
      "date": "2025-06-19",
      "source_url": "https://www.youtube.com/watch?v=LCEmiRjPEtQ",
      "transcript": "Please welcome former director of AI Tesla Andre Carpathy. Hello. Wow, a lot of people here. Hello. Um, okay. Yeah. So I'm excited to be here today to talk to you about software in the era of AI. And I'm told that many of you are students like bachelors, masters, PhD and so on. And you're about to enter the industry. And I think it's actually like an extremely unique and very interesting time to enter the industry right now. And I think fundamentally the reason for that is that um software is changing uh again. And I say again because I actually gave this talk already. Um but the problem is that software keeps changing. So I actually have a lot of material to create new talks and I think it's changing quite fundamentally. I think roughly speaking software has not changed much on such a fundamental level\n\nchanged much on such a fundamental level for 70 years. And then it's changed I think about twice quite rapidly in the last few years. And so there's just a huge amount of work to do a huge amount of software to write and rewrite. So let's take a look at maybe the realm of software. So if we kind of think of this as like the map of software this is a really cool tool called map of GitHub. Um this is kind of like all the software that's written. Uh these are instructions to the computer for carrying out tasks in the digital space. So if you zoom in here, these are all different kinds of repositories and this is all the code that has been written. And a few years ago I kind of observed that um software was kind of changing and there was kind of like a new type of software around and I called this\n\nsoftware around and I called this software 2. 0 at the time and the idea here was that software 1. 0 is the code you write for the computer. Software 2. 0 know are basically neural networks and in particular the weights of a neural network and you're not writing this code directly you are most you are more kind of like tuning the data sets and then you're running an optimizer to create to create the parameters of this neural net and I think like at the time neural nets were kind of seen as like just a different kind of classifier like a decision tree or something like that and so I think it was kind of like um I think this framing was a lot more appropriate and now actually what we have is kind of like an equivalent of GitHub in the realm of software 2. 0 And I think the hugging face is basically\n\nI think the hugging face is basically equivalent of GitHub in software 2. 0. And there's also model atlas and you can visualize all the code written there. In case you're curious, by the way, the giant circle, the point in the middle, uh these are the parameters of flux, the image generator. And so anytime someone tunes a on top of a flux model, you basically create a git commit uh in this space and uh you create a different kind of a image generator. So basically what we have is software 1. 0 is the computer code that programs a computer. Software 2. 0 are the weights which program neural networks. Uh and here's an example of Alexet image recognizer neural network. Now so far all of the neural networks that we've been familiar with until recently where kind of like fixed function computers image to categories\n\nfunction computers image to categories or something like that. And I think what's changed and I think is a quite fundamental change is that neural networks became programmable with large language models. And so I I see this as quite new, unique. It's a new kind of a computer and uh so in my mind it's uh worth giving it a new designation of software 3. 0. And basically your prompts are now programs that program the LLM. And uh remarkably uh these uh prompts are written in English. So it's kind of a very interesting programming language. Um so maybe uh to summarize the difference if you're doing sentiment classification for example you can imagine writing some uh amount of Python to to basically do sentiment classification or you can train a neural net or you can prompt a large language model. Uh so here this is a few short\n\nmodel. Uh so here this is a few short prompt and you can imagine changing it and programming the computer in a slightly different way. So basically we have software 1. 0 software 2. 0 and I think we're seeing maybe you've seen a lot of GitHub code is not just like code anymore. there's a bunch of like English interspersed with code and so I think kind of there's a growing category of new kind of code. So not only is it a new programming paradigm, it's also remarkable to me that it's in our native language of English. And so when this blew my mind a few uh I guess years ago now I tweeted this and um I think it captured the attention of a lot of people and this is my currently pinned tweet uh is that remarkably we're now programming computers in English. Now, when I was at uh Tesla, um we were working on the uh autopilot and uh we\n\nworking on the uh autopilot and uh we were trying to get the car to drive and I sort of showed this slide at the time where you can imagine that the inputs to the car are on the bottom and they're going through a software stack to produce the steering and acceleration and I made the observation at the time that there was a ton of C++ code around in the autopilot which was the software 1. 0 code and then there was some neural nets in there doing image recognition and uh I kind of observed that over time as we made the autopilot better basically the neural network grew in capability and size and in addition to that all the C++ code was being deleted and kind of like was um and a lot of the kind of capabilities and functionality that was originally written in 1. 0 was migrated to 2. 0. So as an example, a lot\n\nmigrated to 2. 0. So as an example, a lot of the stitching up of information across images from the different cameras and across time was done by a neural network and we were able to delete a lot of code and so the software 2. 0 stack quite literally ate through the software stack of the autopilot. So I thought this was really remarkable at the time and I think we're seeing the same thing again where uh basically we have a new kind of software and it's eating through the stack. We have three completely different programming paradigms and I think if you're entering the industry it's a very good idea to be fluent in all of them because they all have slight pros and cons and you may want to program some functionality in 1. 0 or 2. 0 or 3. 0. Are you going to train neurallet? Are you going to just prompt\n\nneurallet? Are you going to just prompt an LLM? Should this be a piece of code that's explicit etc. So we all have to make these decisions and actually potentially uh fluidly trans transition between these paradigms. So what I wanted to get into now is first I want to in the first part talk about LLMs and how to kind of like think of this new paradigm and the ecosystem and what that looks like. Uh like what are what is this new computer? What does it look like and what does the ecosystem look like? Um I was struck by this quote from Anduring actually uh many years ago now I think and I think Andrew is going to be speaking right after me. Uh but he said at the time AI is the new electricity and I do think that it um kind of captures something very interesting in that LLMs certainly feel like they have properties of utilities\n\nlike they have properties of utilities right now. So um LLM labs like OpenAI, Gemini, Enthropic etc. They spend capex to train the LLMs and this is kind of equivalent to building out a grid and then there's opex to serve that intelligence over APIs to all of us and this is done through metered access where we pay per million tokens or something like that and we have a lot of demands that are very utility- like demands out of this API we demand low latency high uptime consistent quality etc. In electricity, you would have a transfer switch. So you can transfer your electricity source from like grid and solar or battery or generator. In LLM, we have maybe open router and easily switch between the different types of LLMs that exist. Because the LLM are software, they don't compete for physical space. So it's okay\n\ncompete for physical space. So it's okay to have basically like six electricity providers and you can switch between them, right? Because they don't compete in such a direct way. And I think what's also a little fascinating and we saw this in the last few days actually a lot of the LLMs went down and people were kind of like stuck and unable to work. And uh I think it's kind of fascinating to me that when the state-of-the-art LLMs go down, it's actually kind of like an intelligence brownout in the world. It's kind of like when the voltage is unreliable in the grid and uh the planet just gets dumber the more reliance we have on these models, which already is like really dramatic and I think will continue to grow. But LLM's don't only have properties of utilities. I think it's also fair to say that they have\n\nit's also fair to say that they have some properties of fabs. And the reason for this is that the capex required for building LLM is actually quite large. Uh it's not just like building some uh power station or something like that, right? You're investing a huge amount of money and I think the tech tree and uh for the technology is growing quite rapidly. So we're in a world where we have sort of deep tech trees, research and development secrets that are centralizing inside the LLM labs. Um and but I think the analogy muddies a little bit also because as I mentioned this is software and software is a bit less defensible because it is so malleable. And so um I think it's just an interesting kind of thing to think about potentially. There's many analogy analogies you can make like a 4 nanometer process node maybe is\n\nnanometer process node maybe is something like a cluster with certain max flops. You can think about when you're use when you're using Nvidia GPUs and you're only doing the software and you're not doing the hardware. That's kind of like the fabless model. But if you're actually also building your own hardware and you're training on TPUs if you're Google, that's kind of like the Intel model where you own your fab. So I think there's some analogies here that make sense. But actually I think the analogy that makes the most sense perhaps is that in my mind LLM have very strong kind of analogies to operating systems. Uh in that this is not just electricity or water. It's not something that comes out of the tap as a commodity. uh this is these are now increasingly complex software ecosystems right so uh they're not just like simple\n\nright so uh they're not just like simple commodities like electricity and it's kind of interesting to me that the ecosystem is shaping in a very similar kind of way where you have a few closed source providers like Windows or Mac OS and then you have an open source alternative like Linux and I think for u neural for LLMs as well we have a kind of a few competing closed source providers and then maybe the llama ecosystem is currently like maybe a close approximation to something that may grow into something like Linux. Again, I think it's still very early because these are just simple LLMs, but we're starting to see that these are going to get a lot more complicated. It's not just about the LLM itself. It's about all the tool use and the multiodalities and how all of that works. And so when I sort of had this\n\nworks. And so when I sort of had this realization a while back, I tried to sketch it out and it kind of seemed to me like LLMs are kind of like a new operating system, right? So the LLM is a new kind of a computer. It's sitting it's kind of like the CPU equivalent. uh the context windows are kind of like the memory and then the LLM is orchestrating memory and compute uh for problem solving um using all of these uh capabilities here and so definitely if you look at it looks very much like operating system from that perspective. Um, a few more analogies. For example, if you want to download an app, say I go to VS Code and I go to download, you can download VS Code and you can run it on Windows, Linux or or Mac in the same way as you can take an LLM app like cursor and you can run it on GPT or cloud or\n\nand you can run it on GPT or cloud or Gemini series, right? It's just a drop down. So, it's kind of like similar in that way as well. uh more analogies that I think strike me is that we're kind of like in this 1960sish era where LLM compute is still very expensive for this new kind of a computer and that forces the LLMs to be centralized in the cloud and we're all just uh sort of thing clients that interact with it over the network and none of us have full utilization of these computers and therefore it makes sense to use time sharing where we're all just you know a dimension of the batch when they're running the computer in the cloud. And this is very much what computers used to look like at during this time. The operating systems were in the cloud. Everything was streamed around and there was batching. And so\n\naround and there was batching. And so the p the personal computing revolution hasn't happened yet because it's just not economical. It doesn't make sense. But I think some people are trying. And it turns out that Mac minis, for example, are a very good fit for some of the LLMs because it's all if you're doing batch one inference, this is all super memory bound. So this actually works. And uh I think these are some early indications maybe of personal computing. Uh but this hasn't really happened yet. It's not clear what this looks like. Maybe some of you get to invent what what this is or how it works or uh what this should what this should be. Maybe one more analogy that I'll mention is whenever I talk to Chach or some LLM directly in text, I feel like I'm talking to an operating system through\n\ntalking to an operating system through the terminal. Like it's just it's it's text. It's direct access to the operating system. And I think a guey hasn't yet really been invented in like a general way like should chatt have a guey like different than just a tech bubbles. Uh certainly some of the apps that we're going to go into in a bit have guey but there's no like guey across all the tasks if that makes sense. Um there are some ways in which LLMs are different from kind of operating systems in some fairly unique way and from early computing. And I wrote about uh this one particular property that strikes me as very different uh this time around. It's that LLMs like flip they flip the direction of technology diffusion uh that is usually uh present in technology. So for example with electricity, cryptography,\n\nexample with electricity, cryptography, computing, flight, internet, GPS, lots of new transformative technologies that have not been around. Typically it is the government and corporations that are the first users because it's new and expensive etc. and it only later diffuses to consumer. Uh, but I feel like LLMs are kind of like flipped around. So maybe with early computers, it was all about ballistics and military use, but with LLMs, it's all about how do you boil an egg or something like that. This is certainly like a lot of my use. And so it's really fascinating to me that we have a new magical computer and it's like helping me boil an egg. It's not helping the government do something really crazy like some military ballistics or some special technology. Indeed, corporations are governments are lagging behind the\n\ngovernments are lagging behind the adoption of all of us, of all of these technologies. So, it's just backwards and I think it informs maybe some of the uses of how we want to use this technology or like where are some of the first apps and so on. So, in summary so far, LLM labs LLMs. I think it's accurate language to use, but LLMs are complicated operating systems. They're circa 1960s in computing and we're redoing computing all over again. and they're currently available via time sharing and distributed like a utility. What is new and unprecedented is that they're not in the hands of a few governments and corporations. They're in the hands of all of us because we all have a computer and it's all just software and Chaship was beamed down to our computers like billions of people like instantly and overnight and this is\n\nlike instantly and overnight and this is insane. Uh and it's kind of insane to me that this is the case and now it is our time to enter the industry and program these computers. This is crazy. So I think this is quite remarkable. Before we program LLMs, we have to kind of like spend some time to think about what these things are. And I especially like to kind of talk about their psychology. So the way I like to think about LLMs is that they're kind of like people spirits. Um they are stoastic simulations of people. Um and the simulator in this case happens to be an auto reggressive transformer. So transformer is a neural net. Uh it's and it just kind of like is goes on the level of tokens. It goes chunk chunk chunk chunk chunk. And there's an almost equal amount of compute for every single chunk. Um and um this simulator of\n\nchunk. Um and um this simulator of course is is just is basically there's some weights involved and we fit it to all of text that we have on the internet and so on. And you end up with this kind of a simulator and because it is trained on humans, it's got this emergent psychology that is humanlike. So the first thing you'll notice is of course uh LLM have encyclopedic knowledge and memory. uh and they can remember lots of things, a lot more than any single individual human can because they read so many things. It's it actually kind of reminds me of this movie Rainman, which I actually really recommend people watch. It's an amazing movie. I love this movie. Um and Dustin Hoffman here is an autistic savant who has almost perfect memory. So, he can read a he can read like a phone book and remember all\n\nread like a phone book and remember all of the names and phone numbers. And I kind of feel like LM are kind of like very similar. They can remember Shaw hashes and lots of different kinds of things very very easily. So they certainly have superpowers in some set in some respects. But they also have a bunch of I would say cognitive deficits. So they hallucinate quite a bit. Um and they kind of make up stuff and don't have a very good uh sort of internal model of self-nowledge, not sufficient at least. And this has gotten better but not perfect. They display jagged intelligence. So they're going to be superhuman in some problems solving domains. And then they're going to make mistakes that basically no human will make. like you know they will insist that 9. 11 is greater than 9. 9 or that there are two Rs in strawberry these are\n\nthere are two Rs in strawberry these are some famous examples but basically there are rough edges that you can trip on so that's kind of I think also kind of unique um they also kind of suffer from entrograde amnesia um so uh and I think I'm alluding to the fact that if you have a co-orker who joins your organization this co-orker will over time learn your organization and uh they will understand and gain like a huge amount of context on the organization and they go home and they sleep and they consolidate knowledge and they develop expertise over time. LLMs don't natively do this and this is not something that has really been solved in the R&amp; D of LLM. I think um and so context windows are really kind of like working memory and you have to sort of program the working memory quite directly because\n\nworking memory quite directly because they don't just kind of like get smarter by uh by default and I think a lot of people get tripped up by the analogies uh in this way. Uh in popular culture I recommend people watch these two movies uh Momento and 51st dates. In both of these movies, the protagonists, their weights are fixed and their context windows gets wiped every single morning and it's really problematic to go to work or have relationships when this happens and this happens to all the time. I guess one more thing I would point to is security kind of related limitations of the use of LLM. So for example, LLMs are quite gullible. Uh they are susceptible to prompt injection risks. They might leak your data etc. And so um and there's many other considerations uh security related. So, so basically long story short, you have\n\nso basically long story short, you have to load your you have to load your you have to simultaneously think through this superhuman thing that has a bunch of cognitive deficits and issues. How do we and yet they are extremely like useful and so how do we program them and how do we work around their deficits and enjoy their superhuman powers. So what I want to switch to now is talk about the opportunities of how do we use these models and what are some of the biggest opportunities. This is not a comprehensive list just some of the things that I thought were interesting for this talk. The first thing I'm kind of excited about is what I would call partial autonomy apps. So for example, let's work with the example of coding. You can certainly go to chacht directly and you can start copy pasting code\n\nand you can start copy pasting code around and copyping bug reports and stuff around and getting code and copy pasting everything around. Why would you why would you do that? Why would you go directly to the operating system? It makes a lot more sense to have an app dedicated for this. And so I think many of you uh use uh cursor. I do as well. And uh cursor is kind of like the thing you want instead. You don't want to just directly go to the chash apt. And I think cursor is a very good example of an early LLM app that has a bunch of properties that I think are um useful across all the LLM apps. So in particular, you will notice that we have a traditional interface that allows a human to go in and do all the work manually just as before. But in addition to that, we now have this LLM integration that allows us to go in\n\nintegration that allows us to go in bigger chunks. And so some of the properties of LLM apps that I think are shared and useful to point out. Number one, the LLMs basically do a ton of the context management. Um, number two, they orchestrate multiple calls to LLMs, right? So in the case of cursor, there's under the hood embedding models for all your files, the actual chat models, models that apply diffs to the code, and this is all orchestrated for you. A really big one that uh I think also maybe not fully appreciated always is application specific uh GUI and the importance of it. Um because you don't just want to talk to the operating system directly in text. Text is very hard to read, interpret, understand and also like you don't want to take some of these actions natively in text. So it's\n\nthese actions natively in text. So it's much better to just see a diff as like red and green change and you can see what's being added is subtracted. It's much easier to just do command Y to accept or command N to reject. I shouldn't have to type it in text, right? So, a guey allows a human to audit the work of these fallible systems and to go faster. I'm going to come back to this point a little bit uh later as well. And the last kind of feature I want to point out is that there's what I call the autonomy slider. So, for example, in cursor, you can just do tap completion. You're mostly in charge. You can select a chunk of code and command K to change just that chunk of code. You can do command L to change the entire file. Or you can do command I which just you know let it rip do whatever you want\n\nyou know let it rip do whatever you want in the entire repo and that's the sort of full autonomy agent agentic version and so you are in charge of the autonomy slider and depending on the complexity of the task at hand you can uh tune the amount of autonomy that you're willing to give up uh for that task maybe to show one more example of a fairly successful LLM app uh perplexity um it also has very similar features to what I've just pointed out to in cursor uh it packages up a lot of the information. It orchestrates multiple LLMs. It's got a GUI that allows you to audit some of its work. So, for example, it will site sources and you can imagine inspecting them. And it's got an autonomy slider. You can either just do a quick search or you can do research or you can do deep research and come back 10 minutes later.\n\nresearch and come back 10 minutes later. So, this is all just varying levels of autonomy that you give up to the tool. So, I guess my question is I feel like a lot of software will become partially autonomous. I'm trying to think through like what does that look like? And for many of you who maintain products and services, how are you going to make your products and services partially autonomous? Can an LLM see everything that a human can see? Can an LLM act in all the ways that a human could act? And can humans supervise and stay in the loop of this activity? Because again, these are fallible systems that aren't yet perfect. And what does a diff look like in Photoshop or something like that? You know, and also a lot of the traditional software right now, it has all these switches and all this kind of\n\nall these switches and all this kind of stuff that's all designed for human. All of this has to change and become accessible to LLMs. So, one thing I want to stress with a lot of these LLM apps that I'm not sure gets as much attention as it should is um we we're now kind of like cooperating with AIS and usually they are doing the generation and we as humans are doing the verification. It is in our interest to make this loop go as fast as possible. So, we're getting a lot of work done. There are two major ways that I think uh this can be done. Number one, you can speed up verification a lot. Um, and I think guies, for example, are extremely important to this because a guey utilizes your computer vision GPU in all of our head. Reading text is effortful and it's not fun, but looking at stuff is fun and it's it's just a\n\nat stuff is fun and it's it's just a kind of like a highway to your brain. So, I think guies are very useful for auditing systems and visual representations in general. And number two, I would say is we have to keep the AI on the leash. We I think a lot of people are getting way over excited with AI agents and uh it's not useful to me to get a diff of 10, 000 lines of code to my repo. Like I have to I'm still the bottleneck, right? Even though that 10, 00 lines come out instantly, I have to make sure that this thing is not introducing bugs. It's just like and that it's doing the correct thing, right? And that there's no security issues and so on. So um I think that um yeah basically you we have to sort of like it's in our interest to make the the flow of these two go very very fast and we have to somehow keep the AI on\n\nand we have to somehow keep the AI on the leash because it gets way too overreactive. It's uh it's kind of like this. This is how I feel when I do AI assisted coding. If I'm just bite coding everything is nice and great but if I'm actually trying to get work done it's not so great to have an overreactive uh agent doing all this kind of stuff. So this slide is not very good. I'm sorry, but I guess I'm trying to develop like many of you some ways of utilizing these agents in my coding workflow and to do AI assisted coding. And in my own work, I'm always scared to get way too big diffs. I always go in small incremental chunks. I want to make sure that everything is good. I want to spin this loop very very fast and um I sort of work on small chunks of single concrete thing. Uh and so I think many of you\n\nthing. Uh and so I think many of you probably are developing similar ways of working with the with LLMs. Um, I also saw a number of blog posts that try to develop these best practices for working with LLMs. And here's one that I read recently and I thought was quite good. And it kind of discussed some techniques and some of them have to do with how you keep the AI on the leash. And so, as an example, if you are prompting, if your prompt is vague, then uh the AI might not do exactly what you wanted and in that case, verification will fail. You're going to ask for something else. If a verification fails, then you're going to start spinning. So it makes a lot more sense to spend a bit more time to be more concrete in your prompts which increases the probability of successful verification and you can\n\nof successful verification and you can move forward. And so I think a lot of us are going to end up finding um kind of techniques like this. I think in my own work as well I'm currently interested in uh what education looks like in um together with kind of like now that we have AI uh and LLMs what does education look like? And I think a a large amount of thought for me goes into how we keep AI on the leash. I don't think it just works to go to chat and be like, \"Hey, teach me physics. \" I don't think this works because the AI is like gets lost in the woods. And so for me, this is actually two separate apps. For example, there's an app for a teacher that creates courses and then there's an app that takes courses and serves them to students. And in both cases, we now have this intermediate artifact of a course\n\nthis intermediate artifact of a course that is auditable and we can make sure it's good. We can make sure it's consistent. and the AI is kept on the leash with respect to a certain syllabus, a certain like um progression of projects and so on. And so this is one way of keeping the AI on leash and I think has a much higher likelihood of working and the AI is not getting lost in the woods. One more kind of analogy I wanted to sort of allude to is I'm not I'm no stranger to partial autonomy and I kind of worked on this I think for five years at Tesla and this is also a partial autonomy product and shares a lot of the features like for example right there in the instrument panel is the GUI of the autopilot so it's showing me what the what the neural network sees and so on and we have the autonomy slider where\n\nand we have the autonomy slider where over the course of my tenure there we did more and more autonomous tasks for the user and maybe the story that I wanted to tell very briefly is uh actually the first time I drove a self-driving vehicle was in 2013 and I had a friend who worked at Whimo and uh he offered to give me a drive around Palo Alto. I took this picture using Google Glass at the time and many of you are so young that you might not even know what that is. Uh but uh yeah, this was like all the rage at the time. And we got into this car and we went for about a 30-minute drive around Palo Alto highways uh streets and so on. And this drive was perfect. There was zero interventions and this was 2013 which is now 12 years ago. And it kind of struck me because at the time when I had this perfect drive, this perfect demo, I felt\n\nperfect drive, this perfect demo, I felt like, wow, self-driving is imminent because this just worked. This is incredible. Um, but here we are 12 years later and we are still working on autonomy. Um, we are still working on driving agents and even now we haven't actually like really solved the problem. like you may see Whimos going around and they look driverless but you know there's still a lot of teleoperation and a lot of human in the loop of a lot of this driving so we still haven't even like declared success but I think it's definitely like going to succeed at this point but it just took a long time and so I think like like this is software is really tricky I think in the same way that driving is tricky and so when I see things like oh 2025 is the year of agents I get very concerned and I kind\n\nagents I get very concerned and I kind of feel like you know this is the decade of agents and this is going to be quite some time. We need humans in the loop. We need to do this carefully. This is software. Let's be serious here. One more kind of analogy that I always think through is the Iron Man suit. Uh I think this is I always love Iron Man. I think it's like so um correct in a bunch of ways with respect to technology and how it will play out. And what I love about the Iron Man suit is that it's both an augmentation and Tony Stark can drive it and it's also an agent. And in some of the movies, the Iron Man suit is quite autonomous and can fly around and find Tony and all this kind of stuff. And so this is the autonomy slider is we can be we can build augmentations or we can build agents and we kind of want to do a\n\nbuild agents and we kind of want to do a bit of both. But at this stage I would say working with fallible LLMs and so on. I would say you know it's less Iron Man robots and more Iron Man suits that you want to build. It's less like building flashy demos of autonomous agents and more building partial autonomy products. And these products have custom gueies and UIUX. And we're trying to um and this is done so that the generation verification loop of the human is very very fast. But we are not losing the sight of the fact that it is in principle possible to automate this work. And there should be an autonomy slider in your product. And you should be thinking about how you can slide that autonomy slider and make your product uh sort of um more autonomous over time. But this is kind of how I think there's\n\nBut this is kind of how I think there's lots of opportunities in these kinds of products. I want to now switch gears a little bit and talk about one other dimension that I think is very unique. Not only is there a new type of programming language that allows for autonomy in software but also as I mentioned it's programmed in English which is this natural interface and suddenly everyone is a programmer because everyone speaks natural language like English. So this is extremely bullish and very interesting to me and also completely unprecedented. I would say it it used to be the case that you need to spend five to 10 years studying something to be able to do something in software. this is not the case anymore. So, I don't know if by any chance anyone has heard of vibe coding. Uh, this this is the tweet that kind of\n\nUh, this this is the tweet that kind of like introduced this, but I'm told that this is now like a major meme. Um, fun story about this is that I've been on Twitter for like 15 years or something like that at this point and I still have no clue which tweet will become viral and which tweet like fizzles and no one cares. And I thought that this tweet was going to be the latter. I don't know. It was just like a shower of thoughts. But this became like a total meme and I really just can't tell. But I guess like it struck a chord and it gave a name to something that everyone was feeling but couldn't quite say in words. So now there's a Wikipedia page and everything. This is like yeah this is like a major contribution now or something like that. So, um, so Tom Wolf from HuggingFace shared this beautiful video that I really love.\n\nthis beautiful video that I really love. Um, And I find that this is such a wholesome video. Like, I love this video. Like, how can you look at this video and feel bad about the future? The future is great. I think this will end up being like a gateway drug to software development. Um, I'm not a doomer about the future of the generation and I think yeah, I love this video. So, I tried by coding a little bit uh as well because it's so fun. Uh, so bike coding is so great when you want to build something super duper custom that doesn't appear to exist and you just want to wing it because it's a Saturday or something like that. So, I built this uh iOS app and I don't I can't actually program in Swift, but I was really shocked that I was able to build like a super basic app and I'm not going to explain it. It's really uh\n\ngoing to explain it. It's really uh dumb, but uh I kind of like this was just like a day of work and this was running on my phone like later that day and I was like, \"Wow, this is amazing. \" I didn't have to like read through Swift for like five days or something like that to like get started. I also vipcoded this app called Menu Genen. And this is live. You can try it in menu. app. And I basically had this problem where I show up at a restaurant, I read through the menu, and I have no idea what any of the things are. And I need pictures. So this doesn't exist. So I was like, \"Hey, I'm going to bite code it. \" So, um, this is what it looks like. You go to menu. app, um, and, uh, you take a picture of a of a menu and then menu generates the images and everyone gets $5 in credits for free when you sign up. And\n\nfor free when you sign up. And therefore, this is a major cost center in my life. So, this is a negative negative uh, revenue app for me right now. I've lost a huge amount of money on menu. Okay. But the fascinating thing about menu genen for me is that the code of the v the vite coding part the code was actually the easy part of v of v coding menu and most of it actually was when I tried to make it real so that you can actually have authentication and payments and the domain name and averal deployment. This was really hard and all of this was not code. All of this devops stuff was in me in the browser clicking stuff and this was extreme slo and took another week. So it was really fascinating that I had the menu genen um basically demo working on my laptop in a few hours and then it took me a week\n\nfew hours and then it took me a week because I was trying to make it real and the reason for this is this was just really annoying. Um, so for example, if you try to add Google login to your web page, I know this is very small, but just a huge amount of instructions of this clerk library telling me how to integrate this. And this is crazy. Like it's telling me go to this URL, click on this dropdown, choose this, go to this, and click on that. And it's like telling me what to do. Like a computer is telling me the actions I should be taking. Like you do it. Why am I doing this? What the hell? I had to follow all these instructions. This was crazy. So I think the last part of my talk therefore focuses on can we just build for agents? I don't want to do this work. Can agents do this? Thank you.\n\nyou. Okay. So roughly speaking, I think there's a new category of consumer and manipulator of digital information. It used to be just humans through GUIs or computers through APIs. And now we have a completely new thing and agents are they're computers but they are humanlike kind of right they're people spirits there's people spirits on the internet and they need to interact with our software infrastructure like can we build for them it's a new thing so as an example you can have robots. txt on your domain and you can instruct uh or like advise I suppose um uh web crawlers on how to behave on your website in the same way you can have maybe lm. txt txt file which is just a simple markdown that's telling LLMs what this domain is about and this is very readable to a to an LLM. If it had to instead get the\n\nan LLM. If it had to instead get the HTML of your web page and try to parse it, this is very errorprone and difficult and will screw it up and it's not going to work. So we can just directly speak to the LLM. It's worth it. Um a huge amount of documentation is currently written for people. So you will see things like lists and bold and pictures and this is not directly accessible by an LLM. So I see some of the services now are transitioning a lot of the their docs to be specifically for LLMs. So Versell and Stripe as an example are early movers here but there are a few more that I've seen already and they offer their documentation in markdown. Markdown is super easy for LMS to understand. This is great. Um maybe one simple example from from uh my experience as well. Maybe some of you know three blue one brown. He makes\n\nknow three blue one brown. He makes beautiful animation videos on YouTube. Yeah, I love this library. So that he wrote uh Manon and I wanted to make my own and uh there's extensive documentations on how to use manon and so I didn't want to actually read through it. So I copy pasted the whole thing to an LLM and I described what I wanted and it just worked out of the box like LLM just bcoded me an animation exactly what I wanted and I was like wow this is amazing. So if we can make docs legible to LLMs, it's going to unlock a huge amount of um kind of use and um I think this is wonderful and should should happen more. The other thing I wanted to point out is that you do unfortunately have to it's not just about taking your docs and making them appear in markdown. That's the easy part. We actually have to change the\n\npart. We actually have to change the docs because anytime your docs say click this is bad. An LLM will not be able to natively take this action right now. So, Verscell, for example, is replacing every occurrence of click with an equivalent curl command that your LM agent could take on your behalf. Um, and so I think this is very interesting. And then, of course, there's a model context protocol from Enthropic. And this is also another way, it's a protocol of speaking directly to agents as this new consumer and manipulator of digital information. So, I'm very bullish on these ideas. The other thing I really like is a number of little tools here and there that are helping ingest data that in like very LLM friendly formats. So for example, when I go to a GitHub repo like my nanoGPT repo, I can't feed\n\nrepo like my nanoGPT repo, I can't feed this to an LLM and ask questions about it uh because it's you know this is a human interface on GitHub. So when you just change the URL from GitHub to get ingest then uh this will actually concatenate all the files into a single giant text and it will create a directory structure etc. And this is ready to be copy pasted into your favorite LLM and you can do stuff. Maybe even more dramatic example of this is deep wiki where it's not just the raw content of these files. uh this is from Devon but also like they have Devon basically do analysis of the GitHub repo and Devon basically builds up a whole docs uh pages just for your repo and you can imagine that this is even more helpful to copy paste into your LLM. So I love all the little tools that basically where you just change the URL\n\nbasically where you just change the URL and it makes something accessible to an LLM. So this is all well and great and u I think there should be a lot more of it. One more note I wanted to make is that it is absolutely possible that in the future LLMs will be able to this is not even future this is today they'll be able to go around and they'll be able to click stuff and so on but I still think it's very worth u basically meeting LLM halfway LLM's halfway and making it easier for them to access all this information uh because this is still fairly expensive I would say to use and uh a lot more difficult and so I do think that lots of software there will be a long tail where it won't like adapt apps because these are not like live player sort of repositories or digital infrastructure and we will need these\n\ninfrastructure and we will need these tools. Uh but I think for everyone else I think it's very worth kind of like meeting in some middle point. So I'm bullish on both if that makes sense. So in summary, what an amazing time to get into the industry. We need to rewrite a ton of code. A ton of code will be written by professionals and by coders. These LLMs are kind of like utilities, kind of like fabs, but they're kind of especially like operating systems. But it's so early. It's like 1960s of operating systems and uh and I think a lot of the analogies cross over. Um and these LMS are kind of like these fallible uh you know people spirits that we have to learn to work with. And in order to do that properly, we need to adjust our infrastructure towards it. So when you're building these LLM apps, I describe some of the\n\nthese LLM apps, I describe some of the ways of working effectively with these LLMs and some of the tools that make that uh kind of possible and how you can spin this loop very very quickly and basically create partial tunneling products and then um yeah, a lot of code has to also be written for the agents more directly. But in any case, going back to the Iron Man suit analogy, I think what we'll see over the next decade roughly is we're going to take the slider from left to right. And I'm very interesting. It's going to be very interesting to see what that looks like. And I can't wait to build it with all of\n"
    }
  ]
}